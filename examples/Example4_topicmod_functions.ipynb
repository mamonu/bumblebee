{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ```topicmod``` functions to easily apply topic modelling LDA and NMF techniques to text data stored in ```pandas.DataFrame``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example script, we show how ```nlpfunctions.topicmod``` functions can make it easy to apply Latent Derichlet Analysis (LDA) and Non-negative Matrix Factorization (NMF) models to text data and store the results in ```pandas.DataFrame``` so that they can be used in other analyses and explorations.\n",
    "\n",
    "We will:\n",
    "1. A\n",
    "2. B\n",
    "3. C\n",
    "4. D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set ups and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and our user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from nltk import word_tokenize\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nlpbumblebee.utils import *\n",
    "from nlpbumblebee.basicnlp import *\n",
    "from nlpbumblebee.nlppipelineutils import *\n",
    "from nlpbumblebee.topicmod import *\n",
    "\n",
    "from gensim import models, corpora    #lda\n",
    "\n",
    "from sklearn import decomposition     #nmf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use the same labelled text data as in Example 2 and 3 from \"From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\" (available here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('Data/imdb.xlsx', header=0)\n",
    "df = pd.read_excel('Data/yelp_labelled.xlsx', header=0)\n",
    "\n",
    "#df['source'] = 'imdb'\n",
    "df['source'] = 'yelp'\n",
    "\n",
    "df[df.duplicated('text')]\n",
    "df = df.drop_duplicates('text')\n",
    "\n",
    "df[pd.isnull(df['text'])]   #yep, 1 case\n",
    "df = df[pd.notnull(df['text'])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      text  \\\n",
      "0  Wow... Loved this place.                                                                  \n",
      "1  Crust is not good.                                                                        \n",
      "2  Not tasty and the texture was just nasty.                                                 \n",
      "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
      "4  The selection on the menu was great and so were the prices.                               \n",
      "\n",
      "   score source  \n",
      "0  1      yelp   \n",
      "1  0      yelp   \n",
      "2  0      yelp   \n",
      "3  1      yelp   \n",
      "4  1      yelp   \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>the</td>\n",
       "      <td>and</td>\n",
       "      <td>I</td>\n",
       "      <td>was</td>\n",
       "      <td>a</td>\n",
       "      <td>to</td>\n",
       "      <td>The</td>\n",
       "      <td>is</td>\n",
       "      <td>of</td>\n",
       "      <td>for</td>\n",
       "      <td>...</td>\n",
       "      <td>place</td>\n",
       "      <td>with</td>\n",
       "      <td>had</td>\n",
       "      <td>be</td>\n",
       "      <td>are</td>\n",
       "      <td>were</td>\n",
       "      <td>very</td>\n",
       "      <td>that</td>\n",
       "      <td>have</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404</td>\n",
       "      <td>378</td>\n",
       "      <td>291</td>\n",
       "      <td>290</td>\n",
       "      <td>227</td>\n",
       "      <td>213</td>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>123</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9 ...     15    16   17  \\\n",
       "word   the  and  I    was  a    to   The  is   of   for ...  place  with  had   \n",
       "count  404  378  291  290  227  213  176  170  123  102 ...  76     71    65    \n",
       "\n",
       "       18   19    20    21    22    23  24  \n",
       "word   be  are  were  very  that  have  so  \n",
       "count  64  62   61    60    59    59    58  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot most frequent words\n",
    "\n",
    "# https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n",
    "all_words = df['text'].str.split(expand=True).unstack().value_counts()\n",
    "all_words = all_words.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 25 more frequent words\n",
    "all_words[:25].plot.bar(x='word')\n",
    "all_words[:25].T\n",
    "\n",
    "#lots of \"rubbish\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text data for topic modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will:\n",
    "1. tokenise\n",
    "2. lower case\n",
    "3. remove stopwords\n",
    "4. remove non-alphabetic tokens (i.e., punctuations and numbers)\n",
    "5. lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipe = combine_functions(sent_tokenise\n",
    "                                       ,remove_punctuation\n",
    "                                       ,word_tokenise\n",
    "                                       ,to_lower\n",
    "                                       ,POS_tagging\n",
    "                                       ,lemmatise\n",
    "                                       ,fix_neg_auxiliary\n",
    "                                       ,lambda s: [[re.sub(r'\\d+','',x) for x in subs] for subs in s]\n",
    "                                       ,lambda x : remove_stopwords(x, extra_stopwords = [\n",
    "                                           'x', \"'s\", \"not\", 'us', 'no', 'many', 'much', 'one', 'put', 've',\n",
    "                                           'wo', 'even', 'first', 'may', 'late', 'come', 'iam', 'ive', 'ill',\n",
    "                                           'good', 'bad', 'great', 'sure', 'best', 'quite', 'per', 'due', 'always',\n",
    "                                           'say', 'want', 'm', 'ever', 'every', 'really', 'well', 'little', 'd',\n",
    "                                           'also', 'get', 'would', 'could', 'like', 'go', 'lot', 'make'])\n",
    "                                       ,flattenIrregularListOfLists\n",
    "                                       ,lambda x: list(filter(None, x))\n",
    "                                      )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>[wow, love, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>[crust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>[stop, bank, holiday, rick, steve, recommendation, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>[selection, menu, price]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "                                                text_lemmas  \n",
       "0  [wow, love, place]                                        \n",
       "1  [crust]                                                   \n",
       "2  [tasty, texture, nasty]                                   \n",
       "3  [stop, bank, holiday, rick, steve, recommendation, love]  \n",
       "4  [selection, menu, price]                                  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lemmas'] = df['text'].apply(lambda x: preprocessing_pipe(x))\n",
    "\n",
    "# check some texts\n",
    "df[['text', 'text_lemmas']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>food</td>\n",
       "      <td>place</td>\n",
       "      <td>service</td>\n",
       "      <td>back</td>\n",
       "      <td>time</td>\n",
       "      <td>eat</td>\n",
       "      <td>love</td>\n",
       "      <td>wait</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>dont</td>\n",
       "      <td>...</td>\n",
       "      <td>think</td>\n",
       "      <td>taste</td>\n",
       "      <td>experience</td>\n",
       "      <td>im</td>\n",
       "      <td>minute</td>\n",
       "      <td>staff</td>\n",
       "      <td>price</td>\n",
       "      <td>pretty</td>\n",
       "      <td>star</td>\n",
       "      <td>server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123</td>\n",
       "      <td>110</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1        2     3     4    5     6     7           8     9  \\\n",
       "word   food  place  service  back  time  eat  love  wait  restaurant  dont   \n",
       "count  123   110    84       60    55    31   30    29    28          28     \n",
       "\n",
       "        ...       15     16          17  18      19     20     21      22  \\\n",
       "word    ...    think  taste  experience  im  minute  staff  price  pretty   \n",
       "count   ...    22     21     21          21  19      19     19     19       \n",
       "\n",
       "         23      24  \n",
       "word   star  server  \n",
       "count  18    18      \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-plot most frequent words\n",
    "\n",
    "all_lemmas = df['text_lemmas'].apply(list2string).str.split(expand=True).unstack().value_counts()\n",
    "all_lemmas = all_lemmas.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 25 more frequent lemmas\n",
    "all_lemmas[:25].plot.bar(x='word')\n",
    "all_lemmas[:25].T\n",
    "\n",
    "# much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling with Latent Dirichlet Analysis (LDA)\n",
    "\n",
    "LDA is a topic discovery technique. It is a generative statistical topic model used to find accurate sets of topics within a given document set. The model assumes that text documents are comprised of a mixture of topics, and each topic is represented as the probability that each of given set of terms will occur. From there, using probability distributions the model can determine which topics are in a given document and which words are in a given topic based on word prevalence across topics and topic prevalence across document. A unique feature of LDA models is that topics are not required to be distinct, and words may occur in multiple topics\n",
    "\n",
    "Ref: \n",
    "\n",
    "https://medium.com/square-corner-blog/topic-modeling-optimizing-for-human-interpretability-48a81f6ce0ed\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note**: As of today, September 2018, there seems to be a bug introduced in a recent version of ```gensim```, the way it interacts with ```numpy``` which is used for all the computations. Downgrading to gensim 3.1.0 seems to solve the problem (ref: https://github.com/RaRe-Technologies/gensim/issues/2115).\n",
    "To do this please type ```$ pip install gensim==3.1.0``` in your Terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Create a dictionary containing the number of times a word appears in the corpus of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary = association word to numeric id\n",
    "# assigning a unique integer id to each unique word while also collecting word counts and relevant statistics. \n",
    "dictionary = corpora.Dictionary(df['text_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640\n"
     ]
    }
   ],
   "source": [
    "# what's the vocabulary size?\n",
    "print(len(dictionary.token2id.keys()))\n",
    "\n",
    "# take a look (first 25 entries in the dictionary)\n",
    "#for k, v in dictionary.token2id.items(): \n",
    "#    print(\"{} : {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Filter out words that occur too frequently or too rarely.\n",
    "\n",
    "When dealing with a bigger corpus than the one used in his example, you may want to further clean the text data by excluding words that occur in:\n",
    "- less than X texts (absolute number) or (infrequent words)\n",
    "- more than 0.p documents (fraction of total corpus size, not absolute number) (too frequent words).\n",
    "- after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wordcount = 10\n",
    "max_freq = 0.6\n",
    "\n",
    "dictionary.filter_extremes(no_below=min_wordcount,\n",
    "                            no_above=max_freq,\n",
    "                            keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our dictionary size has become now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary.token2id.keys()))\n",
    "#...  too harsh filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) From texts as documents to Document Term Matrix\n",
    "\n",
    "Transform the collection of texts to a numerical form: For each text, report how many many times each occurring word appears. I.e., Convert the list of documents (corpus) into a Document Term Matrix using the dictionary prepared above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in df['text_lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "993\n",
      "[[(0, 1), (1, 1)], [], [(2, 1)], [(0, 1)], [(3, 1), (4, 1), (5, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(type(bow_corpus))\n",
    "print(len(bow_corpus))\n",
    "print(bow_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 text text_lemmas\n",
      "1  Crust is not good.  [crust]   \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at how the 1st text looks like: [(word_id, count), ...]\n",
    "\n",
    "print( df[['text', 'text_lemmas']][1:2] )\n",
    "print( bow_corpus[1] )\n",
    "\n",
    "for i in range(len(bow_corpus[1])):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_corpus[1][i][0],\n",
    "          dictionary[bow_corpus[1][i][0]], \n",
    "          bow_corpus[1][i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Find the best number of topics\n",
    "\n",
    "#### Perplexity\n",
    "\n",
    "Perplexity is a standard measure for estimating the performance of a probabilistic model: it measures how well the probabilistic model predicts a sample. The perplexity of a set of test words, is defined as the exponential of the negative normalized predictive likelihood under the model. \n",
    "\n",
    "One should expect \"in-sample\" perplexity to improve with more topics, but that the improvement would level off as the model captures all but the most trivial structures in the data. So the ideal number of topics should be the poin where perplexity starts to level off. \n",
    "\n",
    "Ref: \n",
    "\n",
    "https://docs.google.com/viewer?a=v&pid=forums&srcid=MDEwMDM0NjcxOTk3Njc0MTA0MjMBMTQzMzY3Nzc1NTMzNDgyNjIyMzEBZnBOMFVLSG9BZ0FKATAuMwEBdjI&authuser=0\n",
    "\n",
    "https://groups.google.com/forum/#!topic/gensim/BDuOnCGpgOs\n",
    "\n",
    "http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
    "\n",
    "https://groups.google.com/forum/#!topic/gensim/TpuYRxhyIOc\n",
    "\n",
    "\n",
    "**Important**: However, please note that it has been shown that perplexity doesn't correlate well with human judgements of topic coherence. \n",
    "\n",
    "Other coherence measures have been suggested that have performed better. Example: https://www.kdnuggets.com/2016/07/americas-next-topic-model.html\n",
    "\n",
    "\n",
    "TODO: turn this into a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "# (i) divide corpus in training and test corpus. The test corpus will be used to calculate perplexity\n",
    "    \n",
    "shuffle(bow_corpus)\n",
    "\n",
    "train_corpus, test_corpus = bow_corpus[:800], bow_corpus[800:]\n",
    "\n",
    "# Number of words in the training set and in the test set\n",
    "print(sum(cnt for document in train_corpus for _, cnt in document))\n",
    "print(sum(cnt for document in test_corpus for _, cnt in document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(22, 1), (66, 1)], [(1, 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of topics :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-word likelihood bound      -5.896702794551656\n",
      "perplexity : exp(-bound)                              363.8358464224428\n",
      "elapsed time: 3.252\n",
      " \n",
      "number of topics :  3\n",
      "per-word likelihood bound      -6.195260131659059\n",
      "perplexity : exp(-bound)                              490.4190019151045\n",
      "elapsed time: 3.385\n",
      " \n",
      "number of topics :  4\n",
      "per-word likelihood bound      -6.3538238262007765\n",
      "perplexity : exp(-bound)                              574.6860123670906\n",
      "elapsed time: 3.366\n",
      " \n",
      "number of topics :  5\n",
      "per-word likelihood bound      -6.455445039872226\n",
      "perplexity : exp(-bound)                              636.1567783947216\n",
      "elapsed time: 3.479\n",
      " \n",
      "number of topics :  7\n",
      "per-word likelihood bound      -6.397302296351302\n",
      "perplexity : exp(-bound)                              600.2236263446933\n",
      "elapsed time: 3.406\n",
      " \n",
      "number of topics :  8\n",
      "per-word likelihood bound      -6.3348025481228705\n",
      "perplexity : exp(-bound)                              563.858057160889\n",
      "elapsed time: 3.523\n",
      " \n",
      "number of topics :  9\n",
      "per-word likelihood bound      -6.552454408379151\n",
      "perplexity : exp(-bound)                              700.9625124649376\n",
      "elapsed time: 3.503\n",
      " \n",
      "number of topics :  10\n",
      "per-word likelihood bound      -6.492341080475514\n",
      "perplexity : exp(-bound)                              660.0668253831543\n",
      "elapsed time: 3.456\n",
      " \n",
      "number of topics :  15\n",
      "per-word likelihood bound      -6.437170075615505\n",
      "perplexity : exp(-bound)                              624.6366218503457\n",
      "elapsed time: 3.531\n",
      " \n",
      "number of topics :  20\n",
      "per-word likelihood bound      -6.207742929458618\n",
      "perplexity : exp(-bound)                              496.5791712373883\n",
      "elapsed time: 3.501\n",
      " \n",
      "number of topics :  25\n",
      "per-word likelihood bound      -6.195113040410079\n",
      "perplexity : exp(-bound)                              490.34687087664156\n",
      "elapsed time: 3.545\n",
      " \n",
      "number of topics :  30\n",
      "per-word likelihood bound      -6.235320800310605\n",
      "perplexity : exp(-bound)                              510.4643493062427\n",
      "elapsed time: 3.573\n",
      " \n",
      "number of topics :  35\n",
      "per-word likelihood bound      -6.130100170126209\n",
      "perplexity : exp(-bound)                              459.48218476321506\n",
      "elapsed time: 3.665\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# (ii) loop on training set for several numbers of topics: \n",
    "topics_seq = list((2,3,4,5,7,8,9,10, 15, 20, 25, 30, 35))\n",
    "\n",
    "results_perplexity = {}\n",
    "for topic_n in topics_seq:\n",
    "    start_time = time.time()\n",
    "    # run model\n",
    "    print('number of topics :  %d' % topic_n)\n",
    "    \n",
    "    model = models.LdaModel(corpus=train_corpus\n",
    "                             , num_topics=topic_n\n",
    "                             , id2word=dictionary\n",
    "                             , passes = 20  # as we have a small corpus\n",
    "                             , eta = 0.01 # topics are known to be word-sparse, the Dirichlet parameter of the word distributions is set small (e.g., 0.01), in which case learning is efficient.\n",
    "                             , alpha = 0.1    #believed that each document is associated with few topics\n",
    "                             , random_state = 1\n",
    "                             )\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # perplexity on hold-out test data\n",
    "    log_perplexity = model.log_perplexity(test_corpus)              # this is actually per-word likelihood bound\n",
    "    perplexity_test = np.exp(-log_perplexity.astype(np.float64))    # https://stats.stackexchange.com/a/324243\n",
    "    \n",
    "    print('per-word likelihood bound     ', log_perplexity)\n",
    "    print('perplexity : exp(-bound)                             ', perplexity_test)\n",
    "    print('elapsed time: %.3f' % elapsed)  \n",
    "    print( ' ')\n",
    "    results_perplexity[topic_n] = perplexity_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 363.8358464224428,\n",
       " 3: 490.4190019151045,\n",
       " 4: 574.6860123670906,\n",
       " 5: 636.1567783947216,\n",
       " 7: 600.2236263446933,\n",
       " 8: 563.858057160889,\n",
       " 9: 700.9625124649376,\n",
       " 10: 660.0668253831543,\n",
       " 15: 624.6366218503457,\n",
       " 20: 496.5791712373883,\n",
       " 25: 490.34687087664156,\n",
       " 30: 510.4643493062427,\n",
       " 35: 459.48218476321506}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0a786fd30>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of perplexity versus number of topics\n",
    "plt.plot(results_perplexity.keys(), results_perplexity.values(), 'r--',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Perplexity')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "# Perplexiy seems to suggest 8 topics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Build an lda model with the suggested number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "# Build the lda model with the suggested number of topics\n",
    "\n",
    "NUM_TOPICS = 8\n",
    "\n",
    "lda_model_1 = models.LdaModel(corpus=bow_corpus\n",
    "                             , num_topics=NUM_TOPICS\n",
    "                             , id2word=dictionary\n",
    "                             , passes = 20  # as we have a small corpus\n",
    "                             , eta = 0.01 # topics are known to be word-sparse, the Dirichlet parameter of the word distributions is set small (e.g., 0.01), in which case learning is efficient.\n",
    "                             , alpha = 0.1    #believed that each document is associated with few topics\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Explore topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the topics, we will look at each topic in terms of the words it has the highest probability to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.360*\"service\" + 0.109*\"food\" + 0.077*\"dont\" + 0.070*\"take\" + 0.070*\"burger\"\n",
      "Topic #1: 0.281*\"back\" + 0.215*\"food\" + 0.118*\"never\" + 0.085*\"wont\" + 0.075*\"think\"\n",
      "Topic #2: 0.199*\"nice\" + 0.191*\"friendly\" + 0.140*\"staff\" + 0.132*\"steak\" + 0.103*\"feel\"\n",
      "Topic #3: 0.167*\"restaurant\" + 0.109*\"wait\" + 0.091*\"food\" + 0.080*\"place\" + 0.078*\"know\"\n",
      "Topic #4: 0.238*\"time\" + 0.083*\"price\" + 0.074*\"food\" + 0.065*\"dish\" + 0.061*\"table\"\n",
      "Topic #5: 0.368*\"place\" + 0.080*\"im\" + 0.072*\"experience\" + 0.069*\"star\" + 0.063*\"definitely\"\n",
      "Topic #6: 0.138*\"love\" + 0.106*\"delicious\" + 0.091*\"food\" + 0.074*\"disappointed\" + 0.073*\"eat\"\n",
      "Topic #7: 0.129*\"taste\" + 0.116*\"order\" + 0.116*\"pretty\" + 0.103*\"chicken\" + 0.098*\"salad\"\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# (iv) Explore Topics\n",
    "\n",
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(NUM_TOPICS):\n",
    "    # Print the first 5 most representative words for each topic\n",
    "    print(\"Topic #%s:\" % idx, lda_model_1.print_topic(idx, 5))\n",
    " \n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Really hard to understand the topics...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python package ```pyLDAvis``` is designed to help the interpretion of the topics in a topic model. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization (https://datascienceplus.com/topic-modeling-in-python-with-nltk-and-gensim/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el121591406028325776644708755049\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el121591406028325776644708755049_data = {\"mdsDat\": {\"x\": [0.19677763732102163, 0.05649172104341627, 0.2555578697203853, -0.09339364526495605, 0.12114627949734644, -0.3406536768359741, -0.08832624779639199, -0.10759993768484728], \"y\": [0.13385323171932817, 0.14440530196678206, -0.3084745524837109, 0.09991139737085851, 0.1088280952186045, -0.07871362064388654, 0.15199088945736292, -0.2518007426053384], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [13.841569900512695, 12.55016040802002, 9.386845588684082, 11.19295597076416, 13.929162979125977, 15.178497314453125, 13.244181632995605, 10.676630973815918]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Freq\": [104.0, 82.0, 57.0, 53.0, 30.0, 28.0, 30.0, 120.0, 29.0, 21.0, 22.0, 23.0, 20.0, 30.0, 22.0, 26.0, 20.0, 17.0, 16.0, 15.0, 19.0, 18.0, 17.0, 29.0, 14.0, 15.0, 16.0, 15.0, 28.0, 14.0, 15.642765998840332, 10.757462501525879, 10.755448341369629, 15.515639305114746, 80.26819610595703, 6.762113571166992, 9.789495468139648, 17.266693115234375, 5.8715972900390625, 5.326816082000732, 5.392277717590332, 2.942816734313965, 6.841262340545654, 24.354921340942383, 1.9646124839782715, 2.051919937133789, 0.21452529728412628, 0.10110194981098175, 0.10967840999364853, 0.060195885598659515, 0.06742031872272491, 0.06633950769901276, 0.027352115139365196, 0.030677324160933495, 0.010642407462000847, 0.011268075555562973, 0.014145826920866966, 0.00977207999676466, 0.00977209024131298, 0.010347199626266956, 0.08989032357931137, 0.014926349744200706, 0.013934779912233353, 0.01209650095552206, 0.0159673523157835, 0.014225230552256107, 23.744731903076172, 17.10616111755371, 56.713096618652344, 13.28283405303955, 15.150862693786621, 7.609384536743164, 9.527124404907227, 9.508393287658691, 43.3933219909668, 1.9682859182357788, 3.107403516769409, 0.14005929231643677, 0.021133091300725937, 0.02464626170694828, 0.018689675256609917, 0.010353085584938526, 0.010143835097551346, 0.00997996050864458, 0.08303126692771912, 0.009502732194960117, 0.009502730332314968, 0.009502739645540714, 0.00997996423393488, 0.009996981360018253, 0.009502783417701721, 0.013218776322901249, 0.009979982860386372, 0.009502742439508438, 0.009502753615379333, 0.009502758271992207, 0.010326159186661243, 0.019409658387303352, 0.01105137076228857, 0.01172975730150938, 0.023878686130046844, 0.011348404921591282, 0.010115956887602806, 0.010740249417722225, 0.011553908698260784, 0.01124629657715559, 0.011504526250064373, 0.01030955370515585, 0.010934635996818542, 0.010457281954586506, 0.010585499927401543, 0.010652989149093628, 0.010464969091117382, 30.030460357666016, 28.90619468688965, 21.12664031982422, 15.577720642089844, 11.13208293914795, 19.90122413635254, 11.020569801330566, 5.879514694213867, 2.4378058910369873, 1.2304326295852661, 1.9526562690734863, 0.22923806309700012, 0.15013855695724487, 0.4845975339412689, 0.04792485758662224, 0.041113778948783875, 0.11400935053825378, 0.02600761130452156, 0.0185454823076725, 0.01658235676586628, 0.021833928301930428, 0.01646851934492588, 0.013256211765110493, 0.026374103501439095, 0.014933283440768719, 0.03701428696513176, 0.019352583214640617, 0.011679469607770443, 0.013001098297536373, 0.011735200881958008, 0.017756888642907143, 0.015848364681005478, 0.02750292979180813, 0.02416125126183033, 0.016455724835395813, 30.153423309326172, 14.010083198547363, 12.931072235107422, 13.99406909942627, 12.872037887573242, 11.598502159118652, 19.553850173950195, 6.347889423370361, 7.499207019805908, 3.241854429244995, 3.2388436794281006, 2.1548078060150146, 2.4618306159973145, 3.244152545928955, 14.411676406860352, 16.45704460144043, 2.166285514831543, 1.088269591331482, 1.198359727859497, 0.4996512234210968, 0.13041351735591888, 0.13693076372146606, 0.0695473849773407, 0.035895343869924545, 0.06735266745090485, 0.011699235066771507, 0.012919050641357899, 0.01162383146584034, 0.010770202614367008, 0.01239276397973299, 0.016338208690285683, 0.017010489478707314, 0.015552914701402187, 0.018676014617085457, 0.01669790782034397, 11.757325172424316, 18.556394577026367, 11.745477676391602, 13.681680679321289, 53.26667022705078, 9.448018074035645, 10.184724807739258, 14.521746635437012, 8.158818244934082, 8.822906494140625, 12.72133731842041, 9.802574157714844, 5.869184494018555, 10.637372970581055, 3.3486318588256836, 4.135810375213623, 16.531959533691406, 0.09751415997743607, 0.2863755226135254, 0.02713017165660858, 0.036064162850379944, 0.019743796437978745, 0.012235801666975021, 0.01152908056974411, 0.009796279482543468, 0.010596432723104954, 0.009796246886253357, 0.009796254336833954, 0.009796247817575932, 0.00979623943567276, 0.014553175307810307, 0.01328854076564312, 0.01803469844162464, 0.01217007264494896, 0.015637975186109543, 0.011871890164911747, 0.011574409902095795, 19.532350540161133, 16.74351692199707, 11.152547836303711, 14.319456100463867, 15.35387134552002, 17.68248176574707, 89.81324768066406, 10.217944145202637, 12.090414047241211, 7.32227087020874, 12.965694427490234, 3.7287168502807617, 3.7306854724884033, 5.553977966308594, 2.480121612548828, 0.3472471833229065, 0.44648221135139465, 0.026139164343476295, 0.030599920079112053, 0.18059910833835602, 0.020625364035367966, 0.01516035757958889, 0.01664598099887371, 0.01331451628357172, 0.010922955349087715, 0.012130328454077244, 0.013346237130463123, 0.009304944425821304, 0.00930488295853138, 0.011071146465837955, 0.00977212842553854, 0.03659762069582939, 0.011090410873293877, 0.013278404250741005, 0.01811906136572361, 0.013213285245001316, 0.012548942118883133, 29.396404266357422, 22.53080177307129, 15.69209098815918, 14.695601463317871, 11.765741348266602, 9.812589645385742, 9.809727668762207, 10.679341316223145, 7.85347318649292, 12.320243835449219, 7.748978137969971, 15.647947311401367, 4.828958034515381, 4.042457103729248, 5.891689300537109, 4.63763952255249, 2.9408135414123535, 1.9741889238357544, 19.31456184387207, 0.608559250831604, 0.19284425675868988, 0.09625021368265152, 0.050188854336738586, 0.077736996114254, 0.028796643018722534, 0.021756598725914955, 0.015202799811959267, 0.010986029170453548, 0.009806488640606403, 0.010299076326191425, 0.01643427461385727, 0.010723527520895004, 0.012856174260377884, 0.01675032451748848, 0.013651380315423012, 22.08977508544922, 16.831298828125, 14.721273422241211, 19.93619728088379, 17.693696975708008, 13.458450317382812, 10.517593383789062, 9.368807792663574, 19.99588966369629, 6.837744235992432, 6.320052146911621, 4.206849098205566, 4.2000908851623535, 2.1161773204803467, 1.1524193286895752, 1.592512607574463, 0.041165824979543686, 0.05456935241818428, 0.018337862566113472, 0.01800638809800148, 0.022310657426714897, 0.012454824522137642, 0.011269139125943184, 0.012623864226043224, 0.011072068475186825, 0.01104664709419012, 0.012205943465232849, 0.010518351569771767, 0.011352677829563618, 0.013498199172317982, 0.018484126776456833, 0.012729063630104065, 0.045451194047927856, 0.026802660897374153, 0.01263155322521925, 0.013514193706214428], \"Term\": [\"place\", \"service\", \"back\", \"time\", \"nice\", \"friendly\", \"restaurant\", \"food\", \"love\", \"staff\", \"taste\", \"never\", \"steak\", \"wait\", \"delicious\", \"order\", \"pretty\", \"chicken\", \"salad\", \"feel\", \"im\", \"price\", \"wont\", \"eat\", \"meal\", \"disappointed\", \"star\", \"take\", \"dont\", \"know\", \"take\", \"slow\", \"enjoy\", \"burger\", \"service\", \"serve\", \"menu\", \"dont\", \"minute\", \"pizza\", \"server\", \"atmosphere\", \"order\", \"food\", \"perfect\", \"quality\", \"recommend\", \"cook\", \"think\", \"selection\", \"vega\", \"price\", \"next\", \"never\", \"excellent\", \"still\", \"thing\", \"find\", \"worth\", \"amazing\", \"place\", \"salad\", \"try\", \"awesome\", \"restaurant\", \"back\", \"never\", \"wont\", \"back\", \"flavor\", \"think\", \"atmosphere\", \"fresh\", \"fry\", \"food\", \"bland\", \"dont\", \"excellent\", \"everything\", \"give\", \"buffet\", \"side\", \"meat\", \"perfect\", \"service\", \"find\", \"worth\", \"serve\", \"slow\", \"still\", \"amazing\", \"way\", \"cook\", \"next\", \"enjoy\", \"tasty\", \"enough\", \"love\", \"didnt\", \"disappointed\", \"place\", \"dish\", \"sushi\", \"feel\", \"delicious\", \"staff\", \"eat\", \"wasnt\", \"friendly\", \"star\", \"taste\", \"restaurant\", \"im\", \"nice\", \"friendly\", \"staff\", \"feel\", \"leave\", \"steak\", \"cook\", \"server\", \"dish\", \"serve\", \"service\", \"cant\", \"dont\", \"food\", \"bland\", \"flavor\", \"time\", \"table\", \"still\", \"side\", \"meal\", \"enough\", \"find\", \"im\", \"fantastic\", \"eat\", \"menu\", \"excellent\", \"enjoy\", \"meat\", \"vega\", \"didnt\", \"love\", \"place\", \"delicious\", \"restaurant\", \"know\", \"awesome\", \"wasnt\", \"selection\", \"cant\", \"wait\", \"amazing\", \"dont\", \"quality\", \"thing\", \"serve\", \"didnt\", \"server\", \"place\", \"food\", \"experience\", \"bland\", \"eat\", \"vega\", \"still\", \"burger\", \"pretty\", \"sushi\", \"time\", \"find\", \"tasty\", \"side\", \"excellent\", \"night\", \"give\", \"star\", \"wont\", \"friendly\", \"back\", \"fantastic\", \"price\", \"buffet\", \"table\", \"time\", \"worth\", \"tasty\", \"dish\", \"next\", \"amaze\", \"minute\", \"try\", \"menu\", \"wait\", \"everything\", \"server\", \"food\", \"vega\", \"back\", \"quality\", \"delicious\", \"wasnt\", \"serve\", \"night\", \"excellent\", \"amazing\", \"find\", \"perfect\", \"meat\", \"side\", \"give\", \"recommend\", \"staff\", \"selection\", \"friendly\", \"disappointed\", \"wont\", \"im\", \"star\", \"night\", \"vega\", \"definitely\", \"experience\", \"place\", \"sushi\", \"give\", \"excellent\", \"eat\", \"find\", \"amaze\", \"think\", \"next\", \"worth\", \"time\", \"way\", \"minute\", \"food\", \"burger\", \"enough\", \"thing\", \"cook\", \"meat\", \"cant\", \"flavor\", \"perfect\", \"side\", \"fantastic\", \"amazing\", \"back\", \"bland\", \"taste\", \"service\", \"order\", \"wait\", \"love\", \"delicious\", \"disappointed\", \"way\", \"enough\", \"meat\", \"side\", \"still\", \"perfect\", \"pizza\", \"quality\", \"eat\", \"find\", \"amazing\", \"try\", \"didnt\", \"give\", \"sushi\", \"food\", \"tasty\", \"chicken\", \"everything\", \"cant\", \"steak\", \"night\", \"fry\", \"bland\", \"worth\", \"excellent\", \"serve\", \"star\", \"enjoy\", \"definitely\", \"back\", \"place\", \"taste\", \"salad\", \"meal\", \"pretty\", \"chicken\", \"recommend\", \"thing\", \"bland\", \"order\", \"everything\", \"didnt\", \"fry\", \"fresh\", \"excellent\", \"find\", \"definitely\", \"table\", \"steak\", \"next\", \"buffet\", \"vega\", \"amazing\", \"meat\", \"cook\", \"perfect\", \"worth\", \"night\", \"side\", \"tasty\", \"selection\", \"price\", \"amaze\", \"service\", \"time\", \"im\", \"place\"], \"Total\": [104.0, 82.0, 57.0, 53.0, 30.0, 28.0, 30.0, 120.0, 29.0, 21.0, 22.0, 23.0, 20.0, 30.0, 22.0, 26.0, 20.0, 17.0, 16.0, 15.0, 19.0, 18.0, 17.0, 29.0, 14.0, 15.0, 16.0, 15.0, 28.0, 14.0, 15.715932846069336, 10.829835891723633, 10.830073356628418, 15.726996421813965, 82.40126037597656, 10.199214935302734, 15.731325149536133, 28.06527328491211, 18.678041458129883, 17.713815689086914, 18.691892623901367, 10.614523887634277, 26.90620994567871, 120.72816467285156, 9.880130767822266, 13.110806465148926, 13.738513946533203, 11.187962532043457, 20.871763229370117, 12.999112129211426, 15.044478416442871, 18.693758010864258, 10.726461410522461, 23.838027954101562, 9.631202697753906, 10.87918472290039, 13.828573226928711, 9.764121055603027, 9.85902214050293, 10.454141616821289, 104.39981079101562, 16.90934181213379, 15.760618209838867, 13.004429817199707, 30.235580444335938, 57.10538101196289, 23.838027954101562, 17.186098098754883, 57.10538101196289, 13.388632774353027, 20.871763229370117, 10.614523887634277, 13.788908004760742, 13.790037155151367, 120.72816467285156, 12.51972770690918, 28.06527328491211, 9.631202697753906, 10.34528636932373, 15.1198148727417, 11.836585998535156, 9.887678146362305, 9.88700008392334, 9.880130767822266, 82.40126037597656, 9.764121055603027, 9.85902214050293, 10.199214935302734, 10.829835891723633, 10.87918472290039, 10.454141616821289, 14.78930377960205, 11.187962532043457, 10.726461410522461, 10.830073356628418, 10.857256889343262, 11.848552703857422, 29.501651763916016, 13.475763320922852, 15.770926475524902, 104.39981079101562, 17.02313232421875, 12.280848503112793, 15.649639129638672, 22.635873794555664, 21.20880699157715, 29.891281127929688, 14.080348014831543, 28.993467330932617, 16.830671310424805, 22.168222427368164, 30.235580444335938, 19.623579025268555, 30.10677146911621, 28.993467330932617, 21.20880699157715, 15.649639129638672, 11.201553344726562, 20.086261749267578, 11.187962532043457, 18.691892623901367, 17.02313232421875, 10.199214935302734, 82.40126037597656, 11.930139541625977, 28.06527328491211, 120.72816467285156, 12.51972770690918, 13.388632774353027, 53.95491409301758, 13.799093246459961, 10.87918472290039, 9.887678146362305, 14.806390762329102, 11.848552703857422, 9.764121055603027, 19.623579025268555, 11.836441993713379, 29.891281127929688, 15.731325149536133, 9.631202697753906, 10.830073356628418, 9.88700008392334, 15.044478416442871, 13.475763320922852, 29.501651763916016, 104.39981079101562, 22.635873794555664, 30.235580444335938, 14.081549644470215, 13.004429817199707, 14.080348014831543, 12.999112129211426, 11.930139541625977, 30.256654739379883, 10.454141616821289, 28.06527328491211, 13.110806465148926, 13.828573226928711, 10.199214935302734, 13.475763320922852, 18.691892623901367, 104.39981079101562, 120.72816467285156, 19.914304733276367, 12.51972770690918, 29.891281127929688, 15.044478416442871, 10.87918472290039, 15.726996421813965, 20.06658363342285, 12.280848503112793, 53.95491409301758, 9.764121055603027, 10.857256889343262, 9.887678146362305, 9.631202697753906, 11.247867584228516, 15.1198148727417, 16.830671310424805, 17.186098098754883, 28.993467330932617, 57.10538101196289, 11.836441993713379, 18.693758010864258, 11.836585998535156, 13.799093246459961, 53.95491409301758, 9.85902214050293, 10.857256889343262, 17.02313232421875, 10.726461410522461, 12.619410514831543, 18.678041458129883, 15.760618209838867, 15.731325149536133, 30.256654739379883, 10.34528636932373, 18.691892623901367, 120.72816467285156, 15.044478416442871, 57.10538101196289, 13.110806465148926, 22.635873794555664, 14.080348014831543, 10.199214935302734, 11.247867584228516, 9.631202697753906, 10.454141616821289, 9.764121055603027, 9.880130767822266, 9.88700008392334, 9.887678146362305, 15.1198148727417, 13.738513946533203, 21.20880699157715, 12.999112129211426, 28.993467330932617, 15.770926475524902, 17.186098098754883, 19.623579025268555, 16.830671310424805, 11.247867584228516, 15.044478416442871, 17.01209831237793, 19.914304733276367, 104.39981079101562, 12.280848503112793, 15.1198148727417, 9.631202697753906, 29.891281127929688, 9.764121055603027, 12.619410514831543, 20.871763229370117, 10.726461410522461, 9.85902214050293, 53.95491409301758, 14.78930377960205, 18.678041458129883, 120.72816467285156, 15.726996421813965, 11.848552703857422, 13.828573226928711, 11.187962532043457, 9.88700008392334, 11.930139541625977, 13.388632774353027, 9.880130767822266, 9.887678146362305, 11.836441993713379, 10.454141616821289, 57.10538101196289, 12.51972770690918, 22.168222427368164, 82.40126037597656, 26.90620994567871, 30.256654739379883, 29.501651763916016, 22.635873794555664, 15.770926475524902, 14.78930377960205, 11.848552703857422, 9.88700008392334, 9.887678146362305, 10.87918472290039, 9.880130767822266, 17.713815689086914, 13.110806465148926, 29.891281127929688, 9.764121055603027, 10.454141616821289, 15.760618209838867, 13.475763320922852, 15.1198148727417, 12.280848503112793, 120.72816467285156, 10.857256889343262, 17.94834327697754, 10.34528636932373, 11.930139541625977, 20.086261749267578, 11.247867584228516, 13.790037155151367, 12.51972770690918, 9.85902214050293, 9.631202697753906, 10.199214935302734, 16.830671310424805, 10.830073356628418, 17.01209831237793, 57.10538101196289, 104.39981079101562, 22.168222427368164, 16.90934181213379, 14.806390762329102, 20.06658363342285, 17.94834327697754, 13.738513946533203, 13.828573226928711, 12.51972770690918, 26.90620994567871, 10.34528636932373, 13.475763320922852, 13.790037155151367, 13.788908004760742, 9.631202697753906, 9.764121055603027, 17.01209831237793, 13.799093246459961, 20.086261749267578, 10.726461410522461, 11.836585998535156, 15.044478416442871, 10.454141616821289, 9.88700008392334, 11.187962532043457, 9.880130767822266, 9.85902214050293, 11.247867584228516, 9.887678146362305, 10.857256889343262, 12.999112129211426, 18.693758010864258, 12.619410514831543, 82.40126037597656, 53.95491409301758, 19.623579025268555, 104.39981079101562], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.9728000164031982, 1.9708000421524048, 1.9706000089645386, 1.9639999866485596, 1.951300024986267, 1.566499948501587, 1.5032000541687012, 1.4917000532150269, 0.8202999830245972, 0.7759000062942505, 0.7343999743461609, 0.694599986076355, 0.6080999970436096, 0.3767000138759613, 0.36230000853538513, 0.12280000001192093, -2.181999921798706, -2.7290000915527344, -3.2711000442504883, -3.3975000381469727, -3.430299997329712, -3.6637001037597656, -3.9941999912261963, -4.677999973297119, -4.830399990081787, -4.895100116729736, -4.907599925994873, -4.9293999671936035, -4.9390997886657715, -4.940499782562256, -5.079899787902832, -5.054999828338623, -5.053400039672852, -5.002600193023682, -5.568699836730957, -6.320099830627441, 2.071500062942505, 2.0708000659942627, 2.06850004196167, 2.067500114440918, 1.7551000118255615, 1.7425999641418457, 1.7057000398635864, 1.7036999464035034, 1.0521999597549438, 0.22529999911785126, -0.12530000507831573, -2.1552999019622803, -4.118000030517578, -4.343699932098389, -4.375500202178955, -4.786300182342529, -4.806700229644775, -4.822299957275391, -4.824699878692627, -4.859499931335449, -4.869100093841553, -4.9029998779296875, -4.914000034332275, -4.916900157928467, -4.927700042724609, -4.9446001052856445, -4.946599960327148, -4.953499794006348, -4.963099956512451, -4.96560001373291, -4.969799995422363, -5.250999927520752, -5.030700206756592, -5.128399848937988, -6.307600021362305, -5.237800121307373, -5.026199817657471, -5.208799839019775, -5.504799842834473, -5.466700077056885, -5.787099838256836, -5.144000053405762, -5.807499885559082, -5.308199882507324, -5.571499824523926, -5.875500202178955, -5.460999965667725, 2.363300085067749, 2.362799882888794, 2.361999988555908, 2.361299991607666, 2.359600067138672, 2.356600046157837, 2.350800037384033, 1.2092000246047974, 0.42239999771118164, 0.250900000333786, -1.3765000104904175, -1.5861999988555908, -2.8649001121520996, -3.152100086212158, -3.1995999813079834, -3.4200000762939453, -3.793800115585327, -3.908099889755249, -4.008500099182129, -4.024799823760986, -4.153500080108643, -4.212600231170654, -4.236100196838379, -4.246200084686279, -4.309500217437744, -4.328199863433838, -4.334700107574463, -4.349100112915039, -4.3592000007629395, -4.370500087738037, -4.376100063323975, -4.379700183868408, -4.611999988555908, -6.00540018081665, -4.860799789428711, 2.1872000694274902, 2.184799909591675, 2.1842000484466553, 2.1837000846862793, 2.1800999641418457, 2.1617000102996826, 1.7532999515533447, 1.690999984741211, 0.870199978351593, 0.7925999760627747, 0.7383999824523926, 0.6352999806404114, 0.48989999294281006, 0.43860000371932983, 0.20970000326633453, 0.19709999859333038, -0.02850000001490116, -0.25279998779296875, -1.0267000198364258, -1.215000033378601, -2.2339999675750732, -2.553800106048584, -3.474900007247925, -3.6452999114990234, -4.496099948883057, -4.537099838256836, -4.544000148773193, -4.556099891662598, -4.606100082397461, -4.6209001541137695, -4.640399932861328, -4.707200050354004, -4.817699909210205, -5.157700061798096, -5.947500228881836, 1.9644999504089355, 1.9637999534606934, 1.9635000228881836, 1.9625999927520752, 1.958299994468689, 1.9285999536514282, 1.9071999788284302, 1.8122999668121338, 1.69760000705719, 1.6132999658584595, 1.5871000289916992, 1.4962999820709229, 0.9851999878883362, 0.9258000254631042, 0.8432000279426575, 0.462799996137619, -0.017100000753998756, -3.0676000118255615, -3.324199914932251, -4.209400177001953, -4.470799922943115, -4.598499774932861, -4.754499912261963, -4.911900043487549, -4.919600009918213, -4.923099994659424, -4.933300018310547, -4.945099830627441, -4.945799827575684, -4.945899963378906, -4.974800109863281, -4.969900131225586, -5.098700046539307, -5.002500057220459, -5.553899765014648, -5.220600128173828, -5.331900119781494, 1.8805999755859375, 1.8801000118255615, 1.8767999410629272, 1.8358999490737915, 1.7826999425888062, 1.7663999795913696, 1.7347999811172485, 1.7014000415802002, 1.6617000102996826, 1.611199975013733, 1.0499999523162842, 0.9225999712944031, 0.6665999889373779, 0.5613999962806702, 0.42089998722076416, -1.460800051689148, -2.9091999530792236, -4.452899932861328, -4.528800010681152, -4.619699954986572, -4.751299858093262, -4.776000022888184, -4.836999893188477, -4.848400115966797, -4.922800064086914, -5.005799770355225, -5.025599956512451, -5.082399845123291, -5.083199977874756, -5.089300155639648, -5.089900016784668, -5.467400074005127, -5.143700122833252, -5.534999847412109, -6.537099838256836, -5.73360013961792, -5.902500152587891, 2.0179998874664307, 2.0169999599456787, 2.0165998935699463, 2.0153000354766846, 2.0146000385284424, 2.0141000747680664, 2.013700008392334, 2.0030999183654785, 1.7920000553131104, 1.6584999561309814, 1.4957000017166138, 1.374400019645691, 1.3174999952316284, 1.0714999437332153, 1.037600040435791, 0.9549000263214111, 0.38429999351501465, 0.19370000064373016, 0.18889999389648438, -0.8598999977111816, -2.5118000507354736, -2.6556999683380127, -3.449399948120117, -3.5327999591827393, -3.9460999965667725, -4.430200099945068, -4.691999912261963, -4.777900218963623, -4.868100166320801, -4.876399993896484, -4.909999847412109, -4.895999908447266, -5.166200160980225, -6.112599849700928, -6.920499801635742, 2.233599901199341, 2.2325000762939453, 2.231300115585327, 2.230600118637085, 2.2228000164031982, 2.2165000438690186, 1.9634000062942505, 1.9471999406814575, 1.9402999877929688, 1.8229999542236328, 1.4799000024795532, 1.0499000549316406, 1.0484000444412231, 0.7217000126838684, 0.10029999911785126, -0.1315000057220459, -3.5776000022888184, -3.6712000370025635, -4.134399890899658, -4.251100063323975, -4.276599884033203, -4.495500087738037, -4.53980016708374, -4.549900054931641, -4.556700229644775, -4.5569000244140625, -4.588900089263916, -4.608799934387207, -4.625999927520752, -4.632999897003174, -4.6819000244140625, -4.6620001792907715, -5.265600204467773, -5.370299816131592, -5.111199855804443, -6.715099811553955], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.6565001010894775, -3.030900001525879, -3.031100034713745, -2.664599895477295, -1.0211000442504883, -3.4951999187469482, -3.125200033187866, -2.5576999187469482, -3.636399984359741, -3.7337000370025635, -3.7214999198913574, -4.327099800109863, -3.4835000038146973, -2.2137999534606934, -4.731200218200684, -4.687699794769287, -6.945799827575684, -7.6981000900268555, -7.616700172424316, -8.21660041809082, -8.103300094604492, -8.119500160217285, -9.005499839782715, -8.890700340270996, -9.949399948120117, -9.89229965209961, -9.664799690246582, -10.034700393676758, -10.034700393676758, -9.977499961853027, -7.815700054168701, -9.611100196838379, -9.679900169372559, -9.82129955291748, -9.543700218200684, -9.659199714660645, -2.141200065612793, -2.469099998474121, -1.2704999446868896, -2.722100019454956, -2.5905001163482666, -3.2792000770568848, -3.0543999671936035, -3.0564000606536865, -1.5382000207901, -4.631400108337402, -4.174799919128418, -7.274199962615967, -9.165499687194824, -9.011699676513672, -9.288299560546875, -9.878999710083008, -9.899399757385254, -9.91569995880127, -7.797100067138672, -9.964699745178223, -9.964699745178223, -9.964699745178223, -9.91569995880127, -9.913999557495117, -9.964699745178223, -9.634699821472168, -9.91569995880127, -9.964699745178223, -9.964699745178223, -9.964699745178223, -9.881600379943848, -9.250499725341797, -9.813799858093262, -9.754199981689453, -9.043299674987793, -9.787199974060059, -9.902199745178223, -9.842300415039062, -9.76930046081543, -9.796299934387207, -9.773599624633789, -9.883199691772461, -9.824399948120117, -9.869000434875488, -9.856800079345703, -9.850500106811523, -9.868300437927246, -1.6159000396728516, -1.654099941253662, -1.9675999879837036, -2.2723000049591064, -2.608299970626831, -2.0272998809814453, -2.6184000968933105, -3.2467000484466553, -4.126999855041504, -4.810800075531006, -4.348899841308594, -6.491099834442139, -6.914299964904785, -5.742599964141846, -8.056300163269043, -8.209500312805176, -7.189599990844727, -8.667499542236328, -9.00570011138916, -9.117500305175781, -8.842399597167969, -9.12440013885498, -9.341400146484375, -8.653499603271484, -9.222299575805664, -8.314599990844727, -8.96310043334961, -9.468099594116211, -9.360899925231934, -9.463299751281738, -9.049099922180176, -9.162799835205078, -8.611599922180176, -8.741100311279297, -9.125200271606445, -1.7877999544143677, -2.55430006980896, -2.634500026702881, -2.555500030517578, -2.6389999389648438, -2.7432000637054443, -2.220900058746338, -3.3459999561309814, -3.17930006980896, -4.01800012588501, -4.018899917602539, -4.426400184631348, -4.2932000160217285, -4.017300128936768, -2.526099920272827, -2.393399953842163, -4.42110013961792, -5.109499931335449, -5.013199806213379, -5.888000011444092, -7.231200218200684, -7.182400226593018, -7.859899997711182, -8.521300315856934, -7.891900062561035, -9.64229965209961, -9.54319953918457, -9.648799896240234, -9.725099563598633, -9.584699630737305, -9.30840015411377, -9.267999649047852, -9.357600212097168, -9.174599647521973, -9.286600112915039, -2.9482998847961426, -2.492000102996826, -2.9493000507354736, -2.7967000007629395, -1.4375, -3.1670000553131104, -3.091900110244751, -2.7372000217437744, -3.313699960708618, -3.2355000972747803, -2.869499921798706, -3.130199909210205, -3.6431000232696533, -3.0483999252319336, -4.2042999267578125, -3.9930999279022217, -2.6075000762939453, -7.740600109100342, -6.663300037384033, -9.01990032196045, -8.735300064086914, -9.337699890136719, -9.816200256347656, -9.875699996948242, -10.038599967956543, -9.960000038146973, -10.038599967956543, -10.038599967956543, -10.038599967956543, -10.038599967956543, -9.642800331115723, -9.733699798583984, -9.428299903869629, -9.821599960327148, -9.570899963378906, -9.846400260925293, -9.871800422668457, -2.526599884033203, -2.6807000637054443, -3.0869998931884766, -2.837100028991699, -2.7672998905181885, -2.6261000633239746, -1.0010000467300415, -3.1745998859405518, -3.0062999725341797, -3.5078001022338867, -2.9363999366760254, -4.182600021362305, -4.18209981918335, -3.7841999530792236, -4.590400218963623, -6.556399822235107, -6.305099964141846, -9.142999649047852, -8.98550033569336, -7.21019983291626, -9.379899978637695, -9.687800407409668, -9.594300270080566, -9.81760025024414, -10.015600204467773, -9.910699844360352, -9.815199851989746, -10.17590045928955, -10.17590045928955, -10.002099990844727, -10.126899719238281, -8.806500434875488, -10.000399589538574, -9.820300102233887, -9.509499549865723, -9.825200080871582, -9.876799583435059, -1.9815000295639038, -2.247499942779541, -2.6092000007629395, -2.674799919128418, -2.897200107574463, -3.078700065612793, -3.0789999961853027, -2.9941000938415527, -3.3013999462127686, -2.851099967956543, -3.3148000240325928, -2.611999988555908, -3.7876999378204346, -3.9655001163482666, -3.5887999534606934, -3.828200101852417, -4.283699989318848, -4.682199954986572, -2.4014999866485596, -5.859000205993652, -7.008299827575684, -7.703199863433838, -8.354299545288086, -7.916800022125244, -8.909899711608887, -9.190199851989746, -9.548700332641602, -9.873499870300293, -9.987099647521973, -9.93809986114502, -9.470800399780273, -9.897700309753418, -9.716300010681152, -9.451700210571289, -9.656299591064453, -2.051800012588501, -2.3236000537872314, -2.4576001167297363, -2.1542999744415283, -2.273699998855591, -2.547300100326538, -2.793800115585327, -2.9094998836517334, -2.151400089263916, -3.224400043487549, -3.3032000064849854, -3.710200071334839, -3.7118000984191895, -4.397299766540527, -5.005000114440918, -4.681600093841553, -8.336999893188477, -8.05519962310791, -9.145700454711914, -9.163900375366211, -8.949600219726562, -9.532500267028809, -9.632599830627441, -9.519000053405762, -9.650199890136719, -9.65250015258789, -9.55270004272461, -9.701499938964844, -9.625200271606445, -9.452099800109863, -9.137700080871582, -9.510700225830078, -8.23799991607666, -8.76609992980957, -9.518400192260742, -9.450900077819824]}, \"token.table\": {\"Topic\": [5, 6, 4, 7, 1, 2, 4, 2, 2, 4, 8, 5, 1, 4, 8, 3, 6, 8, 7, 4, 7, 8, 7, 3, 5, 1, 2, 4, 4, 6, 7, 1, 7, 5, 8, 6, 8, 4, 6, 5, 3, 6, 7, 8, 2, 1, 2, 4, 5, 7, 2, 8, 3, 2, 8, 6, 7, 6, 4, 3, 7, 8, 7, 1, 5, 1, 5, 2, 5, 6, 3, 6, 1, 8, 1, 7, 1, 7, 4, 6, 8, 5, 1, 4, 7, 8, 4, 8, 4, 1, 3, 4, 1, 3, 4, 5, 1, 3, 7, 1, 3, 6, 3, 7, 6, 7, 5, 1, 8, 5, 7, 4, 8, 2, 6, 5, 5, 7, 6, 4, 5, 4, 7, 2, 5], \"Freq\": [0.713187038898468, 0.316972017288208, 0.5739352107048035, 0.38262346386909485, 0.28263160586357117, 0.7536842823028564, 0.9996593594551086, 0.9981546401977539, 0.1597478836774826, 0.0798739418387413, 0.7188654541969299, 1.013805866241455, 1.0173588991165161, 1.0058557987213135, 1.0028780698776245, 0.9831995964050293, 0.8817254304885864, 0.117563396692276, 1.016086220741272, 0.14841459691524506, 0.37103649973869324, 0.44524380564689636, 1.014525055885315, 0.11748719215393066, 0.88115394115448, 0.6057307720184326, 0.10689366608858109, 0.24941855669021606, 0.033454570919275284, 0.4349094331264496, 0.5352731347084045, 1.0156902074813843, 1.0127819776535034, 0.28998714685440063, 0.6766366362571716, 0.7268043756484985, 0.20765838027000427, 0.10043031722307205, 0.9038729071617126, 1.0138181447982788, 1.0223877429962158, 0.4096630811691284, 0.5120788812637329, 0.1024157702922821, 0.9709729552268982, 0.1987937092781067, 0.3561720550060272, 0.1325291395187378, 0.1408122181892395, 0.15737836062908173, 0.7252205610275269, 0.2900882363319397, 1.000225305557251, 0.7251611948013306, 0.2900644838809967, 0.7936605215072632, 0.1984151303768158, 1.0191820859909058, 0.9942087531089783, 0.9820066690444946, 0.9829958081245422, 1.0130760669708252, 1.0114291906356812, 0.6356743574142456, 0.3814046084880829, 0.3212328255176544, 0.6960044503211975, 1.0067946910858154, 0.745819091796875, 0.18645477294921875, 0.996453583240509, 0.9779631495475769, 0.26016297936439514, 0.7433228492736816, 0.2024264633655548, 0.8097058534622192, 0.2822655439376831, 0.6774373054504395, 0.13409985601902008, 0.8620705008506775, 0.9966818690299988, 1.016382098197937, 0.15254591405391693, 0.228818878531456, 0.6101836562156677, 0.946245014667511, 0.9922084808349609, 1.0053614377975464, 1.0000683069229126, 0.686327338218689, 0.09804676473140717, 0.19609352946281433, 0.26749566197395325, 0.3209947943687439, 0.16049739718437195, 0.2139965146780014, 0.9708589315414429, 0.024271473288536072, 1.0113598108291626, 1.0157124996185303, 0.9901546835899353, 1.0100606679916382, 0.9957054257392883, 1.0111051797866821, 0.8142759799957275, 0.16285519301891327, 1.0145593881607056, 1.0180751085281372, 0.9924115538597107, 0.9210429787635803, 0.09210429340600967, 0.21694211661815643, 0.7954544425010681, 0.7186743021011353, 0.2874697148799896, 0.982301652431488, 0.6344928741455078, 0.38069573044776917, 0.9305739402770996, 0.6610116362571716, 0.3635563850402832, 0.9942936301231384, 1.0142465829849243, 0.98917156457901, 0.9128694534301758], \"Term\": [\"amaze\", \"amaze\", \"amazing\", \"amazing\", \"atmosphere\", \"atmosphere\", \"awesome\", \"back\", \"bland\", \"bland\", \"bland\", \"buffet\", \"burger\", \"cant\", \"chicken\", \"cook\", \"definitely\", \"definitely\", \"delicious\", \"didnt\", \"didnt\", \"didnt\", \"disappointed\", \"dish\", \"dish\", \"dont\", \"dont\", \"dont\", \"eat\", \"eat\", \"eat\", \"enjoy\", \"enough\", \"everything\", \"everything\", \"excellent\", \"excellent\", \"experience\", \"experience\", \"fantastic\", \"feel\", \"find\", \"find\", \"find\", \"flavor\", \"food\", \"food\", \"food\", \"food\", \"food\", \"fresh\", \"fresh\", \"friendly\", \"fry\", \"fry\", \"give\", \"give\", \"im\", \"know\", \"leave\", \"love\", \"meal\", \"meat\", \"menu\", \"menu\", \"minute\", \"minute\", \"never\", \"next\", \"next\", \"nice\", \"night\", \"order\", \"order\", \"perfect\", \"perfect\", \"pizza\", \"pizza\", \"place\", \"place\", \"pretty\", \"price\", \"quality\", \"quality\", \"quality\", \"recommend\", \"restaurant\", \"salad\", \"selection\", \"serve\", \"serve\", \"serve\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"side\", \"slow\", \"staff\", \"star\", \"steak\", \"still\", \"sushi\", \"sushi\", \"table\", \"take\", \"taste\", \"tasty\", \"tasty\", \"thing\", \"thing\", \"think\", \"think\", \"time\", \"try\", \"try\", \"vega\", \"wait\", \"wait\", \"wasnt\", \"way\", \"wont\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el121591406028325776644708755049\", ldavis_el121591406028325776644708755049_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el121591406028325776644708755049\", ldavis_el121591406028325776644708755049_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el121591406028325776644708755049\", ldavis_el121591406028325776644708755049_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(lda_model_1, bow_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saliency**: a measure of how much the term tells you about the topic.\n",
    "\n",
    "**Relevance**: a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n",
    "\n",
    "The **size** of the bubble measures the importance of the topics, relative to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "?remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (7) Test on new text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.017242866),\n",
       " (1, 0.33501568),\n",
       " (2, 0.18987677),\n",
       " (3, 0.017242607),\n",
       " (4, 0.21618977),\n",
       " (5, 0.18994752),\n",
       " (6, 0.017242605),\n",
       " (7, 0.017242204)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try on a new (invented) text\n",
    "text_test = ['time', 'waste', 'food', 'staff', 'back', 'definitely']\n",
    "text_test_bow = dictionary.doc2bow(text_test)\n",
    "\n",
    "lda_model_1.get_document_topics(bow = text_test_bow)\n",
    "list(lda_model_1[text_test_bow])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of topic probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ```topicmod.lda_dtm2df``` to create a dataframe in which:\n",
    "- each row represents a document/text\n",
    "- has one column for each topic containing the probability of that topic for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_df = lda_dtm2df(lda_model_1[bow_corpus], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_lda</th>\n",
       "      <th>t1_lda</th>\n",
       "      <th>t2_lda</th>\n",
       "      <th>t3_lda</th>\n",
       "      <th>t4_lda</th>\n",
       "      <th>t5_lda</th>\n",
       "      <th>t6_lda</th>\n",
       "      <th>t7_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.392852</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611106</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.392847</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t0_lda    t1_lda    t2_lda    t3_lda    t4_lda    t5_lda    t6_lda  \\\n",
       "0  0.035719  0.392852  0.035714  0.392857  0.035714  0.035714  0.035714   \n",
       "1  0.055556  0.055556  0.055556  0.055561  0.055556  0.611106  0.055556   \n",
       "2  0.055556  0.055556  0.055556  0.055556  0.055556  0.055556  0.611111   \n",
       "3  0.392857  0.392847  0.035714  0.035714  0.035714  0.035714  0.035714   \n",
       "4  0.055556  0.055561  0.055556  0.055557  0.055556  0.055556  0.055556   \n",
       "\n",
       "     t7_lda  \n",
       "0  0.035714  \n",
       "1  0.055556  \n",
       "2  0.055556  \n",
       "3  0.035724  \n",
       "4  0.611104  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of topics' top n words and their probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ```topicmod.lda_topic_top_words``` to create a dataframe in which:\n",
    "- each row represents a document/text\n",
    "- columns contains a list of that topic's top n words and a list of their the probability for that topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_top_words_lda</th>\n",
       "      <th>t1_top_words_lda</th>\n",
       "      <th>t2_top_words_lda</th>\n",
       "      <th>t3_top_words_lda</th>\n",
       "      <th>t4_top_words_lda</th>\n",
       "      <th>t5_top_words_lda</th>\n",
       "      <th>t6_top_words_lda</th>\n",
       "      <th>t7_top_words_lda</th>\n",
       "      <th>t0_top_word_pbs_lda</th>\n",
       "      <th>t1_top_word_pbs_lda</th>\n",
       "      <th>t2_top_word_pbs_lda</th>\n",
       "      <th>t3_top_word_pbs_lda</th>\n",
       "      <th>t4_top_word_pbs_lda</th>\n",
       "      <th>t5_top_word_pbs_lda</th>\n",
       "      <th>t6_top_word_pbs_lda</th>\n",
       "      <th>t7_top_word_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[service, food, dont, take, burger, slow]</td>\n",
       "      <td>[back, food, never, wont, think, flavor]</td>\n",
       "      <td>[nice, friendly, staff, steak, feel, leave]</td>\n",
       "      <td>[restaurant, wait, food, place, know, wasnt]</td>\n",
       "      <td>[time, price, food, dish, table, minute]</td>\n",
       "      <td>[place, im, experience, star, definitely, vega]</td>\n",
       "      <td>[love, delicious, food, disappointed, eat, way]</td>\n",
       "      <td>[taste, order, pretty, chicken, salad, meal]</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[service, food, dont, take, burger, slow]</td>\n",
       "      <td>[back, food, never, wont, think, flavor]</td>\n",
       "      <td>[nice, friendly, staff, steak, feel, leave]</td>\n",
       "      <td>[restaurant, wait, food, place, know, wasnt]</td>\n",
       "      <td>[time, price, food, dish, table, minute]</td>\n",
       "      <td>[place, im, experience, star, definitely, vega]</td>\n",
       "      <td>[love, delicious, food, disappointed, eat, way]</td>\n",
       "      <td>[taste, order, pretty, chicken, salad, meal]</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[service, food, dont, take, burger, slow]</td>\n",
       "      <td>[back, food, never, wont, think, flavor]</td>\n",
       "      <td>[nice, friendly, staff, steak, feel, leave]</td>\n",
       "      <td>[restaurant, wait, food, place, know, wasnt]</td>\n",
       "      <td>[time, price, food, dish, table, minute]</td>\n",
       "      <td>[place, im, experience, star, definitely, vega]</td>\n",
       "      <td>[love, delicious, food, disappointed, eat, way]</td>\n",
       "      <td>[taste, order, pretty, chicken, salad, meal]</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[service, food, dont, take, burger, slow]</td>\n",
       "      <td>[back, food, never, wont, think, flavor]</td>\n",
       "      <td>[nice, friendly, staff, steak, feel, leave]</td>\n",
       "      <td>[restaurant, wait, food, place, know, wasnt]</td>\n",
       "      <td>[time, price, food, dish, table, minute]</td>\n",
       "      <td>[place, im, experience, star, definitely, vega]</td>\n",
       "      <td>[love, delicious, food, disappointed, eat, way]</td>\n",
       "      <td>[taste, order, pretty, chicken, salad, meal]</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[service, food, dont, take, burger, slow]</td>\n",
       "      <td>[back, food, never, wont, think, flavor]</td>\n",
       "      <td>[nice, friendly, staff, steak, feel, leave]</td>\n",
       "      <td>[restaurant, wait, food, place, know, wasnt]</td>\n",
       "      <td>[time, price, food, dish, table, minute]</td>\n",
       "      <td>[place, im, experience, star, definitely, vega]</td>\n",
       "      <td>[love, delicious, food, disappointed, eat, way]</td>\n",
       "      <td>[taste, order, pretty, chicken, salad, meal]</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            t0_top_words_lda  \\\n",
       "0  [service, food, dont, take, burger, slow]   \n",
       "1  [service, food, dont, take, burger, slow]   \n",
       "2  [service, food, dont, take, burger, slow]   \n",
       "3  [service, food, dont, take, burger, slow]   \n",
       "4  [service, food, dont, take, burger, slow]   \n",
       "\n",
       "                           t1_top_words_lda  \\\n",
       "0  [back, food, never, wont, think, flavor]   \n",
       "1  [back, food, never, wont, think, flavor]   \n",
       "2  [back, food, never, wont, think, flavor]   \n",
       "3  [back, food, never, wont, think, flavor]   \n",
       "4  [back, food, never, wont, think, flavor]   \n",
       "\n",
       "                              t2_top_words_lda  \\\n",
       "0  [nice, friendly, staff, steak, feel, leave]   \n",
       "1  [nice, friendly, staff, steak, feel, leave]   \n",
       "2  [nice, friendly, staff, steak, feel, leave]   \n",
       "3  [nice, friendly, staff, steak, feel, leave]   \n",
       "4  [nice, friendly, staff, steak, feel, leave]   \n",
       "\n",
       "                               t3_top_words_lda  \\\n",
       "0  [restaurant, wait, food, place, know, wasnt]   \n",
       "1  [restaurant, wait, food, place, know, wasnt]   \n",
       "2  [restaurant, wait, food, place, know, wasnt]   \n",
       "3  [restaurant, wait, food, place, know, wasnt]   \n",
       "4  [restaurant, wait, food, place, know, wasnt]   \n",
       "\n",
       "                           t4_top_words_lda  \\\n",
       "0  [time, price, food, dish, table, minute]   \n",
       "1  [time, price, food, dish, table, minute]   \n",
       "2  [time, price, food, dish, table, minute]   \n",
       "3  [time, price, food, dish, table, minute]   \n",
       "4  [time, price, food, dish, table, minute]   \n",
       "\n",
       "                                  t5_top_words_lda  \\\n",
       "0  [place, im, experience, star, definitely, vega]   \n",
       "1  [place, im, experience, star, definitely, vega]   \n",
       "2  [place, im, experience, star, definitely, vega]   \n",
       "3  [place, im, experience, star, definitely, vega]   \n",
       "4  [place, im, experience, star, definitely, vega]   \n",
       "\n",
       "                                  t6_top_words_lda  \\\n",
       "0  [love, delicious, food, disappointed, eat, way]   \n",
       "1  [love, delicious, food, disappointed, eat, way]   \n",
       "2  [love, delicious, food, disappointed, eat, way]   \n",
       "3  [love, delicious, food, disappointed, eat, way]   \n",
       "4  [love, delicious, food, disappointed, eat, way]   \n",
       "\n",
       "                               t7_top_words_lda  \\\n",
       "0  [taste, order, pretty, chicken, salad, meal]   \n",
       "1  [taste, order, pretty, chicken, salad, meal]   \n",
       "2  [taste, order, pretty, chicken, salad, meal]   \n",
       "3  [taste, order, pretty, chicken, salad, meal]   \n",
       "4  [taste, order, pretty, chicken, salad, meal]   \n",
       "\n",
       "                                                          t0_top_word_pbs_lda  \\\n",
       "0  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "1  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "2  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "3  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "4  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "\n",
       "                                                          t1_top_word_pbs_lda  \\\n",
       "0  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "1  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "2  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "3  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "4  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "\n",
       "                                                        t2_top_word_pbs_lda  \\\n",
       "0  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "1  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "2  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "3  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "4  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "\n",
       "                                                           t3_top_word_pbs_lda  \\\n",
       "0  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "1  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "2  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "3  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "4  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "\n",
       "                                                         t4_top_word_pbs_lda  \\\n",
       "0  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "1  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "2  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "3  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "4  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "\n",
       "                                                           t5_top_word_pbs_lda  \\\n",
       "0  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "1  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "2  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "3  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "4  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "\n",
       "                                                           t6_top_word_pbs_lda  \\\n",
       "0  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "1  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "2  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "3  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "4  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "\n",
       "                                                         t7_top_word_pbs_lda  \n",
       "0  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]  \n",
       "1  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]  \n",
       "2  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]  \n",
       "3  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]  \n",
       "4  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (iv) extract top n words and their probabilities for each topic, turn them into a dataframe\n",
    "\n",
    "words_topics_dict = lda_topic_top_words(lda_mod = lda_model_1, n_top_words = 6)\n",
    "words_topics_df = topictopwords_dict2df(words_topics_dict, orig_dataset = df, tech = 'lda')\n",
    "\n",
    "words_topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe with top n topics for each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use ```topicmod.lda_ranked_topics2df``` to create a dataframe in which:\n",
    "- rows are documents\n",
    "- the first column ```ranked_topics_lda``` contains tuples of ranked topics for each document; if all topics have the same probability for a document, then topics are ordered by their index (e.g., (0,1,2,3))\n",
    "- the second column ```ranked_topics_pbs_lda``` contains tuples of the ranked topics' probabilities for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranked_topics_lda</th>\n",
       "      <th>ranked_topics_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3, 1, 0, 2, 4, 5, 6, 7)</td>\n",
       "      <td>(0.39285716, 0.39285064, 0.03572079, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(5, 3, 0, 1, 2, 4, 6, 7)</td>\n",
       "      <td>(0.6111058, 0.05556089, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(6, 0, 1, 2, 3, 4, 5, 7)</td>\n",
       "      <td>(0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1, 7, 2, 3, 4, 5, 6)</td>\n",
       "      <td>(0.39285713, 0.39284754, 0.03572388, 0.035714284, 0.035714284, 0.035714284, 0.035714284, 0.035714284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(7, 1, 3, 0, 2, 4, 5, 6)</td>\n",
       "      <td>(0.61110574, 0.05555923, 0.05555722, 0.055555552, 0.055555552, 0.055555552, 0.055555552, 0.055555552)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ranked_topics_lda  \\\n",
       "0  (3, 1, 0, 2, 4, 5, 6, 7)   \n",
       "1  (5, 3, 0, 1, 2, 4, 6, 7)   \n",
       "2  (6, 0, 1, 2, 3, 4, 5, 7)   \n",
       "3  (0, 1, 7, 2, 3, 4, 5, 6)   \n",
       "4  (7, 1, 3, 0, 2, 4, 5, 6)   \n",
       "\n",
       "                                                                                    ranked_topics_pbs_lda  \n",
       "0  (0.39285716, 0.39285064, 0.03572079, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)   \n",
       "1  (0.6111058, 0.05556089, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)         \n",
       "2  (0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)  \n",
       "3  (0.39285713, 0.39284754, 0.03572388, 0.035714284, 0.035714284, 0.035714284, 0.035714284, 0.035714284)   \n",
       "4  (0.61110574, 0.05555923, 0.05555722, 0.055555552, 0.055555552, 0.055555552, 0.055555552, 0.055555552)   "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (v) Ranked topics for each doc, create a DTM dataframe \n",
    "\n",
    "ranked_DTM_df =  lda_ranked_topics2df(lda_mod = lda_model_1, corpus = bow_corpus)\n",
    "\n",
    "ranked_DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join LDA-results datasets with the original dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll be using our ```nlpfunctions.utils.merge_dfs``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = merge_dfs(df, DTM_df, words_topics_df, ranked_DTM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>t0_lda</th>\n",
       "      <th>t1_lda</th>\n",
       "      <th>t2_lda</th>\n",
       "      <th>t3_lda</th>\n",
       "      <th>t4_lda</th>\n",
       "      <th>t5_lda</th>\n",
       "      <th>...</th>\n",
       "      <th>t0_top_word_pbs_lda</th>\n",
       "      <th>t1_top_word_pbs_lda</th>\n",
       "      <th>t2_top_word_pbs_lda</th>\n",
       "      <th>t3_top_word_pbs_lda</th>\n",
       "      <th>t4_top_word_pbs_lda</th>\n",
       "      <th>t5_top_word_pbs_lda</th>\n",
       "      <th>t6_top_word_pbs_lda</th>\n",
       "      <th>t7_top_word_pbs_lda</th>\n",
       "      <th>ranked_topics_lda</th>\n",
       "      <th>ranked_topics_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[wow, love, place]</td>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.392852</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "      <td>(3, 1, 0, 2, 4, 5, 6, 7)</td>\n",
       "      <td>(0.39285716, 0.39285064, 0.03572079, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[crust]</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611106</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "      <td>(5, 3, 0, 1, 2, 4, 6, 7)</td>\n",
       "      <td>(0.6111058, 0.05556089, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "      <td>(6, 0, 1, 2, 3, 4, 5, 7)</td>\n",
       "      <td>(0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[stop, bank, holiday, rick, steve, recommendation, love]</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.392847</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "      <td>(0, 1, 7, 2, 3, 4, 5, 6)</td>\n",
       "      <td>(0.39285713, 0.39284754, 0.03572388, 0.035714284, 0.035714284, 0.035714284, 0.035714284, 0.035714284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[selection, menu, price]</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]</td>\n",
       "      <td>[0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]</td>\n",
       "      <td>[0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]</td>\n",
       "      <td>[0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]</td>\n",
       "      <td>[0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]</td>\n",
       "      <td>[0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]</td>\n",
       "      <td>[0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]</td>\n",
       "      <td>[0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]</td>\n",
       "      <td>(7, 1, 3, 0, 2, 4, 5, 6)</td>\n",
       "      <td>(0.61110574, 0.05555923, 0.05555722, 0.055555552, 0.055555552, 0.055555552, 0.055555552, 0.055555552)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "   score source                                               text_lemmas  \\\n",
       "0  1      yelp   [wow, love, place]                                         \n",
       "1  0      yelp   [crust]                                                    \n",
       "2  0      yelp   [tasty, texture, nasty]                                    \n",
       "3  1      yelp   [stop, bank, holiday, rick, steve, recommendation, love]   \n",
       "4  1      yelp   [selection, menu, price]                                   \n",
       "\n",
       "     t0_lda    t1_lda    t2_lda    t3_lda    t4_lda    t5_lda  \\\n",
       "0  0.035719  0.392852  0.035714  0.392857  0.035714  0.035714   \n",
       "1  0.055556  0.055556  0.055556  0.055561  0.055556  0.611106   \n",
       "2  0.055556  0.055556  0.055556  0.055556  0.055556  0.055556   \n",
       "3  0.392857  0.392847  0.035714  0.035714  0.035714  0.035714   \n",
       "4  0.055556  0.055561  0.055556  0.055557  0.055556  0.055556   \n",
       "\n",
       "                                                    ...                                                    \\\n",
       "0                                                   ...                                                     \n",
       "1                                                   ...                                                     \n",
       "2                                                   ...                                                     \n",
       "3                                                   ...                                                     \n",
       "4                                                   ...                                                     \n",
       "\n",
       "                                                          t0_top_word_pbs_lda  \\\n",
       "0  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "1  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "2  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "3  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "4  [0.36018994, 0.10928859, 0.07748137, 0.07019427, 0.069623806, 0.048272293]   \n",
       "\n",
       "                                                          t1_top_word_pbs_lda  \\\n",
       "0  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "1  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "2  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "3  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "4  [0.28067747, 0.21475688, 0.117514506, 0.08465971, 0.074982785, 0.06573777]   \n",
       "\n",
       "                                                        t2_top_word_pbs_lda  \\\n",
       "0  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "1  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "2  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "3  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "4  [0.19870818, 0.19126904, 0.1397926, 0.13168417, 0.103076026, 0.07365975]   \n",
       "\n",
       "                                                           t3_top_word_pbs_lda  \\\n",
       "0  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "1  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "2  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "3  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "4  [0.16732669, 0.10850778, 0.091323055, 0.079972945, 0.07774444, 0.077655576]   \n",
       "\n",
       "                                                         t4_top_word_pbs_lda  \\\n",
       "0  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "1  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "2  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "3  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "4  [0.23752207, 0.082745045, 0.07371786, 0.0647541, 0.061008148, 0.05672587]   \n",
       "\n",
       "                                                           t5_top_word_pbs_lda  \\\n",
       "0  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "1  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "2  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "3  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "4  [0.36752352, 0.079928055, 0.072358236, 0.06851591, 0.06282936, 0.058596443]   \n",
       "\n",
       "                                                           t6_top_word_pbs_lda  \\\n",
       "0  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "1  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "2  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "3  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "4  [0.13786134, 0.105663486, 0.09058018, 0.07359175, 0.073384725, 0.068918474]   \n",
       "\n",
       "                                                         t7_top_word_pbs_lda  \\\n",
       "0  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]   \n",
       "1  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]   \n",
       "2  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]   \n",
       "3  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]   \n",
       "4  [0.12850812, 0.11632687, 0.115979604, 0.10293377, 0.09791674, 0.08564158]   \n",
       "\n",
       "          ranked_topics_lda  \\\n",
       "0  (3, 1, 0, 2, 4, 5, 6, 7)   \n",
       "1  (5, 3, 0, 1, 2, 4, 6, 7)   \n",
       "2  (6, 0, 1, 2, 3, 4, 5, 7)   \n",
       "3  (0, 1, 7, 2, 3, 4, 5, 6)   \n",
       "4  (7, 1, 3, 0, 2, 4, 5, 6)   \n",
       "\n",
       "                                                                                    ranked_topics_pbs_lda  \n",
       "0  (0.39285716, 0.39285064, 0.03572079, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)   \n",
       "1  (0.6111058, 0.05556089, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)         \n",
       "2  (0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)  \n",
       "3  (0.39285713, 0.39284754, 0.03572388, 0.035714284, 0.035714284, 0.035714284, 0.035714284, 0.035714284)   \n",
       "4  (0.61110574, 0.05555923, 0.05555722, 0.055555552, 0.055555552, 0.055555552, 0.055555552, 0.055555552)   \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the LDA results as input for other analyses. For instance, here we show how we could include documents' ranked topics and probabilities in a classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lda_topic_pbs = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['t0_lda', 't1_lda', 't2_lda', 't3_lda', 't4_lda', 't5_lda', 't6_lda', 't7_lda']))\n",
    "        \n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = CountVectorizer(tokenizer = word_tokenize,\n",
    "                         analyzer=\"word\",\n",
    "                         ngram_range = (1,3),\n",
    "                         stop_words=None,\n",
    "                         min_df=1\n",
    "                         )\n",
    "\n",
    "pipe_bags_words = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['text'])),\n",
    "        ('transformer', Series2ListOfStrings()),\n",
    "        ('vec', my_vec),\n",
    "        ('tf_idf', TfidfTransformer())\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier\n",
    "\n",
    "svm = SVC(probability=True, C=1, kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_svm_clf = Pipeline([\n",
    "        \n",
    "        # Combined text (bag-of-word) and ad-hoc features\n",
    "        ('features', FeatureUnion(\n",
    "            \n",
    "                transformer_list = [\n",
    "                        ('lda', pipe_lda_topic_pbs),\n",
    "                        ('bow', pipe_bags_words)\n",
    "                        ],\n",
    "            \n",
    "                # weight components in FeatureUnion\n",
    "                transformer_weights={\n",
    "                        'lda': 0.6,\n",
    "                        'bow': 1.0\n",
    "                        }    \n",
    "                )),\n",
    "        \n",
    "        # Use classifier on combined features\n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = text_df[['text', 't0_lda', 't1_lda', 't2_lda', 't3_lda', 't4_lda', 't5_lda', 't6_lda', 't7_lda']]\n",
    "y = text_df.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_validate(lda_bow_svm_clf, X, y, cv = 5, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.999 (std 0.001)\n",
      "Test Accuracy: 0.823 (std 0.027)\n"
     ]
    }
   ],
   "source": [
    "sorted(scores_svm.keys())\n",
    "\n",
    "print(\"Train Accuracy: %0.3f (std %0.3f)\" % (scores_svm['train_score'].mean(), scores_svm['train_score'].std()))\n",
    "print(\"Test Accuracy: %0.3f (std %0.3f)\" % (scores_svm['test_score'].mean(), scores_svm['test_score'].std()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuplesToColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class for building sklearn Pipeline step. \n",
    "    This class turns columns from a pandas data frame (type Series) that\n",
    "    contain tuples of integer or float values into separate array columns \n",
    "    that can be used as inout in ML pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialise\n",
    "    def __init__(self):\n",
    "        self              #could also use 'pass'\n",
    "        \n",
    "    # \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):        #X: dataset to pass to the transformer.\n",
    "        cols_df = pd.DataFrame()\n",
    "        for name, valuez in X.iteritems():\n",
    "            valuez_df = pd.DataFrame(valuez.values.tolist())\n",
    "            cols_df = pd.concat([cols_df, valuez_df], axis=1)\n",
    "        return cols_df.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lda_topic_pbs_2 = Pipeline([\n",
    "    \n",
    "    ('selector', ColumnSelector(columns=['ranked_topics_lda', 'ranked_topics_pbs_lda'])),\n",
    "    ('toarray', TuplesToColumns())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_svm_clf_2 = Pipeline([\n",
    "        \n",
    "        # Combined text (bag-of-word) and ad-hoc features\n",
    "        ('features', FeatureUnion(\n",
    "            \n",
    "                transformer_list = [\n",
    "                        ('lda', pipe_lda_topic_pbs_2),\n",
    "                        ('bow', pipe_bags_words)\n",
    "                        ],\n",
    "            \n",
    "                # weight components in FeatureUnion\n",
    "                transformer_weights={\n",
    "                        'lda': 0.6,\n",
    "                        'bow': 1.0\n",
    "                        }    \n",
    "                )),\n",
    "        \n",
    "        # Use classifier on combined features\n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_df[['text', 'ranked_topics_lda', 'ranked_topics_pbs_lda']]\n",
    "y = text_df.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_validate(lda_bow_svm_clf_2, X, y, cv = 5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.998 (std 0.001)\n",
      "Test Accuracy: 0.816 (std 0.023)\n"
     ]
    }
   ],
   "source": [
    "sorted(scores_svm.keys())\n",
    "\n",
    "print(\"Train Accuracy: %0.3f (std %0.3f)\" % (scores_svm['train_score'].mean(), scores_svm['train_score'].std()))\n",
    "print(\"Test Accuracy: %0.3f (std %0.3f)\" % (scores_svm['test_score'].mean(), scores_svm['test_score'].std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc = TuplesToColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.        , 1.        , 0.        , ..., 0.03571429, 0.03571429,\n",
       "        0.03571429],\n",
       "       [5.        , 3.        , 0.        , ..., 0.05555556, 0.05555556,\n",
       "        0.05555556],\n",
       "       [6.        , 0.        , 1.        , ..., 0.05555556, 0.05555556,\n",
       "        0.05555556],\n",
       "       ...,\n",
       "       [1.        , 4.        , 0.        , ..., 0.03571429, 0.03571429,\n",
       "        0.03571429],\n",
       "       [1.        , 0.        , 3.        , ..., 0.05555564, 0.05555556,\n",
       "        0.05555556],\n",
       "       [0.        , 1.        , 2.        , ..., 0.125     , 0.125     ,\n",
       "        0.125     ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc.fit_transform(text_df[['ranked_topics_lda', 'ranked_topics_pbs_lda']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
