{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ```topicmod``` functions to easily apply topic modelling LDA and NMF techniques to text data stored in ```pandas.DataFrame``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example script, we show how ```nlpfunctions.topicmod``` functions can make it easy to apply Latent Derichlet Analysis (LDA) and Non-negative Matrix Factorization (NMF) models to text data and store the results in ```pandas.DataFrame``` so that they can be used in other analyses and explorations.\n",
    "\n",
    "We will:\n",
    "1. A\n",
    "2. B\n",
    "3. C\n",
    "4. D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set ups and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and our user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from nltk import word_tokenize\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nlpbumblebee.utils import *\n",
    "from nlpbumblebee.basicnlp import *\n",
    "from nlpbumblebee.nlppipelineutils import *\n",
    "from nlpbumblebee.topicmod import *\n",
    "\n",
    "from gensim import models, corpora    #lda\n",
    "\n",
    "from sklearn import decomposition     #nmf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use the same labelled text data as in Example 2 and 3 from \"From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\" (available here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('Data/imdb.xlsx', header=0)\n",
    "df = pd.read_excel('Data/yelp_labelled.xlsx', header=0)\n",
    "\n",
    "#df['source'] = 'imdb'\n",
    "df['source'] = 'yelp'\n",
    "\n",
    "df[df.duplicated('text')]\n",
    "df = df.drop_duplicates('text')\n",
    "\n",
    "df[pd.isnull(df['text'])]   #yep, 1 case\n",
    "df = df[pd.notnull(df['text'])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      text  \\\n",
      "0  Wow... Loved this place.                                                                  \n",
      "1  Crust is not good.                                                                        \n",
      "2  Not tasty and the texture was just nasty.                                                 \n",
      "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
      "4  The selection on the menu was great and so were the prices.                               \n",
      "\n",
      "   score source  \n",
      "0  1      yelp   \n",
      "1  0      yelp   \n",
      "2  0      yelp   \n",
      "3  1      yelp   \n",
      "4  1      yelp   \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>the</td>\n",
       "      <td>and</td>\n",
       "      <td>I</td>\n",
       "      <td>was</td>\n",
       "      <td>a</td>\n",
       "      <td>to</td>\n",
       "      <td>The</td>\n",
       "      <td>is</td>\n",
       "      <td>of</td>\n",
       "      <td>for</td>\n",
       "      <td>...</td>\n",
       "      <td>place</td>\n",
       "      <td>with</td>\n",
       "      <td>had</td>\n",
       "      <td>be</td>\n",
       "      <td>are</td>\n",
       "      <td>were</td>\n",
       "      <td>very</td>\n",
       "      <td>that</td>\n",
       "      <td>have</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404</td>\n",
       "      <td>378</td>\n",
       "      <td>291</td>\n",
       "      <td>290</td>\n",
       "      <td>227</td>\n",
       "      <td>213</td>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>123</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9 ...     15    16   17  \\\n",
       "word   the  and  I    was  a    to   The  is   of   for ...  place  with  had   \n",
       "count  404  378  291  290  227  213  176  170  123  102 ...  76     71    65    \n",
       "\n",
       "       18   19    20    21    22    23  24  \n",
       "word   be  are  were  very  that  have  so  \n",
       "count  64  62   61    60    59    59    58  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEbCAYAAADUCE9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XvcXFV97/HPlxATLuES8qCRUIM0goAQ8CFFoYUQW7nYRi0oyE2kpLZQ6LGtBT1W9Bw8UC8g9hSNBzEgChH1BBGslAQxyMWEhBAIHlII8JhUwtVYDJDwO3+sNTA8zGU/c3meyc73/XrNa2avWWvvNbffrL322msrIjAzs/LaYqQrYGZm3eVAb2ZWcg70ZmYl50BvZlZyDvRmZiXnQG9mVnIO9GZmJedAb2ZWcg70ZmYlt+VIVwBgwoQJMXny5JGuhpnZJmXx4sVPRERfs3w9EegnT57MokWLRroaZmabFEmPFMnnrhszs5JzoDczKzkHejOzkuuJPnozs2ZefPFFBgYGWL9+/UhXZdiNHTuWSZMmMXr06JbKO9Cb2SZhYGCAcePGMXnyZCSNdHWGTUTw5JNPMjAwwG677dbSOtx1Y2abhPXr17PTTjttVkEeQBI77bRTW3syDvRmtsnY3IJ8Rbuvu3CglzRK0hJJ1+fl3STdKelBSddIel1OH5OXV+bnJ7dVQzMza8tQ+ujPBlYA2+XlC4GLIuJqSV8FTgMuzfdPR8TvSzou5/tgB+tsZsbkc37U0fWtuuDojq5vqC6++GJmzZrF1ltv3fF1Fwr0kiYBRwPnAx9T2o84HPhQzjIHOI8U6GfmxwDXAv8iSTGEq5DX+wBH+oMwM+uWiy++mBNPPLErgb5o183FwMeBl/LyTsAzEbEhLw8Au+THuwCPAeTnn835zcw2aVdccQX77rsv++23HyeddBKPPPIIM2bMYN9992XGjBk8+uijAHz4wx/m2muvfbnctttuC8Att9zCYYcdxjHHHMOee+7JCSecQERwySWXsHr1aqZPn8706dM7Xu+mgV7Se4DHI2JxdXKNrFHguer1zpK0SNKitWvXFqqsmdlIue+++zj//POZP38+99xzD1/+8pc588wzOfnkk1m2bBknnHACZ511VtP1LFmyhIsvvpj777+fhx56iNtuu42zzjqLN77xjSxYsIAFCxZ0vO5FWvQHA38maRVwNanL5mJgB0mVrp9JwOr8eADYFSA/vz3w1OCVRsTsiOiPiP6+vqaTr5mZjaj58+dzzDHHMGHCBADGjx/P7bffzoc+lHqwTzrpJBYuXNh0PdOmTWPSpElsscUWTJ06lVWrVnWz2kCBQB8R50bEpIiYDBwHzI+IE4AFwDE52ynAvPz4urxMfn7+UPrnzcx6UUQ0HeZYeX7LLbfkpZdeerncCy+88HKeMWPGvPx41KhRbNiwgW5rZxz9P5IOzK4k9cFfltMvA3bK6R8DzmmvimZmI2/GjBnMnTuXJ598EoCnnnqKd77znVx99dUAXHXVVRxyyCFAmnp98eLU2z1v3jxefPHFpusfN24c69at60rdhzQFQkTcAtySHz8ETKuRZz1wbAfqZmZW13CPwtt777355Cc/yaGHHsqoUaPYf//9ueSSS/jIRz7C5z//efr6+rj88ssBOP3005k5cybTpk1jxowZbLPNNk3XP2vWLI488kgmTpzY8X569UKvSn9/f1RfeMTDK81ssBUrVvDWt751pKsxYmq9fkmLI6K/WVlPgWBmVnIO9GZmJedAb2abjF7oah4J7b5uB3oz2ySMHTuWJ598crML9pX56MeOHdvyOnzhETPbJEyaNImBgQE2xzPpK1eYalVpAn2jmew8Wsds0zd69OiWr7C0uXPXjZlZyTnQm5mVnAO9mVnJOdCbmZWcA72ZWck50JuZlZwDvZlZyTnQm5mVnAO9mVnJOdCbmZVc00AvaaykuyTdI+k+SZ/J6d+U9LCkpfk2NadL0iWSVkpaJumAbr8IMzOrr8hcN88Dh0fEbyWNBhZKujE/9w8Rce2g/EcCU/LtD4BL872ZmY2Api36SH6bF0fnW6N5QmcCV+RydwA7SJrYflXNzKwVhfroJY2StBR4HLgpIu7MT52fu2cukjQmp+0CPFZVfCCnmZnZCCgU6CNiY0RMBSYB0yTtA5wL7AkcCIwH/jFnV61VDE6QNEvSIkmLNsf5pc3MhsuQRt1ExDPALcAREbEmd888D1wOTMvZBoBdq4pNAlbXWNfsiOiPiP6+vr6WKm9mZs0VGXXTJ2mH/Hgr4F3AA5V+d0kC3gssz0WuA07Oo28OAp6NiDVdqb2ZmTVVZNTNRGCOpFGkP4a5EXG9pPmS+khdNUuBj+b8NwBHASuB54BTO19tMzMrqmmgj4hlwP410g+vkz+AM9qvmpmZdYLPjDUzKzkHejOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSK3IpwbGS7pJ0j6T7JH0mp+8m6U5JD0q6RtLrcvqYvLwyPz+5uy/BzMwaKdKifx44PCL2A6YCR+RrwV4IXBQRU4CngdNy/tOApyPi94GLcj4zMxshTQN9JL/Ni6PzLYDDgWtz+hzSBcIBZuZl8vMz8gXEzcxsBBTqo5c0StJS4HHgJuA/gGciYkPOMgDskh/vAjwGkJ9/Ftipk5U2M7PiCgX6iNgYEVOBScA04K21suX7Wq33GJwgaZakRZIWrV27tmh9zcxsiIY06iYingFuAQ4CdpC0ZX5qErA6Px4AdgXIz28PPFVjXbMjoj8i+vv6+lqrvZmZNVVk1E2fpB3y462AdwErgAXAMTnbKcC8/Pi6vEx+fn5EvKZFb2Zmw2PL5lmYCMyRNIr0xzA3Iq6XdD9wtaT/CSwBLsv5LwOulLSS1JI/rgv1NjOzgpoG+ohYBuxfI/0hUn/94PT1wLEdqZ2ZmbWtSIu+tCaf86O6z6264Oghl2tUxsxspHgKBDOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSc6A3Myu5IteM3VXSAkkrJN0n6eycfp6kX0lamm9HVZU5V9JKSb+U9O5uvgAzM2usyBWmNgB/FxF3SxoHLJZ0U37uooj4QnVmSXuRrhO7N/BG4N8lvSUiNnay4mZmVkzTFn1ErImIu/PjdcAKYJcGRWYCV0fE8xHxMLCSGteWNTOz4TGkPnpJk0kXCr8zJ50paZmkb0jaMaftAjxWVWyAxn8MZmbWRYUDvaRtge8BfxsRvwEuBXYHpgJrgC9WstYoHjXWN0vSIkmL1q5dO+SKm5lZMYUCvaTRpCB/VUR8HyAifh0RGyPiJeDrvNI9MwDsWlV8ErB68DojYnZE9EdEf19fXzuvwczMGigy6kbAZcCKiPhSVfrEqmzvA5bnx9cBx0kaI2k3YApwV+eqbGZmQ1Fk1M3BwEnAvZKW5rRPAMdLmkrqllkF/CVARNwnaS5wP2nEzhkecWNmNnKaBvqIWEjtfvcbGpQ5Hzi/jXqZmVmH+MxYM7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSK3LClHXA5HN+VPe5VRccPYw1MbPNjVv0ZmYl50BvZlZyDvRmZiXnQG9mVnIO9GZmJedAb2ZWch5e2ePqDcv0kEwzK8otejOzknOgNzMruSLXjN1V0gJJKyTdJ+nsnD5e0k2SHsz3O+Z0SbpE0kpJyyQd0O0XYWZm9RVp0W8A/i4i3gocBJwhaS/gHODmiJgC3JyXAY4kXRB8CjALuLTjtTYzs8KaBvqIWBMRd+fH64AVwC7ATGBOzjYHeG9+PBO4IpI7gB0kTex4zc3MrJAh9dFLmgzsD9wJvD4i1kD6MwB2ztl2AR6rKjaQ0wava5akRZIWrV27dug1NzOzQgoHeknbAt8D/jYiftMoa420eE1CxOyI6I+I/r6+vqLVMDOzISoU6CWNJgX5qyLi+zn515UumXz/eE4fAHatKj4JWN2Z6pqZ2VAVGXUj4DJgRUR8qeqp64BT8uNTgHlV6Sfn0TcHAc9WunjMzGz4FTkz9mDgJOBeSUtz2ieAC4C5kk4DHgWOzc/dABwFrASeA07taI3NzGxImgb6iFhI7X53gBk18gdwRpv1MjOzDvGZsWZmJedAb2ZWcg70ZmYl50BvZlZyDvRmZiXnQG9mVnIO9GZmJedLCZZQvcsPgi9BaLY5covezKzkHOjNzErOXTcGuLvHrMzcojczKzkHejOzknOgNzMrOQd6M7OSc6A3Myu5IpcS/IakxyUtr0o7T9KvJC3Nt6OqnjtX0kpJv5T07m5V3MzMiinSov8mcESN9IsiYmq+3QAgaS/gOGDvXOZfJY3qVGXNzGzomgb6iLgVeKrg+mYCV0fE8xHxMOm6sdPaqJ+ZmbWpnT76MyUty107O+a0XYDHqvIM5DQzMxshrQb6S4HdganAGuCLOb3WRcSj1gokzZK0SNKitWvXtlgNMzNrpqVAHxG/joiNEfES8HVe6Z4ZAHatyjoJWF1nHbMjoj8i+vv6+lqphpmZFdBSoJc0sWrxfUBlRM51wHGSxkjaDZgC3NVeFc3MrB1NJzWT9B3gMGCCpAHg08BhkqaSumVWAX8JEBH3SZoL3A9sAM6IiI3dqbqZmRXRNNBHxPE1ki9rkP984Px2KmVmZp3jM2PNzErOgd7MrOQc6M3MSs6B3sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSq7pmbFmjUw+50c101ddcPQw18TM6nGL3sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSs6B3sys5JoGeknfkPS4pOVVaeMl3STpwXy/Y06XpEskrZS0TNIB3ay8mZk1V6RF/03giEFp5wA3R8QU4Oa8DHAk6YLgU4BZwKWdqaaZmbWqaaCPiFuBpwYlzwTm5MdzgPdWpV8RyR3ADpImdqqyZmY2dK1OgfD6iFgDEBFrJO2c03cBHqvKN5DT1rReRSubetMmQP2pE1opY2ZJpw/GqkZa1MwozZK0SNKitWvXdrgaZmZW0WqL/teSJubW/ETg8Zw+AOxalW8SsLrWCiJiNjAboL+/v+afgVm7vCdg1nqL/jrglPz4FGBeVfrJefTNQcCzlS4eMzMbGU1b9JK+AxwGTJA0AHwauACYK+k04FHg2Jz9BuAoYCXwHHBqF+ps1lXeC7CyaRroI+L4Ok/NqJE3gDParZSZmXWOz4w1Mys5B3ozs5JzoDczKzkHejOzkvPFwc06xBdKt17lFr2ZWcm5RW82gjxm34aDA73ZJsZ/DjZU7roxMys5B3ozs5Jz143ZZsJdPpsvt+jNzErOgd7MrOTcdWNmdbXa3eOTx3qLA72Z9QQfQ+geB3oz22R5j6MYB3ozswKG80+l03s3bQV6SauAdcBGYENE9EsaD1wDTAZWAR+IiKfb2Y6ZmbWuE6NupkfE1Ijoz8vnADdHxBTg5rxsZmYjpBvDK2cCc/LjOcB7u7ANMzMrqN1AH8BPJC2WNCunvT4i1gDk+51rFZQ0S9IiSYvWrl3bZjXMzKyedg/GHhwRqyXtDNwk6YGiBSNiNjAboL+/P9qsh5mZ1dFWiz4iVuf7x4EfANOAX0uaCJDvH2+3kmZm1rqWA72kbSSNqzwG/gRYDlwHnJKznQLMa7eSZmbWuna6bl4P/EBSZT3fjogfS/oFMFfSacCjwLHtV9PMzFrVcqCPiIeA/WqkPwnMaKdSZmbWOZ690sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSs6B3sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSs6B3sys5BzozcxKzoHezKzkHOjNzEqua4Fe0hGSfilppaRzurUdMzNrrCuBXtIo4H8DRwJ7AcdL2qsb2zIzs8a61aKfBqyMiIci4gXgamBml7ZlZmYNdCvQ7wI8VrU8kNPMzGyYKSI6v1LpWODdEfEXefkkYFpE/E1VnlnArLy4B/DLOqubADwxxCq0UmY4t9Xr9RvObfV6/YZzW71ev+HcVq/Xbzi31ajMmyKir+kaIqLjN+AdwL9VLZ8LnNviuhYNR5nh3Fav18/vhd+Lkd5Wr9dvU3gvqm/d6rr5BTBF0m6SXgccB1zXpW2ZmVkDW3ZjpRGxQdKZwL8Bo4BvRMR93diWmZk11pVADxARNwA3dGBVs4epzHBuq9frN5zb6vX6Dee2er1+w7mtXq/fcG6r1fq9rCsHY83MrHd4CgQzs5JzoDczK7mu9dHba0naEZgCjK2kRcStI1ejTYukMRHxfLM0s27YlL9/btEPE0l/AdxKGon0mXx/XoFyr5f0nnzbuUD+t0i6WdLyvLyvpP9esI4HS9omPz5R0pckvalO3ivz/dlF1l1VbpSkbw2lTJXbC6YN3uY7JX1I0smVW4vbb7ad17wX9d4fSeMb3Qpu702S3pUfbyVpXIEyw/Je9DJJX5C0dwtFW/r+tULSaElnSbo23/5G0uhW19dzgT4Htssk3ZiX95J0WoP86yT9pt6thXLrmpT7Z0nb5Q/iZklPSDqxwEs7GzgQeCQipgP7A2sbFZD0AeAu4FjgA8Cdko5psp2vk05QexEgIpaRzmMo4lLgOUn7AR8HHgGuqJP37flP4COSdiwaqCJiI9CXz68oRNIbJL0d2ErS/pIOyLfDgK2blL0S+AJwCOn9PxDob1Lm7PwZK38X75b0JwWqekqNtA/XybsYWJTv1wL/D3gwP17cbEOSTgeuBb6WkyYB/7dJmcLvRau/q6ryQ/odt1GmlYbNA8BsSXdK+qik7Ztso+XvXxt1vBR4O/Cv+XZATmtNu2dcdfoG3EgKavfk5S2BewuU+yzw18A4YDvgr4CPd6F+S/P9+4A5wPhKXZuU+0WlPDCmel0NytwD7Fy13NdsW1XbWTK4zgXqeHe+/yfgtOq0GnnPAlYAzwMPVd0eBh5qsp2vkU6q+xTwscqtQf5TgAXAunxfuV0HvL/JtlaQR5cN4TOufPfenbexX733Iec7Hvgh8HTOX7ktAP69yba+ChxVtXwk8MUi30PgdYM+54a/kxbfi5Z+V638jlss81PSJIrV78Pygq9tD+ACUoPm28D0Tn//Wq1jrd95s99+o1sv9tFPiIi5ks6Fl0++2lig3Lsj4g+qli+VdCfwzx2uX2X36SjgOxHxlKQi5QYk7UBqdd0k6WlgdZMyW0TE41XLT9J8L+wJSbsDAZD3ANYUqSCwLr/vJwJ/pDTddM3dxYi4BLhE0qWkYPVH+albI+KeJttZnW9bkAJIQxExB5gj6c8j4nvFXsrLlgNvoPh7AFD5QI8CLo+Ie9T4Q/55Xv8E4ItV6euAZU22dWBEfLSyEBE3SvofBer4fES8UKmWpC3Jn3kDrbwXrf6uWvkdt1Jm64i4a9DHs6FJmcpU6nvm2xOkRtXHJP1lRLxqD7jN71+rddwoafeI+I9c3zcDReJgTb0Y6P9L0k68EqgOAp4tUG6jpBNIUyIHqZXV8hvTwA8lPQD8DvhrSX3A+maFIuJ9+eF5khYA2wM/blLsRkn/BnwnL3+Q5iehnUE6wWJPSb8itbCLdC1V1v8hUmv+PyX9HvD5JmUeAL4FfJ8UIK+U9PWI+Eq9AhHxGQClPuWIiN8WrN/Nkr7EK38qPwU+GxGNvh8TgPsl3UXa+6jU4c8alFks6SfAbsC5uZ4v1cscEY+QWoXvKPYyXuWJvBv/LdL39kTSH3ozP5X0CVJ3wh+TWt0/rJVR0g/zuscx9Pei1d9VK7/jVsoMuWGTv0N/CswHPhcRd+WnLpRUb3JFIuJ7ko4G9ubVAyo+2+k6An8PLJD0UF6eDJzapEx9re4KdOtG6ou6jfQB30bqu9y3QLnJwDzSv/NaUst5cpfquCMwKj/eGnhDl7ZzIfB+4EvARaTuogsLlt0GGDcMn9cyYJtB213WpMw+wBJScHyE1Ce9d4FtfY90IPvN+fZp4PtNyhxa69akzBb5e7hDXt6p0XcQWJjv1wG/qbqtA37TZFvjgS/n92NJfjy+wHuxBXA68F1SX/3p1OmWqfceFHwvWvpdVf2Onyn6O27lt5+/B/8OPAf8ClhImtGxXn6Rugy3rvP89g3KfpV0zOqx/N27F7iswHsxpDrmMseSusr2zfW9ETig2bbq3XryzNi8G7oH6UP5ZUS8OMJVehVJ+5CunFX9r17voGU727k7Ig4YlLYsIvZtUGYM8OekH+jLe2zRoNUhaWFEHCJpHa/e/VcqGts1KHsvqfthfV4eSzpO8LYGZX4OfDIiFuTlw0gtq3fWK5PzLY2Iqc3SWiVpz4h4QNIBtZ6PiLs7sZ06294OeCkK7t0ojY5aH+ngdqUrYkxEPNegzIUR8Y/N0johfw/OJB3nWEcanfKVyvekRv4tgINIgw8K/fZzmWMidfdsQ+rqXFegbosj4u0tvKZlEbFv1f22pIZGwwP1kkZFxMYh1rGyjUOAz5G6BD8Rr+5GK6wXu24gHbiYTKrfAZKaBtLchXI6rw1wH+lkxSR9GjiMFOhvIB08W0j90SmtbOOvSLvib5ZU3cc7jtTSaWQeqUW0mKrd80Yi4pB837S/vIbLSaOBfpCX3wtc1qTMNpUgn7d7S/4RNPM7SYdExEJIw0FJXWiv0eKf18dI10j4Yo3nAji8QB2HRNLbSN+d8Xn5CeCUiFjepOjNwLuAyh/DVsBPgEZ/ln8MDA7qR9ZIq67fWOA0Xttd0ex3dQVpr+Zzefl44EpSS/U1IuIlSV+MiHcAhSZAzGXOBOZGxH8VKZPdIenAiPjFEMrAK9+15yS9kdTFtluBcg9L+jFwDam7qIhK99jRwFcjYp6k84ZS2Wo916JXGgK2O2lUQeXFRkSc1aTcz4GfkQLcy32I0drBk0bbuZc0CmNJROwn6fXA/4mIP+3gNrYndQ/9L6D6wurrIuKpJmWXR8Q+napLEbkFfAgpiN4aEUua5P8BcDfphw+pX7o/It7bpNxU0kinynC4p0lBsdkBz541HHs31Q0H4D+qnhoH3BYRdY/hSPou6TjMh0gjcE4AVkREw/MnJN0TEfs1Sxv0/GdIXYHfj4KBSdKnSAH4GuDlYN/odyLpftJew6pcpvLnX3dPuWpbXwFmkK6JHaTf/qealNuKdEzgOFL31PXA1ZUGS50y15O6ed5FGmb5O+CuRu9fwzr0YKBfAexV9IOuKtexXfgm2/lFRBwoaTEwnbRbujwiWjkBo+MkzSbtIt870nUZTNKVEXGSpI+R9rwqfw4/BT4TEU83KT8GOIbUENiBtOcSjbql2qjrO3nt3mE3uueGHBBzntuAv6l0JymN8/6X3CIenLedhsOSiNi/qithNOmiQg33biR9k9QSvSMv/wHpT/mvG5RZRzrGs4E0wKFI1+HDNZIjIt7coEzNkwAjHVQvJH8Xx0bjgQC1yu1IOg5zQkSMapBva+AI0vDSByVNBN4WET8ZyvYqerHrppUhYADXSzoq0vTI3fQLpWGSXyftPfyW1K84opROxniJ9Jmemo/WP0/B1sowqZxkdQrpT1K80q1SZIzqPNLBvbtJrZ2uqLdXSQe756o8lFuK1Xs3tYLXYH8LfFdSZYjuRNKoqVoiIlZJOmPwE5LGNwn2lT7yZ/Kxqf8k/QHWlPd4gzQs92RJj+blNwH3N9gOETFO6WS7V00T0qRMka6TwWUeyX3fUyLi8tztu22RsoMbAEW6lXO+Q0mfz5Gkc0g+0KSOz5FGslWW1zD0mPjK9nulRa9XDwGbSgqeRYeAVbcGnid9OZu2Blqs55WkqQx+Rmp1bNcLXQdK4/Lr7tEMpbXSLZLOIp1w82ZeHagrn1XdVlguPyzdUq3uVba4rR1JI4le7voCzmu2d5PLjuaVA5cP1DtwKen6iHhPbv0Gr/5Tbdb6/QvSaKe3Ad8kBcRPRcTX6uSv2Vqu2ljd72He1tmks3yXkg7O/jwiZjQoszXp2MrvRcQsSVOAPSLi+gZlPk06I3iPiHhL7m//bkQc3KjubXQrP5zLzAWuG+LxhI7opUB/KOkLeCHp9PuXnyINKWx6tLlWayAiftrheh5O+lH+ISlgLSX1S3+5k9tpoV6vGaHTqyRdGhF/1UK5YemWyv3SZ+VW1LDQEEfd5DJDGv1V3UiJiAcKbqN6FFfl5LludZfdS5qW4Y6ImCppT1KXXr09FSRdQ9qzPjki9sn94bc36saVtJQ0BcndEbF/Tms4mi3nabVbebuIaDptRDf1TNdNJSBLGj04OOcPr6F6rQHSgZNO1nO+pJ+SvpDTgY+SRiSMaKAHds593zVFxJeGszKNtBLks0OAD+cWUse7pdTeiUWtbrOlUTdqbfTX5aT38CtKZ1ouIQX9Rt/dIY/iasP6iFgvCaVZIR+QtEeTMrtHxAclHQ8QEb+Tmp6q/kJEhKTKCUxFRnxB693KL+Rus6GOXOqYngn0am9IIbwyadgdETG90hroQj1vJnUR3U7qvjkwXj1NwUgZRdqtLjQfwybqyC6v/wu8sldZPQKoktYNXyPN81M96mY2jYdJQjooXRn9dary6K9GBeo0UvahcSNlUkQcUeSFdEAr04S8kBuClaC9O83/kOZK+hqwg9LkcB8hHXOrqQMNgCtJI5feTdXIpSZlOqpnAj1pUqEbaWFkQNZKa6AVy0jDnfYhtXSekXR7RNQczz2M1nRjd7qXdPs4Q7t7lS1q+ZyCSOPIN+Run8dJXYl1tdhI+bmktw3HKK5obZqQT+c8u0q6CjiY+jOGVrxEev2/Ad4C/FNE3NQgf7sNgN+PiGMlzYyIOZK+TZqmfNj0TKDPw5SeJZ1Y0YpWWgNDFhH/DUDprLhTSbvDbwDGdHpbQ1Tmlvyw6MBeZStaHXWzqIXRX4UbKVWjZ0ZkFNcQjq2dDPyINA3EQ8DZEfFEkzLjSCeBPUWaw6fhYIoONACGNHKpG3rmYGwn5QO72wM/jogXOrxVCb8VAAADG0lEQVTuM0kHYt9OmqelcnCr6BlvXVFgmJw1oTbGm7ewrbbOKRi0rskMYfRXVSPl70nzNL2mkdLO6Jnh1M7gCEn7koY8/jkwEBHvqpOv5RPOcvkhjVzqhlIG+m6S9A+k4L44IppOh2pWi9LZmUeS5jQffE5B3TM7VWcenqpydefj6dVGSruU5vmpPu7wu4jYs0C5N5CmZDiONAFgzb2UdhsAwzlyqW4dHOjNhl+r5xTkvuuKWnP41D1jtYyNlBrHHRY2O+6QW+gfJF3I51rgmohoeDJXm3X8Ma+MXKqenqXWnErdqYMDvdnIaeOcgq1I3QmHkAL+z4BLo87skGUl6SLSHsrzpOMot5LG0dcdHCHpAtJcM0uHqY7DPv/Ua+rgQG+26ZE0lzRq5KqcdDxp/vyGp9aXVZHjDiNluE70a1gHB3qzTY9anAytbHr5uMOgkUtTSKOCRmT+qZ4ZXmlmQ7JE0kHx6tkhuzUEtJdtRboCWy8ed3jPSFegwi16s01QnndlD+DRnPR7pLMtX6J3Ziu1HuFAb7YJ2lTGuVtvcKA3Myu5LUa6AmZm1l0O9GZmJedAb9YBkg5TuqCzWc9xoDdrQZ5fxWyT4EBvmx1JH89zzSDpIknz8+MZkr4l6XhJ90paLunCqnK/lfRZSXcC75B0hKQHJC0E3j8yr8asOQd62xzdSjqbEtJFordVutD2IcCDpItJHE662PqBkioXm9gGWB7p+sWLSHPB/2le1xuGr/pmQ+NAb5ujxcDbJY0jnZJ+Oyng/yHwDHBLRKzNZ1peBfxRLreRNK84wJ7AwxHxYL5Y9LeG8wWYDYUDvW12IuJFYBVpEqyfk2Z+nA7szitnmtayPiI2Vi37JBTbJDjQ2+bqVtJMh7eSAv1HSVcnugM4VNKEfMD1eNJVnwZ7ANgtX4waWr8EplnXOdDb5upnwETS3OW/BtaTZj1cA5wLLADuAe6OiHmDC+d532cBP8oHYz3lgPUsT4FgZlZybtGbmZWcA72ZWck50JuZlZwDvZlZyTnQm5mVnAO9mVnJOdCbmZWcA72ZWcn9f1Tcx7lgnE7SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot most frequent words\n",
    "\n",
    "# https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n",
    "all_words = df['text'].str.split(expand=True).unstack().value_counts()\n",
    "all_words = all_words.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 25 more frequent words\n",
    "all_words[:25].plot.bar(x='word')\n",
    "all_words[:25].T\n",
    "\n",
    "#lots of \"rubbish\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text data for topic modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will:\n",
    "1. tokenise\n",
    "2. lower case\n",
    "3. remove stopwords\n",
    "4. remove non-alphabetic tokens (i.e., punctuations and numbers)\n",
    "5. lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipe = combine_functions(sent_tokenise\n",
    "                                       ,remove_punctuation\n",
    "                                       ,word_tokenise\n",
    "                                       ,to_lower\n",
    "                                       ,POS_tagging\n",
    "                                       ,lemmatise\n",
    "                                       ,fix_neg_auxiliary\n",
    "                                       ,lambda s: [[re.sub(r'\\d+','',x) for x in subs] for subs in s]\n",
    "                                       ,lambda x : remove_stopwords(x, extra_stopwords = [\n",
    "                                           'x', \"'s\", \"not\", 'us', 'no', 'many', 'much', 'one', 'put', 've',\n",
    "                                           'wo', 'even', 'first', 'may', 'late', 'come', 'iam', 'ive', 'ill',\n",
    "                                           'good', 'bad', 'great', 'sure', 'best', 'quite', 'per', 'due', 'always',\n",
    "                                           'say', 'want', 'm', 'ever', 'every', 'really', 'well', 'little', 'd',\n",
    "                                           'also', 'get', 'would', 'could', 'like', 'go', 'lot', 'make'])\n",
    "                                       ,flattenIrregularListOfLists\n",
    "                                       ,lambda x: list(filter(None, x))\n",
    "                                      )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>[wow, love, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>[crust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>[stop, bank, holiday, rick, steve, recommendation, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>[selection, menu, price]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "                                                text_lemmas  \n",
       "0  [wow, love, place]                                        \n",
       "1  [crust]                                                   \n",
       "2  [tasty, texture, nasty]                                   \n",
       "3  [stop, bank, holiday, rick, steve, recommendation, love]  \n",
       "4  [selection, menu, price]                                  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lemmas'] = df['text'].apply(lambda x: preprocessing_pipe(x))\n",
    "\n",
    "# check some texts\n",
    "df[['text', 'text_lemmas']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>food</td>\n",
       "      <td>place</td>\n",
       "      <td>service</td>\n",
       "      <td>back</td>\n",
       "      <td>time</td>\n",
       "      <td>eat</td>\n",
       "      <td>love</td>\n",
       "      <td>wait</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>dont</td>\n",
       "      <td>...</td>\n",
       "      <td>think</td>\n",
       "      <td>taste</td>\n",
       "      <td>im</td>\n",
       "      <td>experience</td>\n",
       "      <td>pretty</td>\n",
       "      <td>minute</td>\n",
       "      <td>staff</td>\n",
       "      <td>price</td>\n",
       "      <td>star</td>\n",
       "      <td>server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123</td>\n",
       "      <td>110</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1        2     3     4    5     6     7           8     9  \\\n",
       "word   food  place  service  back  time  eat  love  wait  restaurant  dont   \n",
       "count  123   110    84       60    55    31   30    29    28          28     \n",
       "\n",
       "        ...       15     16  17          18      19      20     21     22  \\\n",
       "word    ...    think  taste  im  experience  pretty  minute  staff  price   \n",
       "count   ...    22     21     21  21          19      19      19     19      \n",
       "\n",
       "         23      24  \n",
       "word   star  server  \n",
       "count  18    18      \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-plot most frequent words\n",
    "\n",
    "all_lemmas = df['text_lemmas'].apply(list2string).str.split(expand=True).unstack().value_counts()\n",
    "all_lemmas = all_lemmas.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 25 more frequent lemmas\n",
    "all_lemmas[:25].plot.bar(x='word')\n",
    "all_lemmas[:25].T\n",
    "\n",
    "# much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling with Latent Dirichlet Analysis (LDA)\n",
    "\n",
    "LDA is a topic discovery technique. It is a generative statistical topic model used to find accurate sets of topics within a given document set. The model assumes that text documents are comprised of a mixture of topics, and each topic is represented as the probability that each of given set of terms will occur. From there, using probability distributions the model can determine which topics are in a given document and which words are in a given topic based on word prevalence across topics and topic prevalence across document. A unique feature of LDA models is that topics are not required to be distinct, and words may occur in multiple topics\n",
    "\n",
    "Ref: \n",
    "\n",
    "https://medium.com/square-corner-blog/topic-modeling-optimizing-for-human-interpretability-48a81f6ce0ed\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note**: As of today, September 2018, there seems to be a bug introduced in a recent version of ```gensim```, the way it interacts with ```numpy``` which is used for all the computations. Downgrading to gensim 3.1.0 seems to solve the problem (ref: https://github.com/RaRe-Technologies/gensim/issues/2115).\n",
    "To do this please type ```$ pip install gensim==3.1.0``` in your Terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Create a dictionary containing the number of times a word appears in the corpus of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary = association word to numeric id\n",
    "# assigning a unique integer id to each unique word while also collecting word counts and relevant statistics. \n",
    "dictionary = corpora.Dictionary(df['text_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640\n"
     ]
    }
   ],
   "source": [
    "# what's the vocabulary size?\n",
    "print(len(dictionary.token2id.keys()))\n",
    "\n",
    "# take a look (first 25 entries in the dictionary)\n",
    "#for k, v in dictionary.token2id.items(): \n",
    "#    print(\"{} : {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Filter out words that occur too frequently or too rarely.\n",
    "\n",
    "When dealing with a bigger corpus than the one used in his example, you may want to further clean the text data by excluding words that occur in:\n",
    "- less than X texts (absolute number) or (infrequent words)\n",
    "- more than 0.p documents (fraction of total corpus size, not absolute number) (too frequent words).\n",
    "- after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wordcount = 10\n",
    "max_freq = 0.6\n",
    "\n",
    "dictionary.filter_extremes(no_below=min_wordcount,\n",
    "                            no_above=max_freq,\n",
    "                            keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our dictionary size has become now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary.token2id.keys()))\n",
    "#...  too harsh filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) From texts as documents to Document Term Matrix\n",
    "\n",
    "Transform the collection of texts to a numerical form: For each text, report how many many times each occurring word appears. I.e., Convert the list of documents (corpus) into a Document Term Matrix using the dictionary prepared above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in df['text_lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "993\n",
      "[[(0, 1), (1, 1)], [], [(2, 1)], [(0, 1)], [(3, 1), (4, 1), (5, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(type(bow_corpus))\n",
    "print(len(bow_corpus))\n",
    "print(bow_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 text text_lemmas\n",
      "1  Crust is not good.  [crust]   \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at how the 1st text looks like: [(word_id, count), ...]\n",
    "\n",
    "print( df[['text', 'text_lemmas']][1:2] )\n",
    "print( bow_corpus[1] )\n",
    "\n",
    "for i in range(len(bow_corpus[1])):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_corpus[1][i][0],\n",
    "          dictionary[bow_corpus[1][i][0]], \n",
    "          bow_corpus[1][i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Find the best number of topics\n",
    "\n",
    "#### Perplexity\n",
    "\n",
    "Perplexity is a standard measure for estimating the performance of a probabilistic model: it measures how well the probabilistic model predicts a sample. The perplexity of a set of test words, is defined as the exponential of the negative normalized predictive likelihood under the model. \n",
    "\n",
    "One should expect \"in-sample\" perplexity to improve with more topics, but that the improvement would level off as the model captures all but the most trivial structures in the data. So the ideal number of topics should be the poin where perplexity starts to level off. \n",
    "\n",
    "Ref: \n",
    "\n",
    "https://docs.google.com/viewer?a=v&pid=forums&srcid=MDEwMDM0NjcxOTk3Njc0MTA0MjMBMTQzMzY3Nzc1NTMzNDgyNjIyMzEBZnBOMFVLSG9BZ0FKATAuMwEBdjI&authuser=0\n",
    "\n",
    "https://groups.google.com/forum/#!topic/gensim/BDuOnCGpgOs\n",
    "\n",
    "http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
    "\n",
    "https://groups.google.com/forum/#!topic/gensim/TpuYRxhyIOc\n",
    "\n",
    "\n",
    "**Important**: However, please note that it has been shown that perplexity doesn't correlate well with human judgements of topic coherence. \n",
    "\n",
    "Other coherence measures have been suggested that have performed better. Example: https://www.kdnuggets.com/2016/07/americas-next-topic-model.html\n",
    "\n",
    "\n",
    "TODO: turn this into a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# (i) divide corpus in training and test corpus. The test corpus will be used to calculate perplexity\n",
    "    \n",
    "shuffle(bow_corpus)\n",
    "\n",
    "train_corpus, test_corpus = bow_corpus[:800], bow_corpus[800:]\n",
    "\n",
    "# Number of words in the training set and in the test set\n",
    "print(sum(cnt for document in train_corpus for _, cnt in document))\n",
    "print(sum(cnt for document in test_corpus for _, cnt in document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (10, 1)], [(39, 1), (76, 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of topics :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-word likelihood bound      -5.996452343016863\n",
      "perplexity : exp(-bound)                              402.0001022679453\n",
      "elapsed time: 3.208\n",
      " \n",
      "number of topics :  3\n",
      "per-word likelihood bound      -6.213694191823403\n",
      "perplexity : exp(-bound)                              499.54325544332806\n",
      "elapsed time: 3.289\n",
      " \n",
      "number of topics :  4\n",
      "per-word likelihood bound      -6.342112111449242\n",
      "perplexity : exp(-bound)                              567.994713494157\n",
      "elapsed time: 3.361\n",
      " \n",
      "number of topics :  5\n",
      "per-word likelihood bound      -6.477943900724252\n",
      "perplexity : exp(-bound)                              650.6318064547115\n",
      "elapsed time: 3.438\n",
      " \n",
      "number of topics :  7\n",
      "per-word likelihood bound      -6.497502271632354\n",
      "perplexity : exp(-bound)                              663.4823629845866\n",
      "elapsed time: 3.480\n",
      " \n",
      "number of topics :  8\n",
      "per-word likelihood bound      -6.45383523846666\n",
      "perplexity : exp(-bound)                              635.1335161641691\n",
      "elapsed time: 3.462\n",
      " \n",
      "number of topics :  9\n",
      "per-word likelihood bound      -6.578909688144922\n",
      "perplexity : exp(-bound)                              719.7541448021694\n",
      "elapsed time: 3.484\n",
      " \n",
      "number of topics :  10\n",
      "per-word likelihood bound      -6.484565182830712\n",
      "perplexity : exp(-bound)                              654.954117020161\n",
      "elapsed time: 3.492\n",
      " \n",
      "number of topics :  15\n",
      "per-word likelihood bound      -6.24314895182848\n",
      "perplexity : exp(-bound)                              514.4760230859339\n",
      "elapsed time: 3.421\n",
      " \n",
      "number of topics :  20\n",
      "per-word likelihood bound      -6.4240820862849555\n",
      "perplexity : exp(-bound)                              616.5146504831371\n",
      "elapsed time: 3.579\n",
      " \n",
      "number of topics :  25\n",
      "per-word likelihood bound      -6.162228438854218\n",
      "perplexity : exp(-bound)                              474.48425673278547\n",
      "elapsed time: 3.391\n",
      " \n",
      "number of topics :  30\n",
      "per-word likelihood bound      -6.406563994089763\n",
      "perplexity : exp(-bound)                              605.8085391120372\n",
      "elapsed time: 3.644\n",
      " \n",
      "number of topics :  35\n",
      "per-word likelihood bound      -6.267290265758832\n",
      "perplexity : exp(-bound)                              527.0472830946286\n",
      "elapsed time: 3.610\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# (ii) loop on training set for several numbers of topics: \n",
    "topics_seq = list((2,3,4,5,7,8,9,10, 15, 20, 25, 30, 35))\n",
    "\n",
    "results_perplexity = {}\n",
    "for topic_n in topics_seq:\n",
    "    start_time = time.time()\n",
    "    # run model\n",
    "    print('number of topics :  %d' % topic_n)\n",
    "    \n",
    "    model = models.LdaModel(corpus=train_corpus\n",
    "                             , num_topics=topic_n\n",
    "                             , id2word=dictionary\n",
    "                             , passes = 20  # as we have a small corpus\n",
    "                             , eta = 0.01 # topics are known to be word-sparse, the Dirichlet parameter of the word distributions is set small (e.g., 0.01), in which case learning is efficient.\n",
    "                             , alpha = 0.1    #believed that each document is associated with few topics\n",
    "                             , random_state = 1\n",
    "                             )\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # perplexity on hold-out test data\n",
    "    log_perplexity = model.log_perplexity(test_corpus)              # this is actually per-word likelihood bound\n",
    "    perplexity_test = np.exp(-log_perplexity.astype(np.float64))    # https://stats.stackexchange.com/a/324243\n",
    "    \n",
    "    print('per-word likelihood bound     ', log_perplexity)\n",
    "    print('perplexity : exp(-bound)                             ', perplexity_test)\n",
    "    print('elapsed time: %.3f' % elapsed)  \n",
    "    print( ' ')\n",
    "    results_perplexity[topic_n] = perplexity_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 402.0001022679453,\n",
       " 3: 499.54325544332806,\n",
       " 4: 567.994713494157,\n",
       " 5: 650.6318064547115,\n",
       " 7: 663.4823629845866,\n",
       " 8: 635.1335161641691,\n",
       " 9: 719.7541448021694,\n",
       " 10: 654.954117020161,\n",
       " 15: 514.4760230859339,\n",
       " 20: 616.5146504831371,\n",
       " 25: 474.48425673278547,\n",
       " 30: 605.8085391120372,\n",
       " 35: 527.0472830946286}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7debcecc18>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of perplexity versus number of topics\n",
    "plt.plot(results_perplexity.keys(), results_perplexity.values(), 'r--',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFfVJREFUeJzt3X2UnnV95/H3hyAFeaxN2CrPCkYiW4WloKuWKNQD9AhuixUsdbGUsLbgulh7cGuVxdYerdanpZW0goiVB23V1I2FPcpUYMtTRSIB42YRJUBFFLBZXCTy3T/uK51xmPnNnZBr5s7k/TpnTu7r8f7O98zMJ9fverhTVUiSNJ3t5roASdJoMygkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEhPQZKxJL+9BfazOsnSLVCStMUZFJqXktyd5EdJ1if5bpKLk+wy13VNp6qeX1VjAEnOS/LJOS5J+lcGheazV1XVLsBhwC8Cb9+UjZNs30tV0lbGoNC8V1X3Al8EDkmye5KPJbk/yb1J/ijJAoAkpyW5PskHkvwAOG/CvI8keSTJN5IcPd17JfmtJHcmeSjJVUn26+b/+yQPJtmnm35BkoeTPK+bvjvJMUmOBf4r8NruaOi2JK9J8k+T3uctST7XS8OkSQwKzXvdH+fjgVuBS4ANwIHAocArgYnnGI4E7gL2BP540ryFwDuBv03yjCne59UM/sj/KrAIuBa4DKCq/hdwIXBJkp2AS4G3V9U3Ju6jqv4eeDdwRVXtUlUvAFYAByQ5eMKqp3b7kHpnUGg++1ySh4HrgH8A/go4DnhzVf3fqnoA+ABw8oRt7quqj1TVhqr6UTfvAeCDVfV4VV0BrAF+ZYr3OxP4k6q6s6o2MPiD/8KNRxXAecDuwE3AfcAFw3wTVfUYcAWDcCDJ84H9gS8Ms730VBkUms9eXVV7VNV+VfU7wL8Bngbc3w37PMzgf/l7Ttjmnin2c2/99NMzvw08a4r19gM+NGHfPwAC7AVQVY8DHwcOAd5fm/ZEzkuA1yUJ8JvAlV2ASL0zKLQtuQd4DFjYBcgeVbVbVT1/wjpT/fHeq/sDvdG+DI4Iptr/mRP2vUdV7dQNO5FkLwZDVxcD70/yM9PU+aQaquoG4MfAy4DX4bCTZpFBoW1GVd0PXM3gj/RuSbZL8pwkR82w6Z7Am5I8LclrgIOBlVOs91Hgbd3QEN2J89d0r8PgaOJjwOnA/cC7pnm/7wL7J5n8+/kJ4L8DG6rquhlqlrYYg0LbmtcDOwB3AA8BnwGeOcM2NwIHAQ8yOMF9UlV9f/JKVfVZ4D3A5Ul+CNzO4JwIwJsYDH39YTfk9AbgDUleNsX7fbr79/tJvjph/qUMhq08mtCsih9cJE0vyWnAb1fVS0eglp0YnFg/rKr+91zXo22HRxTS1uONwM2GhGZbb0GR5KIkDyS5fZrlSfLhJGuTrEpyWF+1SFu7JHcD/xl4yxyXom1Qb0NPSX4JWA98oqoOmWL58cDZDG6EOhL4UFUd2UsxkqTN1tsRRVV9hcF15NM5kUGIVHfp3x5JZjqpKEmaZXP50LO9+Ombm9Z18+6fvGKSZcAygB133PHf7bvvvrNS4Kh74okn2G47TzOBvZjIXoyzF+O++c1vPlhVizZn27kMikwxb8pxsKpaDiwHWLx4ca1Zs6bPurYaY2NjLF26dK7LGAn2Ypy9GGcvxiX59uZuO5dRuw7YZ8L03kx9t6skaQ7NZVCsAF7fXf30IuCR7s5ZSdII6W3oKcllwFJgYZJ1DJ5x8zSAqvoog0cgHA+sBR5lcKeqJGnE9BYUVXXKDMsL+N2+3l+StGV4OYAkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqSmXoMiybFJ1iRZm+TcKZbvm+SaJLcmWZXk+D7rkSRtut6CIskC4ALgOGAJcEqSJZNWeztwZVUdCpwM/Hlf9UiSNk+fRxRHAGur6q6q+jFwOXDipHUK2K17vTtwX4/1SJI2w/Y97nsv4J4J0+uAIyetcx5wdZKzgZ2BY6baUZJlwDKARYsWMTY2tqVr3SqtX7/eXnTsxTh7Mc5ebBl9BkWmmFeTpk8BPl5V70/yYuDSJIdU1RM/tVHVcmA5wOLFi2vp0qV91LvVGRsbw14M2Itx9mKcvdgy+hx6WgfsM2F6b548tHQ6cCVAVf0jsCOwsMeaJEmbqM+guBk4KMkBSXZgcLJ6xaR1vgMcDZDkYAZB8b0ea5IkbaLegqKqNgBnAVcBdzK4uml1kvOTnNCt9hbgjCS3AZcBp1XV5OEpSdIc6vMcBVW1Elg5ad47Jry+A3hJnzVIkp4a78yWJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpKZegyLJsUnWJFmb5Nxp1vn1JHckWZ3kU33WI0nadNv3teMkC4ALgF8G1gE3J1lRVXdMWOcg4G3AS6rqoSR79lWPJGnz9HlEcQSwtqruqqofA5cDJ05a5wzggqp6CKCqHuixHknSZhjqiCLJ+4CLq2r1Jux7L+CeCdPrgCMnrfPcbv/XAwuA86rq76d4/2XAMoBFixYxNja2CWXMX+vXr7cXHXsxzl6MsxdbxrBDT98AlifZHrgYuKyqHplhm0wxr6Z4/4OApcDewLVJDqmqh39qo6rlwHKAxYsX19KlS4cse34bGxvDXgzYi3H2Ypy92DKGGnqqqr+qqpcArwf2B1Yl+VSSlzc2WwfsM2F6b+C+Kdb5fFU9XlXfAtYwCA5J0ogY+hxFd3L6ed3Xg8BtwDlJLp9mk5uBg5IckGQH4GRgxaR1Pge8vNv/QgZDUXdt0ncgSerVsOco/gx4FfBl4N1VdVO36D1J1ky1TVVtSHIWcBWD8w8XVdXqJOcDt1TVim7ZK5PcAfwEeGtVff+pfUuSpC1p2HMUtwNvr6pHp1h2xHQbVdVKYOWkee+Y8LqAc7ovSdIIGnbo6Tcmh0SSLwEMcVJbkrQVax5RJNkReDqwMMnPMn4l027As3quTZI0AmYaejoTeDODUPjqhPk/ZHDXtSRpnmsGRVV9CPhQkrOr6iOzVJMkaYTMNPT0iqr6MnBvkl+dvLyq/ra3yiRJI2GmoaejGFwS+6oplhVgUEjSPDfT0NM7u3/fMDvlSJJGzVCXxya5NMnuE6b323h5rCRpfhv2PorrgBuTHJ/kDOB/Ah/sryxJ0qgY6s7sqrowyWrgGgbPeTq0qv6518okSSNh2KGn3wQuYvD02I8DK5O8oMe6JEkjYthnPf0a8NLuE+guS/JZ4BLghb1VJkkaCcMOPb160vRNSaZ9GKAkaf4YdujpuUm+lOT2bvoXgN/vtTJJ0kgY9qqnvwTeBjwOUFWrGHwQkSRpnhs2KJ4+4cOKNtqwpYuRJI2eYYPiwSTPYfDYDpKcBNzfW1WSpJEx7FVPvwssB56X5F7gW8CpvVUlSRoZw171dBdwTJKdge2q6l/6LUuSNCpmesz4lJ9lnQw+6K6q/qyHmiRJI2SmI4pdZ6UKSdLImukx4/9ttgqRJI2mYW+4e3aSv0vyvSQPJPl8kmf3XZwkae4Ne3nsp4ArgWcCzwI+DVzWV1GSpNExbFCkqi6tqg3d1yfp7qmQJM1vw95HcU2Sc4HLGQTEa4H/keQZAFX1g57qkyTNsWGD4rXdv2dOmv9bDILD8xWSNE/NGBRJtgNOrarrZ6EeSdKImfEcRVU9AbxvFmqRJI2gYU9mX53k17LxlmxJ0jZj2HMU5wA7Az9J8iMgQFXVbr1VJkkaCcM+FNBHeUjSNmrYO7OT5NQkf9hN7+NnZkvStmHYcxR/DrwYeF03vR64oJeKJEkjZdhzFEdW1WFJbgWoqoeS7NBjXZKkETHsEcXjSRYw/lGoi4AnZtooybFJ1iRZ293ZPd16JyWpJIcPWY8kaZYMGxQfBj4L7Jnkj4HrgHe3NuiC5QLgOGAJcEqSJVOstyvwJuDGTahbkjRLhr3q6a+T/BNwNINLY19dVXfOsNkRwNruY1RJcjlwInDHpPXeBbwX+L1NKVySNDtm+ijUHYH/BBwIfB24sKo2DLnvvYB7JkyvA46ctP9DgX2q6gtJpg2KJMuAZQCLFi1ibGxsyBLmt/Xr19uLjr0YZy/G2YstY6YjikuAx4FrGQwhHQy8ech9T3UX978+mrx7htQHgNNm2lFVLQeWAyxevLiWLl06ZAnz29jYGPZiwF6Msxfj7MWWMVNQLKmqfwuQ5GPATZuw73XAPhOm9wbumzC9K3AIMNY9GeTngRVJTqiqWzbhfSRJPZrpZPbjG19swpDTRjcDByU5oLuU9mRgxYT9PVJVC6tq/6raH7gBMCQkacTMdETxgiQ/7F4H2KmbnvFZT1W1IclZwFXAAuCiqlqd5HzglqpaMd22kqTR0QyKqlrwVHZeVSuBlZPmvWOadZc+lfeSJPVj2PsoJEnbKINCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLU1GtQJDk2yZoka5OcO8Xyc5LckWRVki8l2a/PeiRJm663oEiyALgAOA5YApySZMmk1W4FDq+qXwA+A7y3r3okSZunzyOKI4C1VXVXVf0YuBw4ceIKVXVNVT3aTd4A7N1jPZKkzbB9j/veC7hnwvQ64MjG+qcDX5xqQZJlwDKARYsWMTY2toVK3LqtX7/eXnTsxTh7Mc5ebBl9BkWmmFdTrpicChwOHDXV8qpaDiwHWLx4cS1dunQLlbh1Gxsbw14M2Itx9mKcvdgy+gyKdcA+E6b3Bu6bvFKSY4A/AI6qqsd6rEeStBn6PEdxM3BQkgOS7ACcDKyYuEKSQ4ELgROq6oEea5EkbabegqKqNgBnAVcBdwJXVtXqJOcnOaFb7U+BXYBPJ/lakhXT7E6SNEf6HHqiqlYCKyfNe8eE18f0+f6SpKfOO7MlSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ19RoUSY5NsibJ2iTnTrH8Z5Jc0S2/Mcn+fdYjSdp0vQVFkgXABcBxwBLglCRLJq12OvBQVR0IfAB4T1/1SJI2T59HFEcAa6vqrqr6MXA5cOKkdU4ELulefwY4Okl6rEmStIm273HfewH3TJheBxw53TpVtSHJI8DPAQ9OXCnJMmBZN/lYktt7qXjrs5BJvdqG2Ytx9mKcvRi3eHM37DMopjoyqM1Yh6paDiwHSHJLVR3+1Mvb+tmLcfZinL0YZy/GJbllc7ftc+hpHbDPhOm9gfumWyfJ9sDuwA96rEmStIn6DIqbgYOSHJBkB+BkYMWkdVYA/7F7fRLw5ap60hGFJGnu9Db01J1zOAu4ClgAXFRVq5OcD9xSVSuAjwGXJlnL4Eji5CF2vbyvmrdC9mKcvRhnL8bZi3Gb3Yv4H3hJUot3ZkuSmgwKSVLTyAaFj/8YN0QvzklyR5JVSb6UZL+5qHM2zNSLCeudlKSSzNtLI4fpRZJf7342Vif51GzXOFuG+B3ZN8k1SW7tfk+On4s6+5bkoiQPTHevWQY+3PVpVZLDhtpxVY3cF4OT3/8HeDawA3AbsGTSOr8DfLR7fTJwxVzXPYe9eDnw9O71G7flXnTr7Qp8BbgBOHyu657Dn4uDgFuBn+2m95zruuewF8uBN3avlwB3z3XdPfXil4DDgNunWX488EUG97C9CLhxmP2O6hGFj/8YN2Mvquqaqnq0m7yBwT0r89EwPxcA7wLeC/y/2Sxulg3TizOAC6rqIYCqemCWa5wtw/SigN2617vz5Hu65oWq+grte9FOBD5RAzcAeyR55kz7HdWgmOrxH3tNt05VbQA2Pv5jvhmmFxOdzuB/DPPRjL1IciiwT1V9YTYLmwPD/Fw8F3hukuuT3JDk2FmrbnYN04vzgFOTrANWAmfPTmkjZ1P/ngD9PsLjqdhij/+YB4b+PpOcChwOHNVrRXOn2Ysk2zF4CvFps1XQHBrm52J7BsNPSxkcZV6b5JCqerjn2mbbML04Bfh4Vb0/yYsZ3L91SFU90X95I2Wz/m6O6hGFj/8YN0wvSHIM8AfACVX12CzVNttm6sWuwCHAWJK7GYzBrpinJ7SH/R35fFU9XlXfAtYwCI75ZphenA5cCVBV/wjsyOCBgduaof6eTDaqQeHjP8bN2ItuuOVCBiExX8ehYYZeVNUjVbWwqvavqv0ZnK85oao2+2FoI2yY35HPMbjQgSQLGQxF3TWrVc6OYXrxHeBogCQHMwiK781qlaNhBfD67uqnFwGPVNX9M200kkNP1d/jP7Y6Q/biT4FdgE935/O/U1UnzFnRPRmyF9uEIXtxFfDKJHcAPwHeWlXfn7uq+zFkL94C/GWS/8JgqOW0+fgfyySXMRhqXNidj3kn8DSAqvoog/MzxwNrgUeBNwy133nYK0nSFjSqQ0+SpBFhUEiSmgwKSVKTQSFJajIoJElNBoXUSfJzSb7Wff1zknsnTO+wifu6OMnivmqVZpOXx0pTSHIesL6q3jfXtUhzzSMKaQhJfj/J7d3X2d28A7vPebg0ydeTXJlkp27ZdUle2L3+lSRfTXJbkqu7ea/opr/WLdt57r47qW0k78yWRkmSI4DfYPA46wXATUn+gcGdrUuA06vqhiSfAM4EPjhh258H/gJ4WVV9O8kzukVvBZZV1Y1JdmF+PxJdWzmPKKSZvQz4m6p6tKr+hcEzlF7aLftW91x/gE9OmL/Ri4FrqurbAFW18cGV1wMf7I5Odquqn/T6HUhPgUEhzaz1gViTT/JN9Tj8J50IrKo/YnD0sQtwc5L5+FRXzRMGhTSzrwD/IclO3TDRicC13bIDkvxi9/oU4LpJ214PvCLd55hvHHpK8pyqWlVVf8Lg40q9Qkojy6CQZlBVNwGXMXic9Q3AX1TV17vFq4EzkqwCdmbw2cwTt/0ug88x/3yS24C/7hb9XndifBXwMHB1/9+JtHm8PFbaTEkOBD5TVS+c61qkPnlEIUlq8ohCktTkEYUkqcmgkCQ1GRSSpCaDQpLUZFBIkpr+PzRZzAxLwJdvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Perplexity')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "# Perplexiy seems to suggest 8 topics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Build an lda model with the suggested number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "# Build the lda model with the suggested number of topics\n",
    "\n",
    "NUM_TOPICS = 8\n",
    "\n",
    "lda_model_1 = models.LdaModel(corpus=bow_corpus\n",
    "                             , num_topics=NUM_TOPICS\n",
    "                             , id2word=dictionary\n",
    "                             , passes = 20  # as we have a small corpus\n",
    "                             , eta = 0.01 # topics are known to be word-sparse, the Dirichlet parameter of the word distributions is set small (e.g., 0.01), in which case learning is efficient.\n",
    "                             , alpha = 0.1    #believed that each document is associated with few topics\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Explore topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the topics, we will look at each topic in terms of the words it has the highest probability to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.276*\"service\" + 0.108*\"food\" + 0.091*\"restaurant\" + 0.072*\"star\" + 0.068*\"dish\"\n",
      "Topic #1: 0.390*\"place\" + 0.077*\"steak\" + 0.069*\"vega\" + 0.061*\"way\" + 0.056*\"sushi\"\n",
      "Topic #2: 0.155*\"eat\" + 0.138*\"love\" + 0.122*\"dont\" + 0.087*\"place\" + 0.065*\"salad\"\n",
      "Topic #3: 0.428*\"food\" + 0.103*\"delicious\" + 0.075*\"staff\" + 0.062*\"never\" + 0.061*\"pretty\"\n",
      "Topic #4: 0.262*\"back\" + 0.197*\"time\" + 0.079*\"wont\" + 0.070*\"try\" + 0.060*\"menu\"\n",
      "Topic #5: 0.179*\"order\" + 0.110*\"burger\" + 0.090*\"minute\" + 0.089*\"thing\" + 0.076*\"still\"\n",
      "Topic #6: 0.141*\"wait\" + 0.114*\"taste\" + 0.113*\"experience\" + 0.091*\"chicken\" + 0.076*\"meal\"\n",
      "Topic #7: 0.179*\"nice\" + 0.126*\"price\" + 0.099*\"service\" + 0.098*\"think\" + 0.092*\"friendly\"\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# (iv) Explore Topics\n",
    "\n",
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(NUM_TOPICS):\n",
    "    # Print the first 5 most representative words for each topic\n",
    "    print(\"Topic #%s:\" % idx, lda_model_1.print_topic(idx, 5))\n",
    " \n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Really hard to understand the topics...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python package ```pyLDAvis``` is designed to help the interpretion of the topics in a topic model. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization (https://datascienceplus.com/topic-modeling-in-python-with-nltk-and-gensim/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el124441401787763069369119632546\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el124441401787763069369119632546_data = {\"mdsDat\": {\"x\": [-0.30418477229602053, 0.06261105489667317, 0.16836839118915048, -0.2557197886551245, 0.07663687981489138, 0.2215639446342978, 0.2275597443192638, -0.19683545390313228], \"y\": [0.09290925163570048, -0.35099024921091365, -0.17968549256110025, 0.05391268888448411, -0.008384832686226893, 0.1821893520996243, 0.22596506758819768, -0.01591578574976579], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [14.765155792236328, 13.899977684020996, 12.634272575378418, 13.115483283996582, 13.79545783996582, 10.004611015319824, 11.771401405334473, 10.013643264770508]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Freq\": [116.0, 106.0, 81.0, 58.0, 54.0, 28.0, 28.0, 31.0, 30.0, 30.0, 28.0, 20.0, 21.0, 21.0, 21.0, 17.0, 26.0, 27.0, 22.0, 17.0, 20.0, 17.0, 17.0, 14.0, 17.0, 17.0, 15.0, 16.0, 14.0, 14.0, 16.155057907104492, 15.205631256103516, 17.08607292175293, 11.409783363342285, 10.464271545410156, 10.445462226867676, 8.552668571472168, 65.50613403320312, 21.700349807739258, 7.555951118469238, 9.50693130493164, 3.8091237545013428, 2.859790086746216, 25.594236373901367, 2.8221750259399414, 2.9804494380950928, 2.138437271118164, 2.2429308891296387, 1.0120575428009033, 0.031240973621606827, 0.021452009677886963, 0.027847589924931526, 0.021771732717752457, 0.012242279015481472, 0.009505764581263065, 0.00950578786432743, 0.01009425800293684, 0.009505790658295155, 0.00950577575713396, 0.009505798108875751, 0.023740246891975403, 0.009983171708881855, 0.010378198698163033, 0.009983155876398087, 0.009983104653656483, 0.010751848109066486, 0.012650296092033386, 0.010536461137235165, 0.012249683029949665, 0.010568886995315552, 17.298973083496094, 15.376367568969727, 11.537619590759277, 11.536972999572754, 12.48396110534668, 9.613824844360352, 12.45409107208252, 13.657934188842773, 87.35395812988281, 9.706477165222168, 6.818272113800049, 4.393089294433594, 3.044879674911499, 2.057588577270508, 2.6304638385772705, 0.4420601427555084, 1.719767689704895, 0.363955557346344, 0.17634274065494537, 0.16189207136631012, 0.05960888788104057, 0.028342533856630325, 0.04094782471656799, 0.020549658685922623, 0.21022124588489532, 0.022588679566979408, 0.0166400708258152, 0.012021681293845177, 0.010093430057168007, 0.01066472940146923, 0.016574375331401825, 0.012003567069768906, 0.01892932876944542, 0.022342177107930183, 31.440811157226562, 13.185593605041504, 13.18027400970459, 28.046937942504883, 24.839126586914062, 13.195332527160645, 8.112281799316406, 12.178369522094727, 7.107243537902832, 11.542272567749023, 3.290411949157715, 3.0473310947418213, 3.112074851989746, 2.4130454063415527, 3.2725131511688232, 2.039189577102661, 3.6221981048583984, 17.745193481445312, 1.024665355682373, 0.1727675497531891, 0.1185309961438179, 0.016604868695139885, 0.012293420732021332, 0.01116476021707058, 0.010688740760087967, 0.010145646519958973, 0.010145681910216808, 0.010145656764507294, 0.011985099874436855, 0.010742243379354477, 0.10954349488019943, 0.014471805654466152, 0.018617797642946243, 0.011584549210965633, 0.011241290718317032, 0.011369897052645683, 0.013249830342829227, 21.702524185180664, 12.297745704650879, 10.403992652893066, 15.884343147277832, 90.41177368164062, 12.809181213378906, 7.461796760559082, 13.049052238464355, 4.737161159515381, 5.445494651794434, 11.451047897338867, 2.84619402885437, 0.9550343751907349, 0.9481498599052429, 0.05073493346571922, 0.012275067158043385, 0.017110414803028107, 0.016700580716133118, 0.015474020503461361, 0.009980515576899052, 0.009456945583224297, 0.009456931613385677, 0.010030660778284073, 0.009456915780901909, 0.01067926175892353, 0.00945693626999855, 0.009456929750740528, 0.009944704361259937, 0.009456926956772804, 0.009456971660256386, 0.015938999131321907, 0.01914754882454872, 0.024106118828058243, 0.011446366086602211, 0.013142801821231842, 0.024882813915610313, 0.011506064794957638, 0.010202746838331223, 0.010324868373572826, 0.011558255180716515, 0.012426488101482391, 0.011008288711309433, 58.29172897338867, 17.496795654296875, 15.550873756408691, 12.638193130493164, 9.674745559692383, 13.377511978149414, 43.657928466796875, 13.330747604370117, 7.573273181915283, 8.614375114440918, 7.0987229347229, 2.696338653564453, 2.8374156951904297, 3.6358206272125244, 3.2671287059783936, 0.9269934892654419, 0.11145038157701492, 0.05863972380757332, 0.22475212812423706, 0.05406557023525238, 0.14982931315898895, 0.1673971563577652, 0.029175804927945137, 0.018695982173085213, 0.011576485820114613, 0.011914628557860851, 0.014354951679706573, 0.023329220712184906, 0.010358468629419804, 0.016953129321336746, 0.015997963026165962, 0.01466553844511509, 0.014176900498569012, 0.015166249126195908, 0.01438926812261343, 28.83159828186035, 17.740097045898438, 12.204643249511719, 14.366593360900879, 11.053516387939453, 12.088677406311035, 14.42301082611084, 8.689401626586914, 4.871448516845703, 4.026055812835693, 2.7890267372131348, 4.450169563293457, 3.3363373279571533, 9.048147201538086, 2.8504958152770996, 1.1864585876464844, 1.1196619272232056, 3.338024854660034, 1.2231109142303467, 0.8823263049125671, 1.5515642166137695, 0.1864916980266571, 0.032768309116363525, 0.037959132343530655, 0.0253229308873415, 0.028780290856957436, 0.01407512929290533, 0.011898129247128963, 0.011086651124060154, 0.011643454432487488, 0.01734452322125435, 0.021727627143263817, 0.0395394004881382, 0.030158530920743942, 0.017883025109767914, 21.52105712890625, 14.33908748626709, 14.34032154083252, 11.27063274383545, 21.369407653808594, 14.246804237365723, 17.269678115844727, 26.652551651000977, 13.821361541748047, 7.191352367401123, 4.044574737548828, 3.3033053874969482, 6.1601057052612305, 2.566410541534424, 2.3113954067230225, 3.191746711730957, 2.0599851608276367, 1.0983330011367798, 1.611121416091919, 0.3982667922973633, 0.04871850088238716, 0.0279694851487875, 0.01390637457370758, 0.04170950874686241, 0.013194557279348373, 0.010992416180670261, 0.013021670281887054, 0.014947370626032352, 0.011155613698065281, 0.010251631960272789, 0.01679413393139839, 0.0279641542583704, 0.0124733354896307, 0.013800614513456821, 0.013679786585271358, 28.853025436401367, 20.3004150390625, 12.81332015991211, 14.37191104888916, 15.729185104370117, 7.079202651977539, 14.813887596130371, 10.925585746765137, 5.894625663757324, 3.107926368713379, 5.5388383865356445, 15.979013442993164, 2.369069814682007, 0.9742741584777832, 1.4680087566375732, 0.24304962158203125, 0.03577328100800514, 0.025237200781702995, 0.018379535526037216, 0.013232353143393993, 0.01525910384953022, 0.012498736381530762, 0.011345471255481243, 0.01069136243313551, 0.011626744642853737, 0.010691363364458084, 0.010691383853554726, 0.011228345334529877, 0.012345308437943459, 0.010691408067941666, 0.012772183865308762, 0.01317791547626257, 0.011471916921436787, 0.01139476802200079, 0.012070519849658012, 0.012302151881158352, 0.014375387690961361, 0.012162565253674984, 0.012409393675625324, 0.012092940509319305], \"Term\": [\"food\", \"place\", \"service\", \"back\", \"time\", \"order\", \"nice\", \"eat\", \"wait\", \"love\", \"dont\", \"price\", \"taste\", \"experience\", \"delicious\", \"burger\", \"friendly\", \"restaurant\", \"think\", \"chicken\", \"minute\", \"wont\", \"steak\", \"thing\", \"star\", \"disappointed\", \"try\", \"dish\", \"fresh\", \"meal\", \"dish\", \"give\", \"star\", \"selection\", \"slow\", \"atmosphere\", \"excellent\", \"service\", \"restaurant\", \"serve\", \"quality\", \"awesome\", \"side\", \"food\", \"feel\", \"im\", \"menu\", \"never\", \"server\", \"cook\", \"perfect\", \"thing\", \"know\", \"night\", \"meat\", \"worth\", \"everything\", \"amazing\", \"leave\", \"enjoy\", \"nice\", \"cant\", \"still\", \"enough\", \"buffet\", \"fry\", \"time\", \"staff\", \"place\", \"order\", \"steak\", \"vega\", \"buffet\", \"enough\", \"sushi\", \"meat\", \"recommend\", \"way\", \"place\", \"flavor\", \"night\", \"pretty\", \"feel\", \"bland\", \"definitely\", \"next\", \"time\", \"im\", \"awesome\", \"experience\", \"worth\", \"atmosphere\", \"star\", \"cook\", \"food\", \"fresh\", \"quality\", \"find\", \"serve\", \"enjoy\", \"price\", \"fantastic\", \"eat\", \"service\", \"eat\", \"didnt\", \"know\", \"love\", \"dont\", \"salad\", \"perfect\", \"take\", \"side\", \"server\", \"everything\", \"leave\", \"bland\", \"find\", \"pizza\", \"night\", \"im\", \"place\", \"serve\", \"chicken\", \"time\", \"enjoy\", \"selection\", \"atmosphere\", \"amazing\", \"meat\", \"excellent\", \"worth\", \"next\", \"slow\", \"food\", \"try\", \"wait\", \"sushi\", \"feel\", \"table\", \"back\", \"delicious\", \"wasnt\", \"enjoy\", \"staff\", \"food\", \"pretty\", \"feel\", \"never\", \"amazing\", \"bland\", \"friendly\", \"quality\", \"find\", \"flavor\", \"recommend\", \"meat\", \"thing\", \"fresh\", \"table\", \"worth\", \"excellent\", \"serve\", \"everything\", \"side\", \"selection\", \"perfect\", \"leave\", \"tasty\", \"slow\", \"atmosphere\", \"burger\", \"taste\", \"dont\", \"fantastic\", \"steak\", \"time\", \"way\", \"enough\", \"amaze\", \"nice\", \"back\", \"eat\", \"back\", \"wont\", \"try\", \"amaze\", \"worth\", \"menu\", \"time\", \"definitely\", \"tasty\", \"never\", \"think\", \"everything\", \"night\", \"im\", \"dont\", \"love\", \"table\", \"server\", \"place\", \"friendly\", \"service\", \"food\", \"delicious\", \"give\", \"excellent\", \"side\", \"wasnt\", \"price\", \"meat\", \"dish\", \"vega\", \"meal\", \"way\", \"disappointed\", \"nice\", \"order\", \"burger\", \"still\", \"thing\", \"cook\", \"fry\", \"minute\", \"awesome\", \"find\", \"everything\", \"amazing\", \"take\", \"salad\", \"time\", \"disappointed\", \"serve\", \"excellent\", \"wait\", \"pizza\", \"way\", \"love\", \"dont\", \"fantastic\", \"server\", \"sushi\", \"meal\", \"tasty\", \"side\", \"meat\", \"perfect\", \"staff\", \"friendly\", \"place\", \"food\", \"back\", \"taste\", \"fresh\", \"meal\", \"cant\", \"experience\", \"table\", \"chicken\", \"wait\", \"pizza\", \"leave\", \"next\", \"tasty\", \"minute\", \"amazing\", \"find\", \"fry\", \"perfect\", \"bland\", \"definitely\", \"everything\", \"delicious\", \"flavor\", \"excellent\", \"love\", \"cook\", \"meat\", \"selection\", \"didnt\", \"side\", \"worth\", \"dish\", \"time\", \"recommend\", \"salad\", \"im\", \"nice\", \"price\", \"fantastic\", \"disappointed\", \"think\", \"next\", \"friendly\", \"im\", \"server\", \"flavor\", \"restaurant\", \"service\", \"staff\", \"pretty\", \"place\", \"pizza\", \"thing\", \"cant\", \"excellent\", \"side\", \"didnt\", \"cook\", \"amazing\", \"meat\", \"atmosphere\", \"worth\", \"serve\", \"everything\", \"enough\", \"perfect\", \"sushi\", \"way\", \"night\", \"buffet\", \"steak\", \"delicious\", \"food\", \"experience\", \"time\", \"order\"], \"Total\": [116.0, 106.0, 81.0, 58.0, 54.0, 28.0, 28.0, 31.0, 30.0, 30.0, 28.0, 20.0, 21.0, 21.0, 21.0, 17.0, 26.0, 27.0, 22.0, 17.0, 20.0, 17.0, 17.0, 14.0, 17.0, 17.0, 15.0, 16.0, 14.0, 14.0, 16.240896224975586, 15.28997802734375, 17.1915225982666, 11.487746238708496, 10.536795616149902, 10.537107467651367, 9.745404243469238, 81.70292663574219, 27.309738159179688, 9.81777286529541, 12.423436164855957, 12.726665496826172, 10.034299850463867, 116.54869079589844, 13.382486343383789, 21.56328582763672, 15.579105377197266, 23.964357376098633, 18.575454711914062, 11.161282539367676, 10.24640941619873, 14.48766040802002, 13.268858909606934, 11.74938678741455, 9.68887996673584, 9.796016693115234, 10.452034950256348, 10.143952369689941, 10.30020809173584, 10.483559608459473, 28.94445037841797, 11.35774040222168, 12.275472640991211, 11.61070442199707, 11.610651969909668, 15.342170715332031, 54.622283935546875, 18.321735382080078, 106.86589050292969, 28.905113220214844, 17.375802993774414, 15.454041481018066, 11.610651969909668, 11.61070442199707, 12.573577880859375, 9.68887996673584, 12.570947647094727, 14.609535217285156, 106.86589050292969, 13.832170486450195, 11.74938678741455, 18.22901153564453, 13.382486343383789, 11.75601577758789, 17.623708724975586, 11.618850708007812, 54.622283935546875, 21.56328582763672, 12.726665496826172, 21.598907470703125, 9.796016693115234, 10.537107467651367, 17.1915225982666, 11.161282539367676, 116.54869079589844, 14.431124687194824, 12.423436164855957, 10.593347549438477, 9.81777286529541, 10.483559608459473, 20.391645431518555, 12.91015338897705, 31.53114128112793, 81.70292663574219, 31.53114128112793, 13.26976490020752, 13.268858909606934, 30.607702255249023, 28.357948303222656, 16.595609664916992, 10.24640941619873, 16.690044403076172, 10.034299850463867, 18.575454711914062, 10.452034950256348, 10.30020809173584, 11.75601577758789, 10.593347549438477, 18.599929809570312, 11.74938678741455, 21.56328582763672, 106.86589050292969, 9.81777286529541, 17.506254196166992, 54.622283935546875, 10.483559608459473, 11.487746238708496, 10.537107467651367, 10.143952369689941, 9.68887996673584, 9.745404243469238, 9.796016693115234, 11.618850708007812, 10.536795616149902, 116.54869079589844, 15.626439094543457, 30.060293197631836, 12.573577880859375, 13.382486343383789, 14.42654800415039, 58.37811279296875, 21.834957122802734, 12.374563217163086, 10.483559608459473, 18.321735382080078, 116.54869079589844, 18.22901153564453, 13.382486343383789, 23.964357376098633, 10.143952369689941, 11.75601577758789, 26.38024139404297, 12.423436164855957, 10.593347549438477, 13.832170486450195, 12.570947647094727, 9.68887996673584, 14.48766040802002, 14.431124687194824, 14.42654800415039, 9.796016693115234, 9.745404243469238, 9.81777286529541, 10.452034950256348, 10.034299850463867, 11.487746238708496, 10.24640941619873, 10.30020809173584, 10.940549850463867, 10.536795616149902, 10.537107467651367, 17.81761932373047, 21.607746124267578, 28.357948303222656, 12.91015338897705, 17.375802993774414, 54.622283935546875, 14.609535217285156, 11.61070442199707, 12.71147632598877, 28.94445037841797, 58.37811279296875, 31.53114128112793, 58.37811279296875, 17.569461822509766, 15.626439094543457, 12.71147632598877, 9.796016693115234, 15.579105377197266, 54.622283935546875, 17.623708724975586, 10.940549850463867, 23.964357376098633, 22.889739990234375, 10.452034950256348, 11.74938678741455, 21.56328582763672, 28.357948303222656, 30.607702255249023, 14.42654800415039, 18.575454711914062, 106.86589050292969, 26.38024139404297, 81.70292663574219, 116.54869079589844, 21.834957122802734, 15.28997802734375, 9.745404243469238, 10.034299850463867, 12.374563217163086, 20.391645431518555, 9.68887996673584, 16.240896224975586, 15.454041481018066, 14.43371295928955, 14.609535217285156, 17.287141799926758, 28.94445037841797, 28.905113220214844, 17.81761932373047, 12.275472640991211, 14.48766040802002, 11.161282539367676, 15.342170715332031, 20.643842697143555, 12.726665496826172, 10.593347549438477, 10.452034950256348, 10.143952369689941, 16.690044403076172, 16.595609664916992, 54.622283935546875, 17.287141799926758, 9.81777286529541, 9.745404243469238, 30.060293197631836, 18.599929809570312, 14.609535217285156, 30.607702255249023, 28.357948303222656, 12.91015338897705, 18.575454711914062, 12.573577880859375, 14.43371295928955, 10.940549850463867, 10.034299850463867, 9.68887996673584, 10.24640941619873, 18.321735382080078, 26.38024139404297, 106.86589050292969, 116.54869079589844, 58.37811279296875, 21.607746124267578, 14.431124687194824, 14.43371295928955, 11.35774040222168, 21.598907470703125, 14.42654800415039, 17.506254196166992, 30.060293197631836, 18.599929809570312, 10.30020809173584, 11.618850708007812, 10.940549850463867, 20.643842697143555, 10.143952369689941, 10.593347549438477, 15.342170715332031, 10.24640941619873, 11.75601577758789, 17.623708724975586, 10.452034950256348, 21.834957122802734, 13.832170486450195, 9.745404243469238, 30.607702255249023, 11.161282539367676, 9.68887996673584, 11.487746238708496, 13.26976490020752, 10.034299850463867, 9.796016693115234, 16.240896224975586, 54.622283935546875, 12.570947647094727, 16.595609664916992, 21.56328582763672, 28.94445037841797, 20.391645431518555, 12.91015338897705, 17.287141799926758, 22.889739990234375, 11.618850708007812, 26.38024139404297, 21.56328582763672, 18.575454711914062, 13.832170486450195, 27.309738159179688, 81.70292663574219, 18.321735382080078, 18.22901153564453, 106.86589050292969, 18.599929809570312, 14.48766040802002, 11.35774040222168, 9.745404243469238, 10.034299850463867, 13.26976490020752, 11.161282539367676, 10.143952369689941, 9.68887996673584, 10.537107467651367, 9.796016693115234, 9.81777286529541, 10.452034950256348, 11.61070442199707, 10.24640941619873, 12.573577880859375, 14.609535217285156, 11.74938678741455, 11.610651969909668, 17.375802993774414, 21.834957122802734, 116.54869079589844, 21.598907470703125, 54.622283935546875, 28.905113220214844], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.9076000452041626, 1.9074000120162964, 1.9067000150680542, 1.9061000347137451, 1.906000018119812, 1.9041999578475952, 1.7822999954223633, 1.6920000314712524, 1.6829999685287476, 1.6510000228881836, 1.645300030708313, 0.70660001039505, 0.6575999855995178, 0.3970000147819519, 0.3564999997615814, -0.06599999964237213, -0.0729999989271164, -0.45590001344680786, -0.996999979019165, -3.96560001373291, -4.25600004196167, -4.341400146484375, -4.49970006942749, -4.953800201416016, -5.013899803161621, -5.024899959564209, -5.029699802398682, -5.059800148010254, -5.075099945068359, -5.092800140380859, -5.1930999755859375, -5.123899936676025, -5.162799835205078, -5.145899772644043, -5.145899772644043, -5.350399971008301, -6.457600116729736, -5.548099994659424, -7.160900115966797, -6.000999927520752, 1.9688999652862549, 1.9681999683380127, 1.9670000076293945, 1.9668999910354614, 1.9660999774932861, 1.965499997138977, 1.9638999700546265, 1.905900001525879, 1.7717000246047974, 1.6190999746322632, 1.4291000366210938, 0.5503000020980835, 0.4927999973297119, 0.2304999977350235, 0.07119999825954437, -1.295699954032898, -1.4850000143051147, -2.1084001064300537, -2.3057000637054443, -2.9202001094818115, -3.1285998821258545, -3.944999933242798, -4.0665998458862305, -4.324100017547607, -4.344600200653076, -4.486400127410889, -4.642199993133545, -4.808000087738037, -4.906799793243408, -4.917300224304199, -5.14169979095459, -5.007299900054932, -5.444699764251709, -6.231100082397461, 2.0659000873565674, 2.0624001026153564, 2.0620999336242676, 1.9814000129699707, 1.9363000392913818, 1.8394999504089355, 1.8351999521255493, 1.753600001335144, 1.7238999605178833, 1.592900037765503, 0.9129999876022339, 0.8508999943733215, 0.7397000193595886, 0.5893999934196472, 0.3312000036239624, 0.3174999952316284, 0.2847999930381775, 0.2732999920845032, -0.19110000133514404, -2.5495998859405518, -4.064300060272217, -4.3790998458862305, -4.771200180053711, -4.781099796295166, -4.7866997718811035, -4.792900085449219, -4.798699855804443, -4.803899765014648, -4.808000087738037, -4.819699764251709, -4.901000022888184, -4.915800094604492, -5.3180999755859375, -4.920899868011475, -5.013400077819824, -5.077099800109863, -6.322000026702881, 2.0253000259399414, 2.025099992752075, 2.0237998962402344, 1.8885999917984009, 1.777400016784668, 1.6785000562667847, 1.4471999406814575, 1.4234999418258667, 1.2698999643325806, 1.2618000507354736, 1.1967999935150146, 0.5577999949455261, -0.3749000132083893, -0.6488999724388123, -3.4811999797821045, -4.639800071716309, -4.710000038146973, -4.730299949645996, -4.806300163269043, -4.857699871063232, -4.906400203704834, -4.91379976272583, -4.917500019073486, -4.9355998039245605, -4.949399948120117, -4.956600189208984, -4.9618000984191895, -4.971799850463867, -4.984499931335449, -4.984499931335449, -4.987800121307373, -4.997300148010254, -5.03879976272583, -4.996699810028076, -5.155600070953369, -5.662600040435791, -5.115200042724609, -5.0055999755859375, -5.0843000411987305, -5.794400215148926, -6.423500061035156, -5.928699970245361, 1.9794000387191772, 1.976699948310852, 1.9759999513626099, 1.975000023841858, 1.968400001525879, 1.8285000324249268, 1.7568000555038452, 1.70169997215271, 1.6130000352859497, 0.9577000141143799, 0.8101000189781189, 0.6258999705314636, 0.5598999857902527, 0.20069999992847443, -0.18019999563694, -1.5161999464035034, -2.8824000358581543, -3.777400016784668, -4.183499813079834, -4.2093000411987305, -4.320499897003174, -4.564899921417236, -4.6371002197265625, -4.725800037384033, -4.754700183868408, -4.755199909210205, -4.778500080108643, -4.792300224304199, -4.860099792480469, -4.883999824523926, -4.892300128936768, -4.910999774932861, -4.956999778747559, -5.057799816131592, -5.625800132751465, 2.2995998859405518, 2.297800064086914, 2.296299934387207, 2.2936999797821045, 2.2923998832702637, 2.063800096511841, 1.94350004196167, 1.9205000400543213, 1.5253000259399414, 1.348099946975708, 1.0109000205993652, 0.9803000092506409, 0.6978999972343445, 0.5041999816894531, 0.49970000982284546, 0.18889999389648438, 0.13840000331401825, 0.10429999977350235, -0.4196000099182129, -0.5047000050544739, -0.6798999905586243, -2.7221999168395996, -3.6742000579833984, -3.8910000324249268, -3.9054999351501465, -3.9154999256134033, -4.353700160980225, -4.435299873352051, -4.470900058746338, -4.477799892425537, -4.660399913787842, -4.799699783325195, -5.599899768829346, -5.957499980926514, -5.788700103759766, 2.135499954223633, 2.1331000328063965, 2.132999897003174, 2.1317999362945557, 2.1287999153137207, 2.127000093460083, 2.1259000301361084, 2.019200086593628, 1.8425999879837036, 1.7802000045776367, 1.0842000246047974, 0.9419000148773193, 0.9301999807357788, 0.7651000022888184, 0.6171000003814697, 0.5695000290870667, 0.5353000164031982, -0.23109999299049377, -0.25279998779296875, -1.1279000043869019, -3.9656999111175537, -4.0640997886657715, -4.412700176239014, -4.458799839019775, -4.600900173187256, -4.642000198364258, -4.642899990081787, -4.649199962615967, -4.662300109863281, -4.722799777984619, -4.734799861907959, -5.43779993057251, -4.776100158691406, -4.952700138092041, -5.223299980163574, 2.298099994659424, 2.2967000007629395, 2.2936999797821045, 2.116499900817871, 1.9261000156402588, 1.805799961090088, 1.7242000102996826, 1.6212999820709229, 1.15339994430542, 0.8082000017166138, 0.7057999968528748, 0.6693999767303467, 0.2556000053882599, -0.6279000043869019, -1.9864000082015991, -2.036400079727173, -3.7026000022888184, -3.8080999851226807, -3.972100019454956, -4.329899787902832, -4.466800212860107, -4.4934000968933105, -4.49459981918335, -4.5081000328063965, -4.5081000328063965, -4.519100189208984, -4.521299839019775, -4.534900188446045, -4.545199871063232, -4.564000129699707, -4.59089994430542, -4.709700107574463, -4.63040018081665, -4.62529993057251, -4.970799922943115, -5.180300235748291, -6.6992998123168945, -5.180799961090088, -6.088500022888184, -5.47790002822876], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.6888999938964844, -2.7493999004364014, -2.6328001022338867, -3.036600112915039, -3.1231000423431396, -3.1249001026153564, -3.3248000144958496, -1.2889000177383423, -2.3938000202178955, -3.4488000869750977, -3.219099998474121, -4.133699893951416, -4.420300006866455, -2.2286999225616455, -4.433599948883057, -4.379000186920166, -4.710999965667725, -4.663300037384033, -5.459099769592285, -8.937100410461426, -9.312999725341797, -9.05210018157959, -9.298199653625488, -9.87399959564209, -10.126899719238281, -10.126899719238281, -10.066900253295898, -10.126899719238281, -10.126899719238281, -10.126899719238281, -9.211700439453125, -10.077899932861328, -10.03909969329834, -10.077899932861328, -10.07800006866455, -10.003800392150879, -9.84119987487793, -10.02400016784668, -9.873299598693848, -10.020899772644043, -2.5601000785827637, -2.6779000759124756, -2.965100049972534, -2.9651999473571777, -2.8863000869750977, -3.1475000381469727, -2.888700008392334, -2.7964000701904297, -0.9406999945640564, -3.1379001140594482, -3.4911000728607178, -3.9307000637054443, -4.2972002029418945, -4.689199924468994, -4.44350004196167, -6.2270002365112305, -4.868500232696533, -6.42140007019043, -7.145999908447266, -7.231500148773193, -8.23069953918457, -8.974100112915039, -8.606200218200684, -9.295599937438965, -6.970300197601318, -9.201000213623047, -9.506600379943848, -9.83180046081543, -10.006600379943848, -9.951499938964844, -9.510600090026855, -9.83329963684082, -9.377799987792969, -9.211999893188477, -1.8671000003814697, -2.7360999584198, -2.7365000247955322, -1.9814000129699707, -2.102799892425537, -2.7353999614715576, -3.22189998626709, -2.8155999183654785, -3.354099988937378, -2.8691999912261963, -4.124199867248535, -4.201000213623047, -4.179900169372559, -4.434299945831299, -4.129700183868408, -4.602700233459473, -4.028200149536133, -2.4391000270843506, -5.290900230407715, -7.071000099182129, -7.447800159454346, -9.413299560546875, -9.713899612426758, -9.810199737548828, -9.853799819946289, -9.905900001525879, -9.905900001525879, -9.905900001525879, -9.739299774169922, -9.848799705505371, -7.526700019836426, -9.550800323486328, -9.29889965057373, -9.773300170898438, -9.803400039672852, -9.791999816894531, -9.638999938964844, -2.2751998901367188, -2.8431999683380127, -3.0104000568389893, -2.5873000621795654, -0.8482000231742859, -2.802500009536743, -3.3427999019622803, -2.783900022506714, -3.7971999645233154, -3.6577999591827393, -2.9144999980926514, -4.306600093841553, -5.398600101470947, -5.405900001525879, -8.333800315856934, -9.752799987792969, -9.420700073242188, -9.444899559020996, -9.521200180053711, -9.959699630737305, -10.01360034942627, -10.01360034942627, -9.954700469970703, -10.01360034942627, -9.89210033416748, -10.01360034942627, -10.01360034942627, -9.963299751281738, -10.01360034942627, -10.01360034942627, -9.491600036621094, -9.308199882507324, -9.077899932861328, -9.822699546813965, -9.684499740600586, -9.046199798583984, -9.817500114440918, -9.937700271606445, -9.925800323486328, -9.812999725341797, -9.740500450134277, -9.861700057983398, -1.3377000093460083, -2.541100025177002, -2.6589999198913574, -2.8664000034332275, -3.1335999965667725, -2.8096001148223877, -1.6267999410629272, -2.8131000995635986, -3.378499984741211, -3.2497000694274902, -3.44320011138916, -4.411300182342529, -4.360300064086914, -4.112299919128418, -4.219200134277344, -5.479000091552734, -7.597300052642822, -8.239500045776367, -6.895899772644043, -8.320699691772461, -7.301400184631348, -7.190499782562256, -8.937600135803223, -9.382599830627441, -9.861900329589844, -9.833100318908691, -9.64680004119873, -9.161199569702148, -9.973099708557129, -9.480500221252441, -9.53849983215332, -9.625399589538574, -9.659299850463867, -9.59179973602295, -9.644399642944336, -1.7203999757766724, -2.2060000896453857, -2.5799999237060547, -2.4170000553131104, -2.6791000366210938, -2.589600086212158, -2.4130001068115234, -2.919800043106079, -3.498500108718872, -3.6891000270843506, -4.05620002746582, -3.588900089263916, -3.877000093460083, -2.879300117492676, -4.03439998626709, -4.910900115966797, -4.968800067901611, -3.876499891281128, -4.880499839782715, -5.207099914550781, -4.642600059509277, -6.761199951171875, -8.500200271606445, -8.353099822998047, -8.75790023803711, -8.629899978637695, -9.345199584960938, -9.513199806213379, -9.583900451660156, -9.534899711608887, -9.136300086975098, -8.91100025177002, -8.312299728393555, -8.583200454711914, -9.105799674987793, -2.17549991607666, -2.5815000534057617, -2.581399917602539, -2.8222999572753906, -2.182499885559082, -2.5880000591278076, -2.3954999446868896, -1.9615999460220337, -2.618299961090088, -3.2716000080108643, -3.847100019454956, -4.049600124359131, -3.4263999462127686, -4.302000045776367, -4.406599998474121, -4.083899974822998, -4.5218000411987305, -5.150700092315674, -4.767600059509277, -6.16510009765625, -8.266200065612793, -8.821100234985352, -9.51990032196045, -8.421500205993652, -9.572400093078613, -9.755000114440918, -9.585599899291992, -9.447699546813965, -9.740300178527832, -9.824799537658691, -9.331199645996094, -8.82129955291748, -9.628700256347656, -9.52750015258789, -9.536299705505371, -1.7206000089645386, -2.0720999240875244, -2.5322999954223633, -2.4175000190734863, -2.3273000717163086, -3.1256000995635986, -2.387200117111206, -2.691699981689453, -3.3087000846862793, -3.9488000869750977, -3.371000051498413, -2.311500072479248, -4.220300197601318, -5.108799934387207, -4.69890022277832, -6.497300148010254, -8.413299560546875, -8.762200355529785, -9.079299926757812, -9.407899856567383, -9.265299797058105, -9.464900016784668, -9.561699867248535, -9.621100425720215, -9.537199974060059, -9.621100425720215, -9.621100425720215, -9.572099685668945, -9.47719955444336, -9.621100425720215, -9.443300247192383, -9.411999702453613, -9.550600051879883, -9.55739974975586, -9.499799728393555, -9.480799674987793, -9.324999809265137, -9.492199897766113, -9.472100257873535, -9.497900009155273]}, \"token.table\": {\"Topic\": [5, 4, 6, 7, 1, 1, 6, 5, 2, 3, 4, 7, 2, 6, 7, 7, 6, 2, 5, 7, 4, 3, 6, 8, 1, 3, 5, 3, 4, 2, 3, 5, 6, 1, 6, 7, 8, 1, 2, 4, 3, 4, 6, 7, 2, 4, 8, 1, 4, 7, 4, 8, 6, 7, 1, 1, 3, 5, 8, 3, 3, 7, 3, 5, 6, 7, 2, 1, 5, 6, 7, 1, 4, 5, 7, 8, 8, 2, 3, 5, 6, 3, 7, 3, 6, 7, 2, 3, 8, 2, 4, 8, 8, 1, 4, 2, 1, 8, 3, 6, 1, 1, 3, 6, 1, 3, 8, 1, 8, 1, 3, 1, 4, 8, 1, 2, 6, 2, 7, 3, 6, 7, 5, 7, 6, 5, 8, 2, 5, 6, 5, 2, 6, 7, 4, 2, 6, 5, 5], \"Freq\": [1.022697925567627, 0.49290451407432556, 0.2957427203655243, 0.2957427203655243, 0.9490270614624023, 0.3143007159233093, 0.7071766257286072, 0.9935230612754822, 0.17012566328048706, 0.2551884949207306, 0.42531415820121765, 0.08506283164024353, 1.0335336923599243, 1.0102360248565674, 0.9685025215148926, 0.9710814952850342, 0.985549807548523, 0.17022523283958435, 0.7376427054405212, 0.1134834885597229, 1.0075587034225464, 0.9796707034111023, 0.17353938519954681, 0.8098504543304443, 0.9851673245429993, 0.881587028503418, 0.10579044371843338, 0.9831550121307373, 0.9538744688034058, 1.0335290431976318, 0.28702545166015625, 0.28702545166015625, 0.3827005922794342, 0.9235122203826904, 0.10261247307062149, 0.9722713828086853, 1.006959319114685, 0.22417359054088593, 0.22417359054088593, 0.5230717062950134, 0.188797727227211, 0.0943988636136055, 0.4719943404197693, 0.188797727227211, 0.7229523658752441, 0.07229523360729218, 0.21688570082187653, 0.2230827361345291, 0.7722094655036926, 0.9701253771781921, 0.41697874665260315, 0.5686073899269104, 0.7821578979492188, 0.1955394744873047, 0.9810347557067871, 0.13912536203861237, 0.18550048768520355, 0.18550048768520355, 0.5101263523101807, 0.9797375798225403, 0.29125624895095825, 0.6795979142189026, 0.9148024320602417, 0.03267151489853859, 0.06534302979707718, 0.9699513912200928, 1.0321110486984253, 0.12837707996368408, 0.8344510197639465, 0.6781682968139648, 0.290643572807312, 0.08345727622509003, 0.5424723029136658, 0.3755577504634857, 0.34426814317703247, 0.6024692058563232, 1.001919150352478, 0.5957757830619812, 0.17022165656089783, 0.25533246994018555, 1.0032826662063599, 0.7807613015174866, 0.19519032537937164, 0.16129092872142792, 0.05376364290714264, 0.7526910305023193, 0.8141044974327087, 0.16843540966510773, 0.009357523173093796, 0.21943043172359467, 0.7131489515304565, 0.054857607930898666, 0.980793833732605, 0.8049302697181702, 0.2414790838956833, 0.9545819759368896, 0.8055734634399414, 0.2197018563747406, 0.7833396792411804, 0.18077069520950317, 0.9575420618057251, 0.814848780632019, 0.10185609757900238, 0.10185609757900238, 0.05383448302745819, 0.6460137963294983, 0.32300689816474915, 0.8078045845031738, 0.19583141803741455, 0.29897451400756836, 0.6976072192192078, 0.9490551352500916, 0.8732797503471375, 0.10915996879339218, 0.9888594746589661, 0.9783720374107361, 0.9775590896606445, 0.9543823003768921, 0.9704331159591675, 0.7189915180206299, 0.23966383934020996, 1.018153429031372, 0.7312246561050415, 0.27420926094055176, 0.9663395881652832, 0.30581387877464294, 0.6990031599998474, 0.03661509230732918, 0.8055320382118225, 0.16476792097091675, 1.0239057540893555, 0.9706199169158936, 0.09979942440986633, 0.8981948494911194, 0.9697312116622925, 0.958278238773346, 0.06844844669103622, 0.967587947845459, 1.0208231210708618], \"Term\": [\"amaze\", \"amazing\", \"amazing\", \"amazing\", \"atmosphere\", \"awesome\", \"awesome\", \"back\", \"bland\", \"bland\", \"bland\", \"bland\", \"buffet\", \"burger\", \"cant\", \"chicken\", \"cook\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"didnt\", \"disappointed\", \"disappointed\", \"dish\", \"dont\", \"dont\", \"eat\", \"enjoy\", \"enough\", \"everything\", \"everything\", \"everything\", \"excellent\", \"excellent\", \"experience\", \"fantastic\", \"feel\", \"feel\", \"feel\", \"find\", \"find\", \"find\", \"find\", \"flavor\", \"flavor\", \"flavor\", \"food\", \"food\", \"fresh\", \"friendly\", \"friendly\", \"fry\", \"fry\", \"give\", \"im\", \"im\", \"im\", \"im\", \"know\", \"leave\", \"leave\", \"love\", \"love\", \"love\", \"meal\", \"meat\", \"menu\", \"menu\", \"minute\", \"minute\", \"never\", \"never\", \"never\", \"next\", \"next\", \"nice\", \"night\", \"night\", \"night\", \"order\", \"perfect\", \"perfect\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"quality\", \"quality\", \"recommend\", \"restaurant\", \"restaurant\", \"salad\", \"salad\", \"selection\", \"serve\", \"serve\", \"serve\", \"server\", \"server\", \"server\", \"service\", \"service\", \"side\", \"side\", \"slow\", \"staff\", \"staff\", \"star\", \"steak\", \"still\", \"sushi\", \"table\", \"take\", \"take\", \"taste\", \"tasty\", \"tasty\", \"thing\", \"think\", \"think\", \"time\", \"time\", \"time\", \"try\", \"vega\", \"wait\", \"wait\", \"wasnt\", \"way\", \"way\", \"wont\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el124441401787763069369119632546\", ldavis_el124441401787763069369119632546_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el124441401787763069369119632546\", ldavis_el124441401787763069369119632546_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el124441401787763069369119632546\", ldavis_el124441401787763069369119632546_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(lda_model_1, bow_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saliency**: a measure of how much the term tells you about the topic.\n",
    "\n",
    "**Relevance**: a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n",
    "\n",
    "The **size** of the bubble measures the importance of the topics, relative to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "?remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (7) Test on new text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.017242163),\n",
       " (1, 0.017241767),\n",
       " (2, 0.017241381),\n",
       " (3, 0.36206147),\n",
       " (4, 0.53448784),\n",
       " (5, 0.017241914),\n",
       " (6, 0.017241584),\n",
       " (7, 0.017241878)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try on a new (invented) text\n",
    "text_test = ['time', 'waste', 'food', 'staff', 'back', 'definitely']\n",
    "text_test_bow = dictionary.doc2bow(text_test)\n",
    "\n",
    "lda_model_1.get_document_topics(bow = text_test_bow)\n",
    "list(lda_model_1[text_test_bow])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of topic probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ```topicmod.lda_dtm2df``` to create a dataframe in which:\n",
    "- each row represents a document/text\n",
    "- has one column for each topic containing the probability of that topic for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_df = lda_dtm2df(lda_model_1[bow_corpus], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_lda</th>\n",
       "      <th>t1_lda</th>\n",
       "      <th>t2_lda</th>\n",
       "      <th>t3_lda</th>\n",
       "      <th>t4_lda</th>\n",
       "      <th>t5_lda</th>\n",
       "      <th>t6_lda</th>\n",
       "      <th>t7_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.374192</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>0.411519</td>\n",
       "      <td>0.035717</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.392855</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035716</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.017247</td>\n",
       "      <td>0.680398</td>\n",
       "      <td>0.216146</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.189656</td>\n",
       "      <td>0.362064</td>\n",
       "      <td>0.362070</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t0_lda    t1_lda    t2_lda    t3_lda    t4_lda    t5_lda    t6_lda  \\\n",
       "0  0.035714  0.035714  0.374192  0.035714  0.035715  0.411519  0.035717   \n",
       "1  0.035714  0.392857  0.392855  0.035714  0.035716  0.035714  0.035714   \n",
       "2  0.017242  0.017242  0.017241  0.017243  0.017247  0.680398  0.216146   \n",
       "3  0.392857  0.035714  0.035714  0.035714  0.035714  0.035714  0.035714   \n",
       "4  0.017242  0.017242  0.189656  0.362064  0.362070  0.017243  0.017241   \n",
       "\n",
       "     t7_lda  \n",
       "0  0.035714  \n",
       "1  0.035714  \n",
       "2  0.017241  \n",
       "3  0.392857  \n",
       "4  0.017241  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of topics' top n words and their probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ```topicmod.lda_topic_top_words``` to create a dataframe in which:\n",
    "- each row represents a document/text\n",
    "- columns contains a list of that topic's top n words and a list of their the probability for that topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_top_words_lda</th>\n",
       "      <th>t1_top_words_lda</th>\n",
       "      <th>t2_top_words_lda</th>\n",
       "      <th>t3_top_words_lda</th>\n",
       "      <th>t4_top_words_lda</th>\n",
       "      <th>t5_top_words_lda</th>\n",
       "      <th>t6_top_words_lda</th>\n",
       "      <th>t7_top_words_lda</th>\n",
       "      <th>t0_top_word_pbs_lda</th>\n",
       "      <th>t1_top_word_pbs_lda</th>\n",
       "      <th>t2_top_word_pbs_lda</th>\n",
       "      <th>t3_top_word_pbs_lda</th>\n",
       "      <th>t4_top_word_pbs_lda</th>\n",
       "      <th>t5_top_word_pbs_lda</th>\n",
       "      <th>t6_top_word_pbs_lda</th>\n",
       "      <th>t7_top_word_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[service, food, restaurant, star, dish, give]</td>\n",
       "      <td>[place, steak, vega, way, sushi, recommend]</td>\n",
       "      <td>[eat, love, dont, place, salad, didnt]</td>\n",
       "      <td>[food, delicious, staff, never, pretty, wasnt]</td>\n",
       "      <td>[back, time, wont, try, menu, definitely]</td>\n",
       "      <td>[order, burger, minute, thing, still, fry]</td>\n",
       "      <td>[wait, taste, experience, chicken, meal, fresh]</td>\n",
       "      <td>[nice, price, service, think, friendly, disappointed]</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[service, food, restaurant, star, dish, give]</td>\n",
       "      <td>[place, steak, vega, way, sushi, recommend]</td>\n",
       "      <td>[eat, love, dont, place, salad, didnt]</td>\n",
       "      <td>[food, delicious, staff, never, pretty, wasnt]</td>\n",
       "      <td>[back, time, wont, try, menu, definitely]</td>\n",
       "      <td>[order, burger, minute, thing, still, fry]</td>\n",
       "      <td>[wait, taste, experience, chicken, meal, fresh]</td>\n",
       "      <td>[nice, price, service, think, friendly, disappointed]</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[service, food, restaurant, star, dish, give]</td>\n",
       "      <td>[place, steak, vega, way, sushi, recommend]</td>\n",
       "      <td>[eat, love, dont, place, salad, didnt]</td>\n",
       "      <td>[food, delicious, staff, never, pretty, wasnt]</td>\n",
       "      <td>[back, time, wont, try, menu, definitely]</td>\n",
       "      <td>[order, burger, minute, thing, still, fry]</td>\n",
       "      <td>[wait, taste, experience, chicken, meal, fresh]</td>\n",
       "      <td>[nice, price, service, think, friendly, disappointed]</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[service, food, restaurant, star, dish, give]</td>\n",
       "      <td>[place, steak, vega, way, sushi, recommend]</td>\n",
       "      <td>[eat, love, dont, place, salad, didnt]</td>\n",
       "      <td>[food, delicious, staff, never, pretty, wasnt]</td>\n",
       "      <td>[back, time, wont, try, menu, definitely]</td>\n",
       "      <td>[order, burger, minute, thing, still, fry]</td>\n",
       "      <td>[wait, taste, experience, chicken, meal, fresh]</td>\n",
       "      <td>[nice, price, service, think, friendly, disappointed]</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[service, food, restaurant, star, dish, give]</td>\n",
       "      <td>[place, steak, vega, way, sushi, recommend]</td>\n",
       "      <td>[eat, love, dont, place, salad, didnt]</td>\n",
       "      <td>[food, delicious, staff, never, pretty, wasnt]</td>\n",
       "      <td>[back, time, wont, try, menu, definitely]</td>\n",
       "      <td>[order, burger, minute, thing, still, fry]</td>\n",
       "      <td>[wait, taste, experience, chicken, meal, fresh]</td>\n",
       "      <td>[nice, price, service, think, friendly, disappointed]</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                t0_top_words_lda  \\\n",
       "0  [service, food, restaurant, star, dish, give]   \n",
       "1  [service, food, restaurant, star, dish, give]   \n",
       "2  [service, food, restaurant, star, dish, give]   \n",
       "3  [service, food, restaurant, star, dish, give]   \n",
       "4  [service, food, restaurant, star, dish, give]   \n",
       "\n",
       "                              t1_top_words_lda  \\\n",
       "0  [place, steak, vega, way, sushi, recommend]   \n",
       "1  [place, steak, vega, way, sushi, recommend]   \n",
       "2  [place, steak, vega, way, sushi, recommend]   \n",
       "3  [place, steak, vega, way, sushi, recommend]   \n",
       "4  [place, steak, vega, way, sushi, recommend]   \n",
       "\n",
       "                         t2_top_words_lda  \\\n",
       "0  [eat, love, dont, place, salad, didnt]   \n",
       "1  [eat, love, dont, place, salad, didnt]   \n",
       "2  [eat, love, dont, place, salad, didnt]   \n",
       "3  [eat, love, dont, place, salad, didnt]   \n",
       "4  [eat, love, dont, place, salad, didnt]   \n",
       "\n",
       "                                 t3_top_words_lda  \\\n",
       "0  [food, delicious, staff, never, pretty, wasnt]   \n",
       "1  [food, delicious, staff, never, pretty, wasnt]   \n",
       "2  [food, delicious, staff, never, pretty, wasnt]   \n",
       "3  [food, delicious, staff, never, pretty, wasnt]   \n",
       "4  [food, delicious, staff, never, pretty, wasnt]   \n",
       "\n",
       "                            t4_top_words_lda  \\\n",
       "0  [back, time, wont, try, menu, definitely]   \n",
       "1  [back, time, wont, try, menu, definitely]   \n",
       "2  [back, time, wont, try, menu, definitely]   \n",
       "3  [back, time, wont, try, menu, definitely]   \n",
       "4  [back, time, wont, try, menu, definitely]   \n",
       "\n",
       "                             t5_top_words_lda  \\\n",
       "0  [order, burger, minute, thing, still, fry]   \n",
       "1  [order, burger, minute, thing, still, fry]   \n",
       "2  [order, burger, minute, thing, still, fry]   \n",
       "3  [order, burger, minute, thing, still, fry]   \n",
       "4  [order, burger, minute, thing, still, fry]   \n",
       "\n",
       "                                  t6_top_words_lda  \\\n",
       "0  [wait, taste, experience, chicken, meal, fresh]   \n",
       "1  [wait, taste, experience, chicken, meal, fresh]   \n",
       "2  [wait, taste, experience, chicken, meal, fresh]   \n",
       "3  [wait, taste, experience, chicken, meal, fresh]   \n",
       "4  [wait, taste, experience, chicken, meal, fresh]   \n",
       "\n",
       "                                        t7_top_words_lda  \\\n",
       "0  [nice, price, service, think, friendly, disappointed]   \n",
       "1  [nice, price, service, think, friendly, disappointed]   \n",
       "2  [nice, price, service, think, friendly, disappointed]   \n",
       "3  [nice, price, service, think, friendly, disappointed]   \n",
       "4  [nice, price, service, think, friendly, disappointed]   \n",
       "\n",
       "                                                         t0_top_word_pbs_lda  \\\n",
       "0  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "1  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "2  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "3  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "4  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "\n",
       "                                                           t1_top_word_pbs_lda  \\\n",
       "0  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "1  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "2  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "3  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "4  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "\n",
       "                                                        t2_top_word_pbs_lda  \\\n",
       "0  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "1  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "2  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "3  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "4  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "\n",
       "                                                            t3_top_word_pbs_lda  \\\n",
       "0  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "1  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "2  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "3  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "4  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "\n",
       "                                                     t4_top_word_pbs_lda  \\\n",
       "0  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "1  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "2  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "3  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "4  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "\n",
       "                                                      t5_top_word_pbs_lda  \\\n",
       "0  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "1  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "2  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "3  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "4  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "\n",
       "                                                        t6_top_word_pbs_lda  \\\n",
       "0  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "1  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "2  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "3  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "4  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "\n",
       "                                                          t7_top_word_pbs_lda  \n",
       "0  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]  \n",
       "1  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]  \n",
       "2  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]  \n",
       "3  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]  \n",
       "4  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (iv) extract top n words and their probabilities for each topic, turn them into a dataframe\n",
    "\n",
    "words_topics_dict = lda_topic_top_words(lda_mod = lda_model_1, n_top_words = 6)\n",
    "words_topics_df = topictopwords_dict2df(words_topics_dict, orig_dataset = df, tech = 'lda')\n",
    "\n",
    "words_topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe with top n topics for each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use ```topicmod.lda_ranked_topics2df``` to create a dataframe in which:\n",
    "- rows are documents\n",
    "- the first column ```ranked_topics_lda``` contains tuples of ranked topics for each document; if all topics have the same probability for a document, then topics are ordered by their index (e.g., (0,1,2,3))\n",
    "- the second column ```ranked_topics_pbs_lda``` contains tuples of the ranked topics' probabilities for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranked_topics_lda</th>\n",
       "      <th>ranked_topics_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(5, 2, 6, 4, 0, 1, 3, 7)</td>\n",
       "      <td>(0.41159022, 0.37412077, 0.03571729, 0.035714563, 0.035714287, 0.035714287, 0.035714287, 0.035714287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 2, 4, 5, 0, 3, 6, 7)</td>\n",
       "      <td>(0.39285713, 0.3928553, 0.035716146, 0.035714287, 0.035714284, 0.035714284, 0.035714284, 0.035714284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5, 6, 4, 3, 0, 1, 2, 7)</td>\n",
       "      <td>(0.6805126, 0.21603131, 0.017246848, 0.017243193, 0.017241793, 0.01724154, 0.017241381, 0.017241381)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 7, 1, 2, 3, 4, 5, 6)</td>\n",
       "      <td>(0.39285716, 0.3928571, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4, 3, 2, 5, 0, 1, 6, 7)</td>\n",
       "      <td>(0.3620704, 0.36206427, 0.1896557, 0.017243128, 0.017242163, 0.017241564, 0.017241381, 0.017241381)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ranked_topics_lda  \\\n",
       "0  (5, 2, 6, 4, 0, 1, 3, 7)   \n",
       "1  (1, 2, 4, 5, 0, 3, 6, 7)   \n",
       "2  (5, 6, 4, 3, 0, 1, 2, 7)   \n",
       "3  (0, 7, 1, 2, 3, 4, 5, 6)   \n",
       "4  (4, 3, 2, 5, 0, 1, 6, 7)   \n",
       "\n",
       "                                                                                   ranked_topics_pbs_lda  \n",
       "0  (0.41159022, 0.37412077, 0.03571729, 0.035714563, 0.035714287, 0.035714287, 0.035714287, 0.035714287)  \n",
       "1  (0.39285713, 0.3928553, 0.035716146, 0.035714287, 0.035714284, 0.035714284, 0.035714284, 0.035714284)  \n",
       "2  (0.6805126, 0.21603131, 0.017246848, 0.017243193, 0.017241793, 0.01724154, 0.017241381, 0.017241381)   \n",
       "3  (0.39285716, 0.3928571, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)  \n",
       "4  (0.3620704, 0.36206427, 0.1896557, 0.017243128, 0.017242163, 0.017241564, 0.017241381, 0.017241381)    "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (v) Ranked topics for each doc, create a DTM dataframe \n",
    "\n",
    "ranked_DTM_df =  lda_ranked_topics2df(lda_mod = lda_model_1, corpus = bow_corpus)\n",
    "\n",
    "ranked_DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join LDA-results datasets with the original dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll be using our ```nlpfunctions.utils.merge_dfs``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = merge_dfs(df, DTM_df, words_topics_df, ranked_DTM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>t0_lda</th>\n",
       "      <th>t1_lda</th>\n",
       "      <th>t2_lda</th>\n",
       "      <th>t3_lda</th>\n",
       "      <th>t4_lda</th>\n",
       "      <th>t5_lda</th>\n",
       "      <th>...</th>\n",
       "      <th>t0_top_word_pbs_lda</th>\n",
       "      <th>t1_top_word_pbs_lda</th>\n",
       "      <th>t2_top_word_pbs_lda</th>\n",
       "      <th>t3_top_word_pbs_lda</th>\n",
       "      <th>t4_top_word_pbs_lda</th>\n",
       "      <th>t5_top_word_pbs_lda</th>\n",
       "      <th>t6_top_word_pbs_lda</th>\n",
       "      <th>t7_top_word_pbs_lda</th>\n",
       "      <th>ranked_topics_lda</th>\n",
       "      <th>ranked_topics_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[wow, love, place]</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.374192</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>0.411519</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "      <td>(5, 2, 6, 4, 0, 1, 3, 7)</td>\n",
       "      <td>(0.41159022, 0.37412077, 0.03571729, 0.035714563, 0.035714287, 0.035714287, 0.035714287, 0.035714287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[crust]</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.392855</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035716</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "      <td>(1, 2, 4, 5, 0, 3, 6, 7)</td>\n",
       "      <td>(0.39285713, 0.3928553, 0.035716146, 0.035714287, 0.035714284, 0.035714284, 0.035714284, 0.035714284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.017247</td>\n",
       "      <td>0.680398</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "      <td>(5, 6, 4, 3, 0, 1, 2, 7)</td>\n",
       "      <td>(0.6805126, 0.21603131, 0.017246848, 0.017243193, 0.017241793, 0.01724154, 0.017241381, 0.017241381)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[stop, bank, holiday, rick, steve, recommendation, love]</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "      <td>(0, 7, 1, 2, 3, 4, 5, 6)</td>\n",
       "      <td>(0.39285716, 0.3928571, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[selection, menu, price]</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.189656</td>\n",
       "      <td>0.362064</td>\n",
       "      <td>0.362070</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]</td>\n",
       "      <td>[0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]</td>\n",
       "      <td>[0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]</td>\n",
       "      <td>[0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]</td>\n",
       "      <td>[0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]</td>\n",
       "      <td>[0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]</td>\n",
       "      <td>[0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]</td>\n",
       "      <td>[0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]</td>\n",
       "      <td>(4, 3, 2, 5, 0, 1, 6, 7)</td>\n",
       "      <td>(0.3620704, 0.36206427, 0.1896557, 0.017243128, 0.017242163, 0.017241564, 0.017241381, 0.017241381)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "   score source                                               text_lemmas  \\\n",
       "0  1      yelp   [wow, love, place]                                         \n",
       "1  0      yelp   [crust]                                                    \n",
       "2  0      yelp   [tasty, texture, nasty]                                    \n",
       "3  1      yelp   [stop, bank, holiday, rick, steve, recommendation, love]   \n",
       "4  1      yelp   [selection, menu, price]                                   \n",
       "\n",
       "     t0_lda    t1_lda    t2_lda    t3_lda    t4_lda    t5_lda  \\\n",
       "0  0.035714  0.035714  0.374192  0.035714  0.035715  0.411519   \n",
       "1  0.035714  0.392857  0.392855  0.035714  0.035716  0.035714   \n",
       "2  0.017242  0.017242  0.017241  0.017243  0.017247  0.680398   \n",
       "3  0.392857  0.035714  0.035714  0.035714  0.035714  0.035714   \n",
       "4  0.017242  0.017242  0.189656  0.362064  0.362070  0.017243   \n",
       "\n",
       "                                                   ...                                                    \\\n",
       "0                                                  ...                                                     \n",
       "1                                                  ...                                                     \n",
       "2                                                  ...                                                     \n",
       "3                                                  ...                                                     \n",
       "4                                                  ...                                                     \n",
       "\n",
       "                                                         t0_top_word_pbs_lda  \\\n",
       "0  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "1  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "2  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "3  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "4  [0.27556092, 0.10766582, 0.09128563, 0.07187501, 0.06795856, 0.063964665]   \n",
       "\n",
       "                                                           t1_top_word_pbs_lda  \\\n",
       "0  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "1  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "2  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "3  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "4  [0.39033917, 0.07730007, 0.06870895, 0.061030168, 0.055784296, 0.055650823]   \n",
       "\n",
       "                                                        t2_top_word_pbs_lda  \\\n",
       "0  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "1  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "2  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "3  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "4  [0.15456714, 0.13788241, 0.122112386, 0.08723769, 0.06486998, 0.0648221]   \n",
       "\n",
       "                                                            t3_top_word_pbs_lda  \\\n",
       "0  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "1  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "2  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "3  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "4  [0.42816815, 0.10277787, 0.075224385, 0.061797135, 0.060661167, 0.058239132]   \n",
       "\n",
       "                                                     t4_top_word_pbs_lda  \\\n",
       "0  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "1  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "2  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "3  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "4  [0.26244873, 0.19656248, 0.07877639, 0.0700152, 0.06023, 0.060019452]   \n",
       "\n",
       "                                                      t5_top_word_pbs_lda  \\\n",
       "0  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "1  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "2  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "3  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "4  [0.17899548, 0.110136, 0.08954251, 0.08919225, 0.07577019, 0.07505024]   \n",
       "\n",
       "                                                        t6_top_word_pbs_lda  \\\n",
       "0  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "1  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "2  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "3  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "4  [0.14063203, 0.11355573, 0.11275555, 0.09112336, 0.07566662, 0.07566011]   \n",
       "\n",
       "                                                          t7_top_word_pbs_lda  \\\n",
       "0  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]   \n",
       "1  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]   \n",
       "2  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]   \n",
       "3  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]   \n",
       "4  [0.17896694, 0.12591758, 0.09911319, 0.09756357, 0.091886245, 0.089144796]   \n",
       "\n",
       "          ranked_topics_lda  \\\n",
       "0  (5, 2, 6, 4, 0, 1, 3, 7)   \n",
       "1  (1, 2, 4, 5, 0, 3, 6, 7)   \n",
       "2  (5, 6, 4, 3, 0, 1, 2, 7)   \n",
       "3  (0, 7, 1, 2, 3, 4, 5, 6)   \n",
       "4  (4, 3, 2, 5, 0, 1, 6, 7)   \n",
       "\n",
       "                                                                                   ranked_topics_pbs_lda  \n",
       "0  (0.41159022, 0.37412077, 0.03571729, 0.035714563, 0.035714287, 0.035714287, 0.035714287, 0.035714287)  \n",
       "1  (0.39285713, 0.3928553, 0.035716146, 0.035714287, 0.035714284, 0.035714284, 0.035714284, 0.035714284)  \n",
       "2  (0.6805126, 0.21603131, 0.017246848, 0.017243193, 0.017241793, 0.01724154, 0.017241381, 0.017241381)   \n",
       "3  (0.39285716, 0.3928571, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287, 0.035714287)  \n",
       "4  (0.3620704, 0.36206427, 0.1896557, 0.017243128, 0.017242163, 0.017241564, 0.017241381, 0.017241381)    \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the LDA results as input for other analyses. For instance, here we show how we could include documents' ranked topics and probabilities in a classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lda_topic_pbs = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['t0_lda', 't1_lda', 't2_lda', 't3_lda', 't4_lda', 't5_lda', 't6_lda', 't7_lda']))\n",
    "        \n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = CountVectorizer(tokenizer = word_tokenize,\n",
    "                         analyzer=\"word\",\n",
    "                         ngram_range = (1,3),\n",
    "                         stop_words=None,\n",
    "                         min_df=1\n",
    "                         )\n",
    "\n",
    "pipe_bags_words = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['text'])),\n",
    "        ('transformer', Series2ListOfStrings()),\n",
    "        ('vec', my_vec),\n",
    "        ('tf_idf', TfidfTransformer())\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier\n",
    "\n",
    "svm = SVC(probability=True, C=1, kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_svm_clf = Pipeline([\n",
    "        \n",
    "        # Combined text (bag-of-word) and ad-hoc features\n",
    "        ('features', FeatureUnion(\n",
    "            \n",
    "                transformer_list = [\n",
    "                        ('lda', pipe_lda_topic_pbs),\n",
    "                        ('bow', pipe_bags_words)\n",
    "                        ],\n",
    "            \n",
    "                # weight components in FeatureUnion\n",
    "                transformer_weights={\n",
    "                        'lda': 0.6,\n",
    "                        'bow': 1.0\n",
    "                        }    \n",
    "                )),\n",
    "        \n",
    "        # Use classifier on combined features\n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = text_df[['text', 't0_lda', 't1_lda', 't2_lda', 't3_lda', 't4_lda', 't5_lda', 't6_lda', 't7_lda']]\n",
    "y = text_df.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_validate(lda_bow_svm_clf, X, y, cv = 5, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.998 (std 0.001)\n",
      "Test Accuracy: 0.831 (std 0.028)\n"
     ]
    }
   ],
   "source": [
    "sorted(scores_svm.keys())\n",
    "\n",
    "print(\"Train Accuracy: %0.3f (std %0.3f)\" % (scores_svm['train_score'].mean(), scores_svm['train_score'].std()))\n",
    "print(\"Test Accuracy: %0.3f (std %0.3f)\" % (scores_svm['test_score'].mean(), scores_svm['test_score'].std()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuplesToColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class for building sklearn Pipeline step. \n",
    "    This class turns columns from a pandas data frame (type Series) that\n",
    "    contain tuples of integer or float values into separate array columns \n",
    "    that can be used as inout in ML pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialise\n",
    "    def __init__(self):\n",
    "        self              #could also use 'pass'\n",
    "        \n",
    "    # \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):        #X: dataset to pass to the transformer.\n",
    "        cols_df = pd.DataFrame()\n",
    "        for name, valuez in X.iteritems():\n",
    "            valuez_df = pd.DataFrame(valuez.values.tolist())\n",
    "            cols_df = pd.concat([cols_df, valuez_df], axis=1)\n",
    "        return cols_df.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lda_topic_pbs_2 = Pipeline([\n",
    "    \n",
    "    ('selector', ColumnSelector(columns=['ranked_topics_lda', 'ranked_topics_pbs_lda'])),\n",
    "    ('toarray', TuplesToColumns())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_svm_clf_2 = Pipeline([\n",
    "        \n",
    "        # Combined text (bag-of-word) and ad-hoc features\n",
    "        ('features', FeatureUnion(\n",
    "            \n",
    "                transformer_list = [\n",
    "                        ('lda', pipe_lda_topic_pbs_2),\n",
    "                        ('bow', pipe_bags_words)\n",
    "                        ],\n",
    "            \n",
    "                # weight components in FeatureUnion\n",
    "                transformer_weights={\n",
    "                        'lda': 0.6,\n",
    "                        'bow': 1.0\n",
    "                        }    \n",
    "                )),\n",
    "        \n",
    "        # Use classifier on combined features\n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_df[['text', 'ranked_topics_lda', 'ranked_topics_pbs_lda']]\n",
    "y = text_df.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_validate(lda_bow_svm_clf_2, X, y, cv = 5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.998 (std 0.001)\n",
      "Test Accuracy: 0.820 (std 0.023)\n"
     ]
    }
   ],
   "source": [
    "sorted(scores_svm.keys())\n",
    "\n",
    "print(\"Train Accuracy: %0.3f (std %0.3f)\" % (scores_svm['train_score'].mean(), scores_svm['train_score'].std()))\n",
    "print(\"Test Accuracy: %0.3f (std %0.3f)\" % (scores_svm['test_score'].mean(), scores_svm['test_score'].std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc = TuplesToColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.        , 2.        , 6.        , ..., 0.03571429, 0.03571429,\n",
       "        0.03571429],\n",
       "       [1.        , 2.        , 4.        , ..., 0.03571428, 0.03571428,\n",
       "        0.03571428],\n",
       "       [5.        , 6.        , 4.        , ..., 0.01724154, 0.01724138,\n",
       "        0.01724138],\n",
       "       ...,\n",
       "       [0.        , 1.        , 2.        , ..., 0.125     , 0.125     ,\n",
       "        0.125     ],\n",
       "       [0.        , 1.        , 2.        , ..., 0.125     , 0.125     ,\n",
       "        0.125     ],\n",
       "       [3.        , 7.        , 0.        , ..., 0.03571429, 0.03571429,\n",
       "        0.03571429]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc.fit_transform(text_df[['ranked_topics_lda', 'ranked_topics_pbs_lda']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
