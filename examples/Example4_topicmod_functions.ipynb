{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ```topicmod``` functions to easily apply topic modelling LDA and NMF techniques to text data stored in ```pandas.DataFrame``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example script, we show how ```nlpfunctions.topicmod``` functions can make it easy to apply Latent Derichlet Analysis (LDA) and Non-negative Matrix Factorization (NMF) models to text data and store the results in ```pandas.DataFrame``` so that they can be used in other analyses and explorations.\n",
    "\n",
    "We will:\n",
    "1. A\n",
    "2. B\n",
    "3. C\n",
    "4. D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set ups and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and our user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from nltk import word_tokenize\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nlpbumblebee.utils import *\n",
    "from nlpbumblebee.basicnlp import *\n",
    "from nlpbumblebee.nlppipelineutils import *\n",
    "from nlpbumblebee.topicmod import *\n",
    "\n",
    "from gensim import models, corpora    #lda\n",
    "\n",
    "from sklearn import decomposition     #nmf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use the same labelled text data as in Example 2 and 3 from \"From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\" (available here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('Data/imdb.xlsx', header=0)\n",
    "df = pd.read_excel('Data/yelp_labelled.xlsx', header=0)\n",
    "\n",
    "#df['source'] = 'imdb'\n",
    "df['source'] = 'yelp'\n",
    "\n",
    "df[df.duplicated('text')]\n",
    "df = df.drop_duplicates('text')\n",
    "\n",
    "df[pd.isnull(df['text'])]   #yep, 1 case\n",
    "df = df[pd.notnull(df['text'])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      text  \\\n",
      "0  Wow... Loved this place.                                                                  \n",
      "1  Crust is not good.                                                                        \n",
      "2  Not tasty and the texture was just nasty.                                                 \n",
      "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
      "4  The selection on the menu was great and so were the prices.                               \n",
      "\n",
      "   score source  \n",
      "0  1      yelp   \n",
      "1  0      yelp   \n",
      "2  0      yelp   \n",
      "3  1      yelp   \n",
      "4  1      yelp   \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>the</td>\n",
       "      <td>and</td>\n",
       "      <td>I</td>\n",
       "      <td>was</td>\n",
       "      <td>a</td>\n",
       "      <td>to</td>\n",
       "      <td>The</td>\n",
       "      <td>is</td>\n",
       "      <td>of</td>\n",
       "      <td>for</td>\n",
       "      <td>...</td>\n",
       "      <td>place</td>\n",
       "      <td>with</td>\n",
       "      <td>had</td>\n",
       "      <td>be</td>\n",
       "      <td>are</td>\n",
       "      <td>were</td>\n",
       "      <td>very</td>\n",
       "      <td>that</td>\n",
       "      <td>have</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404</td>\n",
       "      <td>378</td>\n",
       "      <td>291</td>\n",
       "      <td>290</td>\n",
       "      <td>227</td>\n",
       "      <td>213</td>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>123</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9 ...     15    16   17  \\\n",
       "word   the  and  I    was  a    to   The  is   of   for ...  place  with  had   \n",
       "count  404  378  291  290  227  213  176  170  123  102 ...  76     71    65    \n",
       "\n",
       "       18   19    20    21    22    23  24  \n",
       "word   be  are  were  very  that  have  so  \n",
       "count  64  62   61    60    59    59    58  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEbCAYAAADUCE9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XvcXFV97/HPlxATLuES8qCRUIM0goAQ8CFFoYUQW7nYRi0oyE2kpLZQ6LGtBT1W9Bw8UC8g9hSNBzEgChH1BBGslAQxyMWEhBAIHlII8JhUwtVYDJDwO3+sNTA8zGU/c3meyc73/XrNa2avWWvvNbffrL322msrIjAzs/LaYqQrYGZm3eVAb2ZWcg70ZmYl50BvZlZyDvRmZiXnQG9mVnIO9GZmJedAb2ZWcg70ZmYlt+VIVwBgwoQJMXny5JGuhpnZJmXx4sVPRERfs3w9EegnT57MokWLRroaZmabFEmPFMnnrhszs5JzoDczKzkHejOzkuuJPnozs2ZefPFFBgYGWL9+/UhXZdiNHTuWSZMmMXr06JbKO9Cb2SZhYGCAcePGMXnyZCSNdHWGTUTw5JNPMjAwwG677dbSOtx1Y2abhPXr17PTTjttVkEeQBI77bRTW3syDvRmtsnY3IJ8Rbuvu3CglzRK0hJJ1+fl3STdKelBSddIel1OH5OXV+bnJ7dVQzMza8tQ+ujPBlYA2+XlC4GLIuJqSV8FTgMuzfdPR8TvSzou5/tgB+tsZsbkc37U0fWtuuDojq5vqC6++GJmzZrF1ltv3fF1Fwr0kiYBRwPnAx9T2o84HPhQzjIHOI8U6GfmxwDXAv8iSTGEq5DX+wBH+oMwM+uWiy++mBNPPLErgb5o183FwMeBl/LyTsAzEbEhLw8Au+THuwCPAeTnn835zcw2aVdccQX77rsv++23HyeddBKPPPIIM2bMYN9992XGjBk8+uijAHz4wx/m2muvfbnctttuC8Att9zCYYcdxjHHHMOee+7JCSecQERwySWXsHr1aqZPn8706dM7Xu+mgV7Se4DHI2JxdXKNrFHguer1zpK0SNKitWvXFqqsmdlIue+++zj//POZP38+99xzD1/+8pc588wzOfnkk1m2bBknnHACZ511VtP1LFmyhIsvvpj777+fhx56iNtuu42zzjqLN77xjSxYsIAFCxZ0vO5FWvQHA38maRVwNanL5mJgB0mVrp9JwOr8eADYFSA/vz3w1OCVRsTsiOiPiP6+vqaTr5mZjaj58+dzzDHHMGHCBADGjx/P7bffzoc+lHqwTzrpJBYuXNh0PdOmTWPSpElsscUWTJ06lVWrVnWz2kCBQB8R50bEpIiYDBwHzI+IE4AFwDE52ynAvPz4urxMfn7+UPrnzcx6UUQ0HeZYeX7LLbfkpZdeerncCy+88HKeMWPGvPx41KhRbNiwgW5rZxz9P5IOzK4k9cFfltMvA3bK6R8DzmmvimZmI2/GjBnMnTuXJ598EoCnnnqKd77znVx99dUAXHXVVRxyyCFAmnp98eLU2z1v3jxefPHFpusfN24c69at60rdhzQFQkTcAtySHz8ETKuRZz1wbAfqZmZW13CPwtt777355Cc/yaGHHsqoUaPYf//9ueSSS/jIRz7C5z//efr6+rj88ssBOP3005k5cybTpk1jxowZbLPNNk3XP2vWLI488kgmTpzY8X569UKvSn9/f1RfeMTDK81ssBUrVvDWt751pKsxYmq9fkmLI6K/WVlPgWBmVnIO9GZmJedAb2abjF7oah4J7b5uB3oz2ySMHTuWJ598crML9pX56MeOHdvyOnzhETPbJEyaNImBgQE2xzPpK1eYalVpAn2jmew8Wsds0zd69OiWr7C0uXPXjZlZyTnQm5mVnAO9mVnJOdCbmZWcA72ZWck50JuZlZwDvZlZyTnQm5mVnAO9mVnJOdCbmZVc00AvaaykuyTdI+k+SZ/J6d+U9LCkpfk2NadL0iWSVkpaJumAbr8IMzOrr8hcN88Dh0fEbyWNBhZKujE/9w8Rce2g/EcCU/LtD4BL872ZmY2Api36SH6bF0fnW6N5QmcCV+RydwA7SJrYflXNzKwVhfroJY2StBR4HLgpIu7MT52fu2cukjQmp+0CPFZVfCCnmZnZCCgU6CNiY0RMBSYB0yTtA5wL7AkcCIwH/jFnV61VDE6QNEvSIkmLNsf5pc3MhsuQRt1ExDPALcAREbEmd888D1wOTMvZBoBdq4pNAlbXWNfsiOiPiP6+vr6WKm9mZs0VGXXTJ2mH/Hgr4F3AA5V+d0kC3gssz0WuA07Oo28OAp6NiDVdqb2ZmTVVZNTNRGCOpFGkP4a5EXG9pPmS+khdNUuBj+b8NwBHASuB54BTO19tMzMrqmmgj4hlwP410g+vkz+AM9qvmpmZdYLPjDUzKzkHejOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSK3IpwbGS7pJ0j6T7JH0mp+8m6U5JD0q6RtLrcvqYvLwyPz+5uy/BzMwaKdKifx44PCL2A6YCR+RrwV4IXBQRU4CngdNy/tOApyPi94GLcj4zMxshTQN9JL/Ni6PzLYDDgWtz+hzSBcIBZuZl8vMz8gXEzcxsBBTqo5c0StJS4HHgJuA/gGciYkPOMgDskh/vAjwGkJ9/Ftipk5U2M7PiCgX6iNgYEVOBScA04K21suX7Wq33GJwgaZakRZIWrV27tmh9zcxsiIY06iYingFuAQ4CdpC0ZX5qErA6Px4AdgXIz28PPFVjXbMjoj8i+vv6+lqrvZmZNVVk1E2fpB3y462AdwErgAXAMTnbKcC8/Pi6vEx+fn5EvKZFb2Zmw2PL5lmYCMyRNIr0xzA3Iq6XdD9wtaT/CSwBLsv5LwOulLSS1JI/rgv1NjOzgpoG+ohYBuxfI/0hUn/94PT1wLEdqZ2ZmbWtSIu+tCaf86O6z6264Oghl2tUxsxspHgKBDOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSc6A3Myu5IteM3VXSAkkrJN0n6eycfp6kX0lamm9HVZU5V9JKSb+U9O5uvgAzM2usyBWmNgB/FxF3SxoHLJZ0U37uooj4QnVmSXuRrhO7N/BG4N8lvSUiNnay4mZmVkzTFn1ErImIu/PjdcAKYJcGRWYCV0fE8xHxMLCSGteWNTOz4TGkPnpJk0kXCr8zJ50paZmkb0jaMaftAjxWVWyAxn8MZmbWRYUDvaRtge8BfxsRvwEuBXYHpgJrgC9WstYoHjXWN0vSIkmL1q5dO+SKm5lZMYUCvaTRpCB/VUR8HyAifh0RGyPiJeDrvNI9MwDsWlV8ErB68DojYnZE9EdEf19fXzuvwczMGigy6kbAZcCKiPhSVfrEqmzvA5bnx9cBx0kaI2k3YApwV+eqbGZmQ1Fk1M3BwEnAvZKW5rRPAMdLmkrqllkF/CVARNwnaS5wP2nEzhkecWNmNnKaBvqIWEjtfvcbGpQ5Hzi/jXqZmVmH+MxYM7OSc6A3Mys5B3ozs5JzoDczKzkHejOzknOgNzMrOQd6M7OSK3LClHXA5HN+VPe5VRccPYw1MbPNjVv0ZmYl50BvZlZyDvRmZiXnQG9mVnIO9GZmJedAb2ZWch5e2ePqDcv0kEwzK8otejOzknOgNzMruSLXjN1V0gJJKyTdJ+nsnD5e0k2SHsz3O+Z0SbpE0kpJyyQd0O0XYWZm9RVp0W8A/i4i3gocBJwhaS/gHODmiJgC3JyXAY4kXRB8CjALuLTjtTYzs8KaBvqIWBMRd+fH64AVwC7ATGBOzjYHeG9+PBO4IpI7gB0kTex4zc3MrJAh9dFLmgzsD9wJvD4i1kD6MwB2ztl2AR6rKjaQ0wava5akRZIWrV27dug1NzOzQgoHeknbAt8D/jYiftMoa420eE1CxOyI6I+I/r6+vqLVMDOzISoU6CWNJgX5qyLi+zn515UumXz/eE4fAHatKj4JWN2Z6pqZ2VAVGXUj4DJgRUR8qeqp64BT8uNTgHlV6Sfn0TcHAc9WunjMzGz4FTkz9mDgJOBeSUtz2ieAC4C5kk4DHgWOzc/dABwFrASeA07taI3NzGxImgb6iFhI7X53gBk18gdwRpv1MjOzDvGZsWZmJedAb2ZWcg70ZmYl50BvZlZyDvRmZiXnQG9mVnIO9GZmJedLCZZQvcsPgi9BaLY5covezKzkHOjNzErOXTcGuLvHrMzcojczKzkHejOzknOgNzMrOQd6M7OSc6A3Myu5IpcS/IakxyUtr0o7T9KvJC3Nt6OqnjtX0kpJv5T07m5V3MzMiinSov8mcESN9IsiYmq+3QAgaS/gOGDvXOZfJY3qVGXNzGzomgb6iLgVeKrg+mYCV0fE8xHxMOm6sdPaqJ+ZmbWpnT76MyUty107O+a0XYDHqvIM5DQzMxshrQb6S4HdganAGuCLOb3WRcSj1gokzZK0SNKitWvXtlgNMzNrpqVAHxG/joiNEfES8HVe6Z4ZAHatyjoJWF1nHbMjoj8i+vv6+lqphpmZFdBSoJc0sWrxfUBlRM51wHGSxkjaDZgC3NVeFc3MrB1NJzWT9B3gMGCCpAHg08BhkqaSumVWAX8JEBH3SZoL3A9sAM6IiI3dqbqZmRXRNNBHxPE1ki9rkP984Px2KmVmZp3jM2PNzErOgd7MrOQc6M3MSs6B3sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSq7pmbFmjUw+50c101ddcPQw18TM6nGL3sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSs6B3sys5JoGeknfkPS4pOVVaeMl3STpwXy/Y06XpEskrZS0TNIB3ay8mZk1V6RF/03giEFp5wA3R8QU4Oa8DHAk6YLgU4BZwKWdqaaZmbWqaaCPiFuBpwYlzwTm5MdzgPdWpV8RyR3ADpImdqqyZmY2dK1OgfD6iFgDEBFrJO2c03cBHqvKN5DT1rReRSubetMmQP2pE1opY2ZJpw/GqkZa1MwozZK0SNKitWvXdrgaZmZW0WqL/teSJubW/ETg8Zw+AOxalW8SsLrWCiJiNjAboL+/v+afgVm7vCdg1nqL/jrglPz4FGBeVfrJefTNQcCzlS4eMzMbGU1b9JK+AxwGTJA0AHwauACYK+k04FHg2Jz9BuAoYCXwHHBqF+ps1lXeC7CyaRroI+L4Ok/NqJE3gDParZSZmXWOz4w1Mys5B3ozs5JzoDczKzkHejOzkvPFwc06xBdKt17lFr2ZWcm5RW82gjxm34aDA73ZJsZ/DjZU7roxMys5B3ozs5Jz143ZZsJdPpsvt+jNzErOgd7MrOTcdWNmdbXa3eOTx3qLA72Z9QQfQ+geB3oz22R5j6MYB3ozswKG80+l03s3bQV6SauAdcBGYENE9EsaD1wDTAZWAR+IiKfb2Y6ZmbWuE6NupkfE1Ijoz8vnADdHxBTg5rxsZmYjpBvDK2cCc/LjOcB7u7ANMzMrqN1AH8BPJC2WNCunvT4i1gDk+51rFZQ0S9IiSYvWrl3bZjXMzKyedg/GHhwRqyXtDNwk6YGiBSNiNjAboL+/P9qsh5mZ1dFWiz4iVuf7x4EfANOAX0uaCJDvH2+3kmZm1rqWA72kbSSNqzwG/gRYDlwHnJKznQLMa7eSZmbWuna6bl4P/EBSZT3fjogfS/oFMFfSacCjwLHtV9PMzFrVcqCPiIeA/WqkPwnMaKdSZmbWOZ690sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSs6B3sys5BzozcxKzoHezKzkHOjNzErOgd7MrOQc6M3MSs6B3sys5BzozcxKzoHezKzkHOjNzEqua4Fe0hGSfilppaRzurUdMzNrrCuBXtIo4H8DRwJ7AcdL2qsb2zIzs8a61aKfBqyMiIci4gXgamBml7ZlZmYNdCvQ7wI8VrU8kNPMzGyYKSI6v1LpWODdEfEXefkkYFpE/E1VnlnArLy4B/DLOqubADwxxCq0UmY4t9Xr9RvObfV6/YZzW71ev+HcVq/Xbzi31ajMmyKir+kaIqLjN+AdwL9VLZ8LnNviuhYNR5nh3Fav18/vhd+Lkd5Wr9dvU3gvqm/d6rr5BTBF0m6SXgccB1zXpW2ZmVkDW3ZjpRGxQdKZwL8Bo4BvRMR93diWmZk11pVADxARNwA3dGBVs4epzHBuq9frN5zb6vX6Dee2er1+w7mtXq/fcG6r1fq9rCsHY83MrHd4CgQzs5JzoDczK7mu9dHba0naEZgCjK2kRcStI1ejTYukMRHxfLM0s27YlL9/btEPE0l/AdxKGon0mXx/XoFyr5f0nnzbuUD+t0i6WdLyvLyvpP9esI4HS9omPz5R0pckvalO3ivz/dlF1l1VbpSkbw2lTJXbC6YN3uY7JX1I0smVW4vbb7ad17wX9d4fSeMb3Qpu702S3pUfbyVpXIEyw/Je9DJJX5C0dwtFW/r+tULSaElnSbo23/5G0uhW19dzgT4Htssk3ZiX95J0WoP86yT9pt6thXLrmpT7Z0nb5Q/iZklPSDqxwEs7GzgQeCQipgP7A2sbFZD0AeAu4FjgA8Cdko5psp2vk05QexEgIpaRzmMo4lLgOUn7AR8HHgGuqJP37flP4COSdiwaqCJiI9CXz68oRNIbJL0d2ErS/pIOyLfDgK2blL0S+AJwCOn9PxDob1Lm7PwZK38X75b0JwWqekqNtA/XybsYWJTv1wL/D3gwP17cbEOSTgeuBb6WkyYB/7dJmcLvRau/q6ryQ/odt1GmlYbNA8BsSXdK+qik7Ztso+XvXxt1vBR4O/Cv+XZATmtNu2dcdfoG3EgKavfk5S2BewuU+yzw18A4YDvgr4CPd6F+S/P9+4A5wPhKXZuU+0WlPDCmel0NytwD7Fy13NdsW1XbWTK4zgXqeHe+/yfgtOq0GnnPAlYAzwMPVd0eBh5qsp2vkU6q+xTwscqtQf5TgAXAunxfuV0HvL/JtlaQR5cN4TOufPfenbexX733Iec7Hvgh8HTOX7ktAP69yba+ChxVtXwk8MUi30PgdYM+54a/kxbfi5Z+V638jlss81PSJIrV78Pygq9tD+ACUoPm28D0Tn//Wq1jrd95s99+o1sv9tFPiIi5ks6Fl0++2lig3Lsj4g+qli+VdCfwzx2uX2X36SjgOxHxlKQi5QYk7UBqdd0k6WlgdZMyW0TE41XLT9J8L+wJSbsDAZD3ANYUqSCwLr/vJwJ/pDTddM3dxYi4BLhE0qWkYPVH+albI+KeJttZnW9bkAJIQxExB5gj6c8j4nvFXsrLlgNvoPh7AFD5QI8CLo+Ie9T4Q/55Xv8E4ItV6euAZU22dWBEfLSyEBE3SvofBer4fES8UKmWpC3Jn3kDrbwXrf6uWvkdt1Jm64i4a9DHs6FJmcpU6nvm2xOkRtXHJP1lRLxqD7jN71+rddwoafeI+I9c3zcDReJgTb0Y6P9L0k68EqgOAp4tUG6jpBNIUyIHqZXV8hvTwA8lPQD8DvhrSX3A+maFIuJ9+eF5khYA2wM/blLsRkn/BnwnL3+Q5iehnUE6wWJPSb8itbCLdC1V1v8hUmv+PyX9HvD5JmUeAL4FfJ8UIK+U9PWI+Eq9AhHxGQClPuWIiN8WrN/Nkr7EK38qPwU+GxGNvh8TgPsl3UXa+6jU4c8alFks6SfAbsC5uZ4v1cscEY+QWoXvKPYyXuWJvBv/LdL39kTSH3ozP5X0CVJ3wh+TWt0/rJVR0g/zuscx9Pei1d9VK7/jVsoMuWGTv0N/CswHPhcRd+WnLpRUb3JFIuJ7ko4G9ubVAyo+2+k6An8PLJD0UF6eDJzapEx9re4KdOtG6ou6jfQB30bqu9y3QLnJwDzSv/NaUst5cpfquCMwKj/eGnhDl7ZzIfB+4EvARaTuogsLlt0GGDcMn9cyYJtB213WpMw+wBJScHyE1Ce9d4FtfY90IPvN+fZp4PtNyhxa69akzBb5e7hDXt6p0XcQWJjv1wG/qbqtA37TZFvjgS/n92NJfjy+wHuxBXA68F1SX/3p1OmWqfceFHwvWvpdVf2Onyn6O27lt5+/B/8OPAf8ClhImtGxXn6Rugy3rvP89g3KfpV0zOqx/N27F7iswHsxpDrmMseSusr2zfW9ETig2bbq3XryzNi8G7oH6UP5ZUS8OMJVehVJ+5CunFX9r17voGU727k7Ig4YlLYsIvZtUGYM8OekH+jLe2zRoNUhaWFEHCJpHa/e/VcqGts1KHsvqfthfV4eSzpO8LYGZX4OfDIiFuTlw0gtq3fWK5PzLY2Iqc3SWiVpz4h4QNIBtZ6PiLs7sZ06294OeCkK7t0ojY5aH+ngdqUrYkxEPNegzIUR8Y/N0johfw/OJB3nWEcanfKVyvekRv4tgINIgw8K/fZzmWMidfdsQ+rqXFegbosj4u0tvKZlEbFv1f22pIZGwwP1kkZFxMYh1rGyjUOAz5G6BD8Rr+5GK6wXu24gHbiYTKrfAZKaBtLchXI6rw1wH+lkxSR9GjiMFOhvIB08W0j90SmtbOOvSLvib5ZU3cc7jtTSaWQeqUW0mKrd80Yi4pB837S/vIbLSaOBfpCX3wtc1qTMNpUgn7d7S/4RNPM7SYdExEJIw0FJXWiv0eKf18dI10j4Yo3nAji8QB2HRNLbSN+d8Xn5CeCUiFjepOjNwLuAyh/DVsBPgEZ/ln8MDA7qR9ZIq67fWOA0Xttd0ex3dQVpr+Zzefl44EpSS/U1IuIlSV+MiHcAhSZAzGXOBOZGxH8VKZPdIenAiPjFEMrAK9+15yS9kdTFtluBcg9L+jFwDam7qIhK99jRwFcjYp6k84ZS2Wo916JXGgK2O2lUQeXFRkSc1aTcz4GfkQLcy32I0drBk0bbuZc0CmNJROwn6fXA/4mIP+3gNrYndQ/9L6D6wurrIuKpJmWXR8Q+napLEbkFfAgpiN4aEUua5P8BcDfphw+pX7o/It7bpNxU0kinynC4p0lBsdkBz541HHs31Q0H4D+qnhoH3BYRdY/hSPou6TjMh0gjcE4AVkREw/MnJN0TEfs1Sxv0/GdIXYHfj4KBSdKnSAH4GuDlYN/odyLpftJew6pcpvLnX3dPuWpbXwFmkK6JHaTf/qealNuKdEzgOFL31PXA1ZUGS50y15O6ed5FGmb5O+CuRu9fwzr0YKBfAexV9IOuKtexXfgm2/lFRBwoaTEwnbRbujwiWjkBo+MkzSbtIt870nUZTNKVEXGSpI+R9rwqfw4/BT4TEU83KT8GOIbUENiBtOcSjbql2qjrO3nt3mE3uueGHBBzntuAv6l0JymN8/6X3CIenLedhsOSiNi/qithNOmiQg33biR9k9QSvSMv/wHpT/mvG5RZRzrGs4E0wKFI1+HDNZIjIt7coEzNkwAjHVQvJH8Xx0bjgQC1yu1IOg5zQkSMapBva+AI0vDSByVNBN4WET8ZyvYqerHrppUhYADXSzoq0vTI3fQLpWGSXyftPfyW1K84opROxniJ9Jmemo/WP0/B1sowqZxkdQrpT1K80q1SZIzqPNLBvbtJrZ2uqLdXSQe756o8lFuK1Xs3tYLXYH8LfFdSZYjuRNKoqVoiIlZJOmPwE5LGNwn2lT7yZ/Kxqf8k/QHWlPd4gzQs92RJj+blNwH3N9gOETFO6WS7V00T0qRMka6TwWUeyX3fUyLi8tztu22RsoMbAEW6lXO+Q0mfz5Gkc0g+0KSOz5FGslWW1zD0mPjK9nulRa9XDwGbSgqeRYeAVbcGnid9OZu2Blqs55WkqQx+Rmp1bNcLXQdK4/Lr7tEMpbXSLZLOIp1w82ZeHagrn1XdVlguPyzdUq3uVba4rR1JI4le7voCzmu2d5PLjuaVA5cP1DtwKen6iHhPbv0Gr/5Tbdb6/QvSaKe3Ad8kBcRPRcTX6uSv2Vqu2ljd72He1tmks3yXkg7O/jwiZjQoszXp2MrvRcQsSVOAPSLi+gZlPk06I3iPiHhL7m//bkQc3KjubXQrP5zLzAWuG+LxhI7opUB/KOkLeCHp9PuXnyINKWx6tLlWayAiftrheh5O+lH+ISlgLSX1S3+5k9tpoV6vGaHTqyRdGhF/1UK5YemWyv3SZ+VW1LDQEEfd5DJDGv1V3UiJiAcKbqN6FFfl5LludZfdS5qW4Y6ImCppT1KXXr09FSRdQ9qzPjki9sn94bc36saVtJQ0BcndEbF/Tms4mi3nabVbebuIaDptRDf1TNdNJSBLGj04OOcPr6F6rQHSgZNO1nO+pJ+SvpDTgY+SRiSMaKAHds593zVFxJeGszKNtBLks0OAD+cWUse7pdTeiUWtbrOlUTdqbfTX5aT38CtKZ1ouIQX9Rt/dIY/iasP6iFgvCaVZIR+QtEeTMrtHxAclHQ8QEb+Tmp6q/kJEhKTKCUxFRnxB693KL+Rus6GOXOqYngn0am9IIbwyadgdETG90hroQj1vJnUR3U7qvjkwXj1NwUgZRdqtLjQfwybqyC6v/wu8sldZPQKoktYNXyPN81M96mY2jYdJQjooXRn9dary6K9GBeo0UvahcSNlUkQcUeSFdEAr04S8kBuClaC9O83/kOZK+hqwg9LkcB8hHXOrqQMNgCtJI5feTdXIpSZlOqpnAj1pUqEbaWFkQNZKa6AVy0jDnfYhtXSekXR7RNQczz2M1nRjd7qXdPs4Q7t7lS1q+ZyCSOPIN+Run8dJXYl1tdhI+bmktw3HKK5obZqQT+c8u0q6CjiY+jOGVrxEev2/Ad4C/FNE3NQgf7sNgN+PiGMlzYyIOZK+TZqmfNj0TKDPw5SeJZ1Y0YpWWgNDFhH/DUDprLhTSbvDbwDGdHpbQ1Tmlvyw6MBeZStaHXWzqIXRX4UbKVWjZ0ZkFNcQjq2dDPyINA3EQ8DZEfFEkzLjSCeBPUWaw6fhYIoONACGNHKpG3rmYGwn5QO72wM/jogXOrxVCb8VAAADG0lEQVTuM0kHYt9OmqelcnCr6BlvXVFgmJw1oTbGm7ewrbbOKRi0rskMYfRXVSPl70nzNL2mkdLO6Jnh1M7gCEn7koY8/jkwEBHvqpOv5RPOcvkhjVzqhlIG+m6S9A+k4L44IppOh2pWi9LZmUeS5jQffE5B3TM7VWcenqpydefj6dVGSruU5vmpPu7wu4jYs0C5N5CmZDiONAFgzb2UdhsAwzlyqW4dHOjNhl+r5xTkvuuKWnP41D1jtYyNlBrHHRY2O+6QW+gfJF3I51rgmohoeDJXm3X8Ma+MXKqenqXWnErdqYMDvdnIaeOcgq1I3QmHkAL+z4BLo87skGUl6SLSHsrzpOMot5LG0dcdHCHpAtJcM0uHqY7DPv/Ua+rgQG+26ZE0lzRq5KqcdDxp/vyGp9aXVZHjDiNluE70a1gHB3qzTY9anAytbHr5uMOgkUtTSKOCRmT+qZ4ZXmlmQ7JE0kHx6tkhuzUEtJdtRboCWy8ed3jPSFegwi16s01QnndlD+DRnPR7pLMtX6J3Ziu1HuFAb7YJ2lTGuVtvcKA3Myu5LUa6AmZm1l0O9GZmJedAb9YBkg5TuqCzWc9xoDdrQZ5fxWyT4EBvmx1JH89zzSDpIknz8+MZkr4l6XhJ90paLunCqnK/lfRZSXcC75B0hKQHJC0E3j8yr8asOQd62xzdSjqbEtJFordVutD2IcCDpItJHE662PqBkioXm9gGWB7p+sWLSHPB/2le1xuGr/pmQ+NAb5ujxcDbJY0jnZJ+Oyng/yHwDHBLRKzNZ1peBfxRLreRNK84wJ7AwxHxYL5Y9LeG8wWYDYUDvW12IuJFYBVpEqyfk2Z+nA7szitnmtayPiI2Vi37JBTbJDjQ2+bqVtJMh7eSAv1HSVcnugM4VNKEfMD1eNJVnwZ7ANgtX4waWr8EplnXOdDb5upnwETS3OW/BtaTZj1cA5wLLADuAe6OiHmDC+d532cBP8oHYz3lgPUsT4FgZlZybtGbmZWcA72ZWck50JuZlZwDvZlZyTnQm5mVnAO9mVnJOdCbmZWcA72ZWcn9f1Tcx7lgnE7SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot most frequent words\n",
    "\n",
    "# https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n",
    "all_words = df['text'].str.split(expand=True).unstack().value_counts()\n",
    "all_words = all_words.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 25 more frequent words\n",
    "all_words[:25].plot.bar(x='word')\n",
    "all_words[:25].T\n",
    "\n",
    "#lots of \"rubbish\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text data for topic modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will:\n",
    "1. tokenise\n",
    "2. lower case\n",
    "3. remove stopwords\n",
    "4. remove non-alphabetic tokens (i.e., punctuations and numbers)\n",
    "5. lemmatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipe = combine_functions(sent_tokenise\n",
    "                                       ,remove_punctuation\n",
    "                                       ,word_tokenise\n",
    "                                       ,to_lower\n",
    "                                       ,POS_tagging\n",
    "                                       ,lemmatise\n",
    "                                       ,fix_neg_auxiliary\n",
    "                                       ,lambda s: [[re.sub(r'\\d+','',x) for x in subs] for subs in s]\n",
    "                                       ,lambda x : remove_stopwords(x, extra_stopwords = [\n",
    "                                           'x', \"'s\", \"not\", 'us', 'no', 'many', 'much', 'one', 'put', 've',\n",
    "                                           'wo', 'even', 'first', 'may', 'late', 'come', 'iam', 'ive', 'ill',\n",
    "                                           'good', 'bad', 'great', 'sure', 'best', 'quite', 'per', 'due', 'always',\n",
    "                                           'say', 'want', 'm', 'ever', 'every', 'really', 'well', 'little', 'd',\n",
    "                                           'also', 'get', 'would', 'could', 'like', 'go', 'lot', 'make'])\n",
    "                                       ,flattenIrregularListOfLists\n",
    "                                       ,lambda x: list(filter(None, x))\n",
    "                                      )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>[wow, love, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>[crust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>[stop, bank, holiday, rick, steve, recommendation, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>[selection, menu, price]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "                                                text_lemmas  \n",
       "0  [wow, love, place]                                        \n",
       "1  [crust]                                                   \n",
       "2  [tasty, texture, nasty]                                   \n",
       "3  [stop, bank, holiday, rick, steve, recommendation, love]  \n",
       "4  [selection, menu, price]                                  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lemmas'] = df['text'].apply(lambda x: preprocessing_pipe(x))\n",
    "\n",
    "# check some texts\n",
    "df[['text', 'text_lemmas']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>food</td>\n",
       "      <td>place</td>\n",
       "      <td>service</td>\n",
       "      <td>back</td>\n",
       "      <td>time</td>\n",
       "      <td>eat</td>\n",
       "      <td>love</td>\n",
       "      <td>wait</td>\n",
       "      <td>dont</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>...</td>\n",
       "      <td>think</td>\n",
       "      <td>experience</td>\n",
       "      <td>taste</td>\n",
       "      <td>im</td>\n",
       "      <td>minute</td>\n",
       "      <td>staff</td>\n",
       "      <td>price</td>\n",
       "      <td>pretty</td>\n",
       "      <td>pizza</td>\n",
       "      <td>definitely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123</td>\n",
       "      <td>110</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1        2     3     4    5     6     7     8           9  \\\n",
       "word   food  place  service  back  time  eat  love  wait  dont  restaurant   \n",
       "count  123   110    84       60    55    31   30    29    28    28           \n",
       "\n",
       "          ...         15          16     17  18      19     20     21      22  \\\n",
       "word      ...      think  experience  taste  im  minute  staff  price  pretty   \n",
       "count     ...      22     21          21     21  19      19     19     19       \n",
       "\n",
       "          23          24  \n",
       "word   pizza  definitely  \n",
       "count  18     18          \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE3CAYAAACkZooiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xm4HFWd//H3hyQQlrBHBAMEEUFAEAyLwAxLdGSRRQUVESKgGWdAHHFUcMNlGMEV8DejRpFFUUFAgygKEwKIrAkQdhRZIygRQXBhCXx/f5zT3M6lu6u6uu+Sup/X8/Rzb9et0+d0d91vnTpbKSIwM7P6WmakC2BmZkPLgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mam78SBcAYM0114ypU6eOdDHMzJYq8+fP/1NETC7ab1QE+qlTpzJv3ryRLoaZ2VJF0v1l9nPTjZlZzTnQm5nVnAO9mVnNjYo2ejOzIs8++ywLFy7kqaeeGumiDLuJEycyZcoUJkyYUCm9A72ZLRUWLlzIpEmTmDp1KpJGujjDJiJ49NFHWbhwIRtssEGl13DTjZktFZ566inWWGONMRXkASSxxhpr9HQl40BvZkuNsRbkG3p93w70ZmY1Nyrb6Kce87OW2+87Ya9hLomZjVbt4kRVIx1fTjrpJGbOnMkKK6zQ99d2jd7MbBQ46aST+Pvf/z4kr10Y6CV9R9Ijkm5t2vZFSXdKulnSjyWt2vS3YyXdLekuSW8cklKbmY2AM888ky222IItt9ySgw8+mPvvv5/p06ezxRZbMH36dB544AEA3v3ud3Puuee+kG6llVYC4LLLLmOXXXZh//33Z5NNNuGggw4iIjjllFN46KGH2HXXXdl11137Xu4yNfrTgd0HbbsE2DwitgB+AxwLIGlT4B3AZjnN/0oa17fSmpmNkNtuu43jjz+eSy+9lAULFnDyySdz5JFHcsghh3DzzTdz0EEHcdRRRxW+zo033shJJ53E7bffzj333MOvf/1rjjrqKNZZZx3mzp3L3Llz+172wkAfEVcAfx607eKIWJyfXgNMyb/vC/wwIp6OiHuBu4Ft+1heM7MRcemll7L//vuz5pprArD66qtz9dVX8853vhOAgw8+mCuvvLLwdbbddlumTJnCMsssw2te8xruu+++oSw20J82+sOAi/LvLwMebPrbwrztRSTNlDRP0rxFixb1oRhmZkMnIgqHOTb+Pn78eJ5//vkX0j3zzDMv7LPccsu98Pu4ceNYvHgxQ62nQC/p48Bi4KzGpha7Rau0ETErIqZFxLTJkwuXUzYzG1HTp0/nnHPO4dFHHwXgz3/+MzvssAM//OEPATjrrLPYaaedgLT0+vz58wGYPXs2zz77bOHrT5o0iSeffHJIyl55eKWkGcCbgOkR0QjmC4F1m3abAjxUvXhmZq0N93DIzTbbjI9//OPsvPPOjBs3jq222opTTjmFww47jC9+8YtMnjyZ0047DYD3vve97Lvvvmy77bZMnz6dFVdcsfD1Z86cyR577MHaa6/d93Z6DcToDjtJU4ELI2Lz/Hx34CvAzhGxqGm/zYDvk9rl1wHmABtFxHOdXn/atGnRfOMRj6M3s8HuuOMOXvWqV410MUZMq/cvaX5ETCtKW1ijl/QDYBdgTUkLgeNIo2yWAy7JbVLXRMT7IuI2SecAt5OadI4oCvJmZja0CgN9RBzYYvOpHfY/Hji+l0KZmVn/eGasmS01yjQ111Gv79uB3syWChMnTuTRRx8dc8G+sR79xIkTK7/GqFzUzMxssClTprBw4ULG4rybxh2mqnKgN7OlwoQJEyrfYWmsc9ONmVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnN1WYcfac7wnvVSzMby1yjNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6s5B3ozs5pzoDczqzkHejOzmnOgNzOrucJAL+k7kh6RdGvTttUlXSLpt/nnanm7JJ0i6W5JN0vaeigLb2ZmxcrU6E8Hdh+07RhgTkRsBMzJzwH2ADbKj5nA1/tTTDMzq6ow0EfEFcCfB23eFzgj/34GsF/T9jMjuQZYVdLa/SqsmZl1r2ob/VoR8TBA/vmSvP1lwINN+y3M215E0kxJ8yTNW7RoUcVimJlZkX53xqrFtmi1Y0TMiohpETFt8uTJfS6GmZk1VA30f2w0yeSfj+TtC4F1m/abAjxUvXhmZtarqoH+AmBG/n0GMLtp+yF59M32wF8aTTxmZjYyCm8OLukHwC7AmpIWAscBJwDnSDoceAA4IO/+c2BP4G7g78ChQ1BmMzPrQmGgj4gD2/xpeot9Azii10KZmVn/eGasmVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnNOdCbmdWcA72ZWc2NH+kCjKSpx/ys7d/uO2GvYSyJmdnQcY3ezKzmHOjNzGqup0Av6YOSbpN0q6QfSJooaQNJ10r6raSzJS3br8KamVn3Kgd6SS8DjgKmRcTmwDjgHcCJwFcjYiPgMeDwfhTUzMyq6bXpZjywvKTxwArAw8BuwLn572cA+/WYh5mZ9aByoI+I3wNfAh4gBfi/APOBxyNicd5tIfCyXgtpZmbV9dJ0sxqwL7ABsA6wIrBHi12jTfqZkuZJmrdo0aKqxTAzswK9NN28Hrg3IhZFxLPA+cAOwKq5KQdgCvBQq8QRMSsipkXEtMmTJ/dQDDMz66SXQP8AsL2kFSQJmA7cDswF9s/7zABm91ZEMzPrRS9t9NeSOl1vAG7JrzUL+ChwtKS7gTWAU/tQTjMzq6inJRAi4jjguEGb7wG27eV1zcysfzwz1sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5noK9JJWlXSupDsl3SHpdZJWl3SJpN/mn6v1q7BmZta9Xmv0JwO/iIhNgC2BO4BjgDkRsREwJz83M7MRUjnQS1oZ+GfgVICIeCYiHgf2Bc7Iu50B7NdrIc3MrLrxPaR9ObAIOE3SlsB84APAWhHxMEBEPCzpJa0SS5oJzARYb731eijG8Jt6zM9abr/vhL2GuSRmZsV6aboZD2wNfD0itgL+RhfNNBExKyKmRcS0yZMn91AMMzPrpJdAvxBYGBHX5ufnkgL/HyWtDZB/PtJbEc3MrBeVA31E/AF4UNLGedN04HbgAmBG3jYDmN1TCc3MrCe9tNEDvB84S9KywD3AoaSTxzmSDgceAA7oMQ8zM+tBT4E+Im4CprX40/ReXtfMzPrHM2PNzGrOgd7MrOYc6M3Maq7Xzlgrqd0kK/BEKzMbWq7Rm5nVnAO9mVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnNOdCbmdWcA72ZWc050JuZ1ZwDvZlZzTnQm5nVnAO9mVnNOdCbmdVcz4Fe0jhJN0q6MD/fQNK1kn4r6WxJy/ZeTDMzq6ofNfoPAHc0PT8R+GpEbAQ8BhzehzzMzKyingK9pCnAXsC383MBuwHn5l3OAPbrJQ8zM+tNrzX6k4CPAM/n52sAj0fE4vx8IfCyVgklzZQ0T9K8RYsW9VgMMzNrp3Kgl/Qm4JGImN+8ucWu0Sp9RMyKiGkRMW3y5MlVi2FmZgXG95B2R2AfSXsCE4GVSTX8VSWNz7X6KcBDvRfTzMyqqlyjj4hjI2JKREwF3gFcGhEHAXOB/fNuM4DZPZfSzMwqG4px9B8FjpZ0N6nN/tQhyMPMzErqpenmBRFxGXBZ/v0eYNt+vK6ZmfXOM2PNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Maq4vM2Nt6Ew95mctt993wl7DXBIzW1q5Rm9mVnOu0ddQu6sA8JWA2VjkQG+ATw5mdeamGzOzmnON3npSpbPYVw9mw8s1ejOzmnON3pYKvgowq841ejOzmnON3mqtypWArx6sbhzozfrEs5httHLTjZlZzTnQm5nVnAO9mVnNuY3ebAS549eGQ+VAL2ld4EzgpcDzwKyIOFnS6sDZwFTgPuBtEfFY70U1M/DJwbrXS9PNYuBDEfEqYHvgCEmbAscAcyJiI2BOfm5mZiOkco0+Ih4GHs6/PynpDuBlwL7ALnm3M4DLgI/2VEoz69lwzinwUNPRpS+dsZKmAlsB1wJr5ZNA42Twkn7kYWZm1fQc6CWtBJwH/EdEPNFFupmS5kmat2jRol6LYWZmbfQ06kbSBFKQPysizs+b/yhp7Yh4WNLawCOt0kbELGAWwLRp06KXcpjZ0m+0Ny0tzZ3glWv0kgScCtwREV9p+tMFwIz8+wxgdvXimZlZr3qp0e8IHAzcIummvO1jwAnAOZIOBx4ADuitiGZmS6/RcPXQy6ibKwG1+fP0qq9rZmb95SUQzMxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqbsgCvaTdJd0l6W5JxwxVPmZm1tmQBHpJ44D/AfYANgUOlLTpUORlZmadDVWNflvg7oi4JyKeAX4I7DtEeZmZWQeKiP6/qLQ/sHtEvCc/PxjYLiKObNpnJjAzP90YuKvNy60J/KnLIlRJM5x5jfbyDWdeo718w5nXaC/fcOY12ss3nHl1SrN+REwufIWI6PsDOAD4dtPzg4GvVXytecORZjjzGu3l82fhz2Kk8xrt5VsaPovmx1A13SwE1m16PgV4aIjyMjOzDoYq0F8PbCRpA0nLAu8ALhiivMzMrIPxQ/GiEbFY0pHAL4FxwHci4raKLzdrmNIMZ16jvXzDmddoL99w5jXayzeceY328g1nXlXL94Ih6Yw1M7PRwzNjzcxqzoHezKzmHOjNzGrOgd6sBiQtN9JlsNFr1AR6Sat3epR8jfUlvT7/vrykSUOUZmqLbduUKWM3JM0ps61N2q7el6TvltnWYp8Dymwb9PcNymxrk7b0+5I0TtL3yrzuoHTzJB0habUu0oyT9MUKeR3QeA+SPiHpfElbF6T5zqDnKwE/7zbvkuVbQdInJX0rP99I0ptGOi9JJ+afHY+1gvy6/R85T9JekoY8bkr6kqTN+vaCvc646tcDuBe4J/98jjTl99H8+70l0r+XNH7/d/n5RsCcfqfJ+90AvKzp+c7ALQVpXgnMAW7Nz7cAPtFm34nA6sACYLX8++rAVOCOIfosbhj0fBxwe5nPosy2EmnmD9H7+iWwbJfH4iuA44G7Ses0vZE8Qq0g3aVl9huU5ub8cyfgV6Q1oa4tSPM54Ov599WAq4BDS+RV+hhsSnM28JGmNMsDN5XIawPgK8D5pDk0FwAX9Csv4BZgQtGx1udj6fXAWcDvgBOATUrmNRE4Avhf4DuNR0Ga9wC/Bq4F3gesUuV9vvB6vSQeigfwDWDPpud7AF8uke4mYFngxuaDod9p8j7b5IPkpcCe+XXWLUhzOWmxt+a8bm2z7wdIJ7ynGTj53UsK/Ef287MAjgWeBBYDT+THk6ST7Oc75LEH8DXgj8ApTY/TgevapNkEeGv+R3lL0+PdwG1D9B1/M39XnwSObjxKHovLAPsAvwceBD4DrN5h/y+TAtrBze+vII8b88/PA+9s3laQ7sT8v3I98NaS76f0Mdj093mDywQsKJHXAuAoYFdSRWhnYOd+5QV8EfjLoOO2cew+MRTHUtN+q5CC74PkkywwocP+PyKdnH8HzAAuBk4umdfGpJPK/cD3gV3LpBv8GJIJUz3aJiLe13gSERdJ+lyJdE9HxDOSAJA0HiiaJFAlDRFxvaSjSF/YU8AbImJRQbIVIuK6Rl7Z4javfzJwsqT3R8TXisrTQun3FRGfBz4v6fMRcWwXeTwEzCMFwvlN258EPtgmzcbAm4BVgb0HpXlviTyrfF8P5ccyQGGzXIOkLUj/wHsC55FqcjuRau2vaZNsddIJcrembUGq1bbze0nfJNUWT8xt7S2bBiS9penpdaST13VASHpLRHTKB7o4Bps8I2n5/D6QtCGpAlLkqYg4pcR+VfP6RER8WNLsiKiyMm6l/31JawDvIp3Mb2TguJgB7NIm2Ssi4gBJ+0bEGZK+T7rSLMprHKlytAmphWMBcLSkf42IdxSlbzYaA/2fJH0C+B7pg38X6Z+nyOWSPgYsL+kNwL8DP+1nGkk/ZcmDYQVSreJUSUTEPh3y+lM+cBsH8f7Aw50KFxFfk7Q5aU3/iU3bz+z8tsq/L0mbRMSdwI9atQ1HxA1tyrYAWCDp+xHxbEF5GmlmA7MlvS4iri6TZpCuv+OI+AyApBUj4m9lMpE0H3gcOBU4JiIaweZaSTt2yOvQMq8/yNuA3YEvRcTjktYGPtxm370HPb+R1HyxN8UnFKhwDAKfBn4BrCvpLGBH0gmwyMmSjiNVhl4I1u2Opwp5XQ1sTarFV9H1sSTpfFLQ/S6wd0Q0PruzJc3rkLTx//F4/n/+A6kZtlNeXyFVouYA/x0R1+U/nSip3Uq/7V8vXx6MGkodr8cB/5w3XQF8JiL+XJBuGeBw4F8Akc6Y344Ob7DbNJJ27lSGiLi8Q14vJ01l3gF4jNQU866IuK9DmuNItYRNSZ1tewBXRsT+ncrRzfuSNCsiZkqa2/otxW4ttjen35H0D7o+qeKgnO7lHdJMJtXgp9JU2YiIw/r1vprSvI4UsFeKiPUkbQn8a0T8e4c0L4+IezqVpU26VwJfB9aKiM3zVcE+EfFfHdKs12p7RDzQbf4lytf1MZjTrQFsT/rMr4mIwmV2JX2eVOv9HfB83lzmeCqVl6RbSc03n6LFibHo6qbisbRnRPx80LblmioC7dK9h3RV+GpS0+ZKwKci4hsd0hwG/DAi/t7ib6tExF865fmiNKMt0DdIWhl4PiL+WnL/FUmXi8/l5+OA5Vp9UL2kyfttADwcEU/l58uT/rnvK1nOZSLiyRL73gJsSWpH3FLSWqSDcXDNbnC6NwM/LzoA+0HSnaSmmvmkjnMAIqLtVZikq0gdj4PTnFeQV5Xv+Fpgf1JH4FZ5260RsXmLfY/ulH9EfKWgfJeTgs43i/JqSnMLqYYt0lXbBsBdEdF2xEXVE2VT+m6OwTkRMb1oW4t0dwJbRLrxUCnd5CVpJ+Ag0hXR4AUTo0SlocqxdENEbF20rRetrqqbFVwRtTXqmm4kvRo4k9TeiaQ/ATMi4taCpHNI7ZyNE8PypMvGHfqcBlLnSvM+z+VtbYdYSloVOIT8z9loG4yIozrk84+IeF7S4nziewRoW1Nusg9wkqQrSKNGfhkRRW2xVGwm+ktEXFSiTM1WiIiPdpkGKn5fEfHgoHbp59rsWroNv42u28Aj4tXNz/M/+r8W5DObdKL8P9q/lxeR9N/AFyLi8fx8NeBDEfGJFvtOJDVNrpn3a7yplYF1SmS3gNQX80iJcnWdV0RcCVwpaV5EnFqiPIOVPpYkvRR4GamZZ6tB5VuhKCNJz5GuPo5tXDF0OEF8ucNLBUv2/5Q26gI9aZTE0RExF0DSLgxcbnYysbn2HxF/lVT0JVRJAzC+uaaSO3WWLUjzc+Aa0rCw5wv2bZiXTxCzSLXfv5KGW3UUEYdKmkBq6nkn8L+SLol8x69W2jUTkU66ncxVGj9+PuXbYi9sdRlcQpXv60FJO5A6LJcljQS5o9WOjfb8HlRpAx9chhtUPCej6olyj4j4WFNej0naE3hRoCedbP6DFGjnMxDcniDdD7rIWsCdkq5nyeOiVT9Wc17Nx01hXhFxasUKSjfH0htJI8OmkAJx82fxsTZpmt1G6mC/WNLbczO0Wu0YEbuWeL2ujcZAv2IjyANExGX5MqvI3yRt3Qgwkl4L/GMI0gAskrRPRFyQ0+1L8e3BJkZEx6aBFo4kBeq1gDcA65FG+RSKiGclXUQKOsuTxme3DfSk5o1GM9GhjWaiElltl39Oa86ezjWPDwAfk/Q0qaOq0a6/ckFeVb6v9wEnk2pkC0m1tiNa7Sip4yiRgqsv8uvOAjaR9HtSG/hBnRIMai5ahtTBWDSCq+qJclxzm3Jucmw5ozZ6H/l1XNkde8mrhwpK6WMpIs4AzpD0kYj4wqD8y0z0WxwRH5H0NuBXkg6hYIRPPukcDayX+9A2AjaOiAtL5Pfi1xttbfSSfkw6qzdmZb4LmBYR+xWk24bUTNG4k9XawNsjYn4/0+R0G5KGVa1DClIPAodExN0d0nyQVCO/kCVrOG07mSV9nVT73y0iXpUvay+OiI41Pkm7k272sitwGWkiysWdmm8kXR8R2yiNONmVNOTx1k5txcOt6vfVxevPyL/uSAocZ+fnB5AmdLUbNtpIPy4inuuyDbw5IC4G7gPOa/T/tEnzJLAi6TgqfaKU9BFSs95ppEBzGKnv4gsd0hwA/CIinlQaDbc18F9V24oLyndIq+2dauc99GNViRet2ujnR8RrC/K6sanPZjPgB6QAvmqHNGeTrqQOidSxvzxwdUS0G9rb0Wis0R9GmphyPukAvoISw7kijW3fhDRWW8CdUTDsr0qanO53wPZKU89V5h8aeIbUTvdxBs7mQec29+0iYmtJN+Z8HyvRRATpMvOHpNElZTtkr8/NRN9ioJnous5J0ggAlhwldTnw2SgYFZBPWhux5OX2FZ3SdPN9SfoaHWpNrWrnueaGpHeTJqY8m59/g3QlUOReSb8gnSAuLbF/8/DPSelp8eCDiKjUlxARX8iBcTrp8/tcRBSN5/5kRPwod36+EfgSaWTRdq12lnRlROyUT0bNn3+Zk1FzBWZiLucNdK6dV+rH6vJY2gTYDFhFS85lWJmm47eDw5vyvS1/lh0rrsCGEfF2SQfmdP/QoM6fboy6QB8RjwFHqctRN9nGDLTVbaU0tv1FB4mk3SLi0kFfGqTbHxYOzcqvsRfpy5+ogY7Vz3ZIcjRp4kQ3d4B/Vmk0QKPNdzIl2vcj4h25ZvOGXLbrIqKoU2wSqeZ6GWks88oRcXOJMn4HuJU0+gHSkLrTSLNCW1IabvYBUpvnTaThdFfTprmn4vfVGNfcsnZe8J7WIX0ejautlSjXAbkxaUz7EaS5FReShshd2S5Bbl/+LiUGHyjPeVCbkRllatmROs676TxvdPbuRVp2YbakT3d4/Z3yz65PRhHx/ubnuRJRtN5Sox+rVAWl4rHU60S/H0n6YuThlBHxRG7G6XQCqzpRrbWoMJ12KB+ksaY3kqb83k/68jYvke44YC5pSv5ppEkJ57bZ9zP552ktHh3XoMjpvpG/pAdzvrcApxakuYDUidbNZ3FQTreQtPbKXcABJdIdkD+7M3I57wX2L0izG2lM8iWksc/nAR8okdeL1iJptW3Q328hnYxvys83Ac7usP/g76uxXkjh95WPiQlNzycAcwvSHJo/v9Pz415S8O3mu1stf/bPFex3FU3T2kntzVe12XdW03sa/Li0RJneAvyWNMmv1HIBpKbGb+ZjYlVSm37hEgj9eOTvqnBtp6b9p5KGdHbap/L/PvC6iu/jTlJF4zTyuksULHNBGt9/Oam/5ixSk16l5Q8iYlQG+tIH/qB0t5A6sxbk52sBPy1IM65iGW8e9HMlUht4pzQ/Bn6T/2leWBumRF6bkGqIRwKvKlm+BcBLmp5PLvPPSVrIbHvS+jf3ky5ni9JcDezU9HxHUltipzTX5583kcYuQ7mFsiaSTn4fJ51gjyNNPOmU5i6a1qchBeC7SuT1UlIH9r7AS7s4NnYmLV51L3AOBevQtPpehiqQkhZpK3UMNaVZgXSC2Cg/Xxv4lyEq308ZWADtQtI6TycUpHnRQmSttg36+zLA2yqUr+tF4fJ+N+SfHyGNmlufEouxAWuQrqTeBKzZy2c76ppuqD7qpkpb3RJtqpE/3TJ55Z9/l7QOaYmGot73n+RHVyItT3Bnl8mWiSWbah6lYElqpeWPVyQF7l+R1hwqHANNGtVyZr7MhjTjckaH/QEW5svtnwCXSHqMgU6xTn5CWprgBgZGHxV9ZycAN2pg5u/OpJm8RcaRalPjgVdKemUU9CFIupd08joH+HCUW3LhHkmfZMnBB/cWJVIaMjqVJSdMFY00+WNEtBxa2k6kCUTnS3qJBmbxdns8lvWlpt8XA/dHxMJWO6qHcf45ThxJ+p668S3yhLj8OjcrrVvTduZzo7h5/y/kwQ6/JDfVtU0wMFHsZy22dW00BvpKBz5dttVlXbepZhfmvL7AQHtvx6GIkTv6hskvJP2S1LsP8HaK1yu/GXgtsDnp0v5xSVdHRMshZ1pyWOCZpJMEwN9IE1Hatu9HxJvzr5/OAXgVUr9AkSkRsXuJ/RplFGlS0UUMdB4eExF/KEh3Iukzu42m6fukgQGdbBkR3a690vXgA6X7BGxIOqk02tCD4iGF8/Jojp+w5Mivtn1SkvYhjR1fh1R5Wo8U6Ps+Gis6LCHSQqtx/kFqjvp/JdJfIuk/SZW8F07I0XmplSqLwkFqEm28/hxJb6RNZaiXE1gno2Z4paTvRsTBOYBMJa0IJ1I71WciddKWfa2plO9MbKRZjTTe+qCIGFew7/LAvwH/RDq4fkXqqHrRkDhJ50TE2zQw1b1ZRMSWZcvYDUlvJTWjCLgiIn5cMt1KpEDzn6Qmi5bjrJuGBW5MGi0xO+e1d86v5Zh9pTVGbo4OywJ0KNss4GsRcUsXaQqHv7VIcxeprbfKjlaWAAANKklEQVSrzi9VWOumCkl3AJt2cQXaSHdai80RHZYLkLSA1H/zfxGxlaRdgQMjYmZXhS5XvreQll9+CelYKhypI+lTwEmROjg/SRr++bko6JjOV18v+vyi8xpNF5GaUH8UaTTc/sDhEbFHm/277jyX9AEGTmDNV7lPAN+KiDInsZaZjYoHcDup7WoB6bJmDQZuuNFpDfCtOz1K5NtVm2pOcw5poaxd82MWcE6bfdduSrN+02NquzQj9PkfSard3E1qhzyONH6/KN3FwKSm55NI4647pTmLNI64yjHyDKnd/WZSv8zNBWn+h9QM1U0+F5EWQeu2fN3cc+Ck/LO5XbrsDTp+1DiuhuG4aKwRv4DUJAht7jfQh7yq9CE037jlCkrcuCXvvzzwIVLf2fmk9ZqWL0jzctIV4t9J9yi4Eli/w/7NneeXNj0KO8+B9/fzsx1NTTffIF2+v5yBoXEwcEnW7kzbvDZE8xm6ka7tDM2KbaqQZqg118Tn5prPi8TAUqaviIj7B+W/Scn8SmkxdvmFP1E8hnl50h2B5keJdXGarEcKvg3PULAEK6lD7zZJ17HkZXOnZZ4hzXrs1q7A+yTdl/NqfBZbdEjzd+Cm3G/R3MRRNDO2m0v7RtPkl9r8/UU0sEz2JOD2/PkVLS/QnL7KFcfj+SrvCuAsSY8wsOxuv3Xdh8CSwz+/EQXDP5ucQaolN2ZDH5i3va3VzvlKdFpEvF4lJ8TFwFXPnqRlkHeiqQWgTT67RcSlpPsUvGiIcpQY+t3KqAn0kW5ScIqkr0fEv3WRbld4oTml1IeZ9x8HnBadx763c6Ok7SPimvxa25Fu+9Uqn3/L5Xq5pOampEnt0lQVFSfS5LRd3+80+y5wndKM5gDeTPqH6aTSmjKDT5Ql7UEaafNP+fkVpA7dTho1626VXusmBmZgziMPJMhpxtFmWQLSSUGk5o3mCTeNbUWqdCYuIJ34Pkga8bQKaZTZUOi6D4EubtwySOnKWi7DCx24XVQIG1qdVM6k9UllZ1Ktv9XM3qD4ngMtjZo2+l5JOof0YZ6VNx0IrBoRLc/QOc3c6GIRoaZ29gmktukH8vP1SfdXbbX07SqkQPN54JimPz0ZBWvsLy1yG+QLgTQibhzJ8jTLbZ7vYaCzcz9SW2fHNVVyxWG9iCh9kwe1Xu/9oE4nKEnXAK+PPDEw154vjoi2i/ip9VT8mwuuUpqXuWiekn9TdJhWXzWvKir2IaxAunHLLRHxW6Ubt7w6IjrOZJZ0OukKoLmyNiM636fgk6QRd9104CJpwaCTSsttQ6lOgb7rD1PS8aQayuAvrmVHjqT1O5WhYo1zzBnUxLQs6cT5t4Kmpap53Uya6PK3/HxF0jj/toFK0t6k2vOyEbGBpNeQlnUoahpZjrQ43FRS39ITpEDV9qqxVaBtF3ybrw5JE5gaJgG/joh3FZSvdGdiU14bktrOu8prtMsd2o3KGqQmyDtIo6xaNu1V6cDN6U6n+5PKcqT7K09lySG0VVogRk/TTR+Ubk5p0qg1NX94bdv1Hcj7Y3ATk6T9SJ2YQ0EsuWb7cwwMWWvn07k8lwFExE0qt0rhbAbG+ZeZFwDdrcj5fVJHcdWrw1ara7YL2L3mVZryqpBqsz5Rib6RKkoP022yKS9uHm57l6gm2wGHSFripNJoIWhT6ZhNGuY8n16WPsjqVKPv+gxto4ekayJi+yF43aNJY5Ybw0v3A06PiJM6pLk2IrYb1MRRpmmk492k2qQZ0hU52+RZenXN4SBp74j4qdLqoa0CfdH8gGFRpXk4p+u6JaDKsdRJnWr0XZ+hlRb++m9gnYjYQ9KmpMv8KnessZIGjSZYhrSW/ZDUOCLiK5IuY2BexqEl+hBulfRO0vrtG5FuVnJVieyukvTq6GKcf1RcQbUbkt4VEd/ToFslamAxvo63SBxqEdG4KfftpBt5TGUgNpWZCDZcuurAbajYEtD1sdRJbQJ9xQ/zdNJCQx/Pz39Daq93oB9azSMKGmuw7ztUmeVmkW7WT38/6Zh4mjS7+JfA50qk2wl4d27LfZoOQznVhxVUu9CYtdzrrRKH2vdIo4K6uQvbcKrSPFxV6WOpjNo03VRRZRSCWTvtLtHbXJp/JiKOqzLSpGLZxgFHRcRX+/m6/aS8lv1Il6Od4Wwe7uZYKqM2NfqK/iZpDQbGPW9P6gCxIaS0nsfh5PX8G9v7Hdy6JemkiPgPDUxMWkLRqJtu/gkj4rj8s/CmOv0Q6c5X+wCjNtADx0n6Nmlmdtlx9MOpSgduVyStHGm9pL72n4z1QH80aWLMhpJ+TVrOd/+RLdKY8F3SwlhvJI14Oog2N+weZl3PVq1qcHv5YEPUbn6VpP9HyeHEI+BQ0rLcE1hyMblREeiHadTd90nLEs8nvffmEWKdVgjoaKwH+g1JMyfXJY1Z3Q5/JsPhFRFxgKR9I+KMPDuz6JZ2Qy4i5ucmjvcOwzjxkWgv72o48QjYMiJePdKFGGEn5J+vig73De7WWA9qjfthrkaaQv1lOtwP0/qmMarkcaVb6f2B4vVxhkVu4pgsadmIeKY4ReV8Ki0D0WOepWeBj5BrJG0aEbePdEFG0Mmk5cKvIi3M2BdjPdBXXRDJejMrn1w/QWo6Wwn45MgWaQn3Ab+WdAFLNnH0vTlFw7S0cc5rtA8n3gmY0a+RJkupZ3MH/RRJpwz+Y9XJY2N91M2FpOVGX086i/6DtATrsK1BMRZJ2iAi7i3aNtw0cE+Ex2nRaTkUtXBJl5MXGmsa+dXXyTJNeV1EHk4cEVtKGk9aUnlUNJf0e6TJ0kjSmuQF2mi6YUlDVLyB0Viv0b+N1JP+pYh4PC+I9OERLtNYcB4vviw9l3SyHUmvzcHmAaDjomd9VPWuRVWsGRHnSDoWICIWS3quKNFwGUsBvZ2I+BPwQ0l3REThZKyyxnSgj3w/zKbnD9NmWVnrXZ4BuhmwyqCJQivTNMxyBDXuibAB3d0ToRellzbuAw8nXnr8Q+l+CH1p0hvTTTc2vCTtS1prZh+WXO/9SdK9esssMzDk1OU9EXrMq+uljXvIa2vSlcrmwK3k4cTRxS03bXj0u0nPgd6GnaTXRcTVI12OkdRiHP3ypHV//gZDt/5MbpdvrKtzV7/X1bH+6Pes/TJ3YjHrtzdLWlnSBElzJP1J0lK9vnkFk/JjGulG86sBqwLvIy2H23d5RvJRpHV7PgMckbfZ6NPXJj3X6G3YNWomkt5Masr5IDB3LI52knQx6Yb0T+bnk0g3Bun7dPu8zO6TpMXDIC2zu1pEHNDvvKw3/W7SG9OdsTZiJuSfewI/iIg/Dxp1MpZUubl6VZWW2bXhM6hJ7+fAXAaa9N4KVGrSc6C3kfBTSXeS5i38u6TJQN+mey9lqtxcvarhXGbXqmksjbExsA3pTlMCDibd2L4SN93YiMgzY5/ISw6sCEyKiD+MdLlGgobp5urDucyu9abfTXqu0duwk7QC6f6l6wEzgXVIAejCkSzXSKlwY5SqhnyZXeubvjbpOdDbSDiNtAxrYzXFhcCPGKOBfhhtFBH/17xB0oyq0+ptSPW1Sc9NNzbsJM2LiGmDxggvGIujboaTpCuA24D/JC0k923g6YjwPRhGoX426blGbyPhGUnLMzBGeEOa7ihkQ2Zn4EPATfn5pyLiByNYHuugn016DvQ2rJTGUTbWlFlX0lnAjsC7R7JcY8RqpHst/A6YAqwvSeHL+tpz040NO0nzgX8BticNHbsmr9pnQ0jSb4ATIuI7+YrqRGBaROxQkNSWcg70Nuwk/Q9wekRcP9JlGUskrUdqvtkgIj6bn0+NiMrjs23p4EBvw07S7cArgftJM/7G4p2Ehp2kr5PGzO8WEa/KcxkujohtRrhoNsTcRm8jYY+RLsAYtV1EbC3pRoCIeEzSsiNdKBt6DvQ27HwnoRHzrKRxDIx2mkyq4VvNeZlis7HjFODHwEskHQ9cSbpZuNWc2+jNxpB8O8fppH6RORFxxwgXyYaBA72ZWc256cbMrOYc6M3Mas6B3qwPJO0iyatv2qjkQG9WQR6maLZUcKC3MUfSRyQdlX//qqRL8+/TJX1P0oGSbpF0q6QTm9L9VdJnJV0LvE7S7pLulHQl8JaReTdmxRzobSy6goF1vqcBK0maAOwE/Ja02NduwGuAbSTtl/ddEbg1IrYD5gHfAvbOr/XS4Su+WXcc6G0smg+8Nt+H82ngalLA/yfgceCyiFgUEYuBs4B/zumeA87Lv28C3BsRv83L/H5vON+AWTcc6G3MiYhngfuAQ4GrgF8BuwIbMnDj7Faeiojnml9qqMpo1k8O9DZWXUG6pd4VpED/PtKdl64Bdpa0Zu5wPRC4vEX6O4EN8t2xyPuZjUoO9DZW/QpYG7g6Iv4IPAX8KiIeBo4F5gILgBsiYvbgxBHxFDAT+FnujPVCbTZqeQkEM7Oac43ezKzmHOjNzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqzoHezKzm/j9ZBg/6pv5GFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-plot most frequent words\n",
    "\n",
    "all_lemmas = df['text_lemmas'].apply(list2string).str.split(expand=True).unstack().value_counts()\n",
    "all_lemmas = all_lemmas.to_frame().reset_index().rename(columns = {'index' : 'word', 0 : 'count'})\n",
    "\n",
    "# get 25 more frequent lemmas\n",
    "all_lemmas[:25].plot.bar(x='word')\n",
    "all_lemmas[:25].T\n",
    "\n",
    "# much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling with Latent Dirichlet Analysis (LDA)\n",
    "\n",
    "LDA is a topic discovery technique. It is a generative statistical topic model used to find accurate sets of topics within a given document set. The model assumes that text documents are comprised of a mixture of topics, and each topic is represented as the probability that each of given set of terms will occur. From there, using probability distributions the model can determine which topics are in a given document and which words are in a given topic based on word prevalence across topics and topic prevalence across document. A unique feature of LDA models is that topics are not required to be distinct, and words may occur in multiple topics\n",
    "\n",
    "Ref: \n",
    "\n",
    "https://medium.com/square-corner-blog/topic-modeling-optimizing-for-human-interpretability-48a81f6ce0ed\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note**: As of today, September 2018, there seems to be a bug introduced in a recent version of ```gensim```, the way it interacts with ```numpy``` which is used for all the computations. Downgrading to gensim 3.1.0 seems to solve the problem (ref: https://github.com/RaRe-Technologies/gensim/issues/2115).\n",
    "To do this please type ```$ pip install gensim==3.1.0``` in your Terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Create a dictionary containing the number of times a word appears in the corpus of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary = association word to numeric id\n",
    "# assigning a unique integer id to each unique word while also collecting word counts and relevant statistics. \n",
    "dictionary = corpora.Dictionary(df['text_lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640\n"
     ]
    }
   ],
   "source": [
    "# what's the vocabulary size?\n",
    "print(len(dictionary.token2id.keys()))\n",
    "\n",
    "# take a look (first 25 entries in the dictionary)\n",
    "#for k, v in dictionary.token2id.items(): \n",
    "#    print(\"{} : {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Filter out words that occur too frequently or too rarely.\n",
    "\n",
    "When dealing with a bigger corpus than the one used in his example, you may want to further clean the text data by excluding words that occur in:\n",
    "- less than X texts (absolute number) or (infrequent words)\n",
    "- more than 0.p documents (fraction of total corpus size, not absolute number) (too frequent words).\n",
    "- after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wordcount = 10\n",
    "max_freq = 0.6\n",
    "\n",
    "dictionary.filter_extremes(no_below=min_wordcount,\n",
    "                            no_above=max_freq,\n",
    "                            keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our dictionary size has become now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary.token2id.keys()))\n",
    "#...  too harsh filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) From texts as documents to Document Term Matrix\n",
    "\n",
    "Transform the collection of texts to a numerical form: For each text, report how many many times each occurring word appears. I.e., Convert the list of documents (corpus) into a Document Term Matrix using the dictionary prepared above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in df['text_lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "993\n",
      "[[(0, 1), (1, 1)], [], [(2, 1)], [(0, 1)], [(3, 1), (4, 1), (5, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(type(bow_corpus))\n",
    "print(len(bow_corpus))\n",
    "print(bow_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 text text_lemmas\n",
      "1  Crust is not good.  [crust]   \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at how the 1st text looks like: [(word_id, count), ...]\n",
    "\n",
    "print( df[['text', 'text_lemmas']][1:2] )\n",
    "print( bow_corpus[1] )\n",
    "\n",
    "for i in range(len(bow_corpus[1])):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_corpus[1][i][0],\n",
    "          dictionary[bow_corpus[1][i][0]], \n",
    "          bow_corpus[1][i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Find the best number of topics\n",
    "\n",
    "#### Perplexity\n",
    "\n",
    "Perplexity is a standard measure for estimating the performance of a probabilistic model: it measures how well the probabilistic model predicts a sample. The perplexity of a set of test words, is defined as the exponential of the negative normalized predictive likelihood under the model. \n",
    "\n",
    "One should expect \"in-sample\" perplexity to improve with more topics, but that the improvement would level off as the model captures all but the most trivial structures in the data. So the ideal number of topics should be the poin where perplexity starts to level off. \n",
    "\n",
    "Ref: \n",
    "\n",
    "https://docs.google.com/viewer?a=v&pid=forums&srcid=MDEwMDM0NjcxOTk3Njc0MTA0MjMBMTQzMzY3Nzc1NTMzNDgyNjIyMzEBZnBOMFVLSG9BZ0FKATAuMwEBdjI&authuser=0\n",
    "\n",
    "https://groups.google.com/forum/#!topic/gensim/BDuOnCGpgOs\n",
    "\n",
    "http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
    "\n",
    "https://groups.google.com/forum/#!topic/gensim/TpuYRxhyIOc\n",
    "\n",
    "\n",
    "**Important**: However, please note that it has been shown that perplexity doesn't correlate well with human judgements of topic coherence. \n",
    "\n",
    "Other coherence measures have been suggested that have performed better. Example: https://www.kdnuggets.com/2016/07/americas-next-topic-model.html\n",
    "\n",
    "\n",
    "TODO: turn this into a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# (i) divide corpus in training and test corpus. The test corpus will be used to calculate perplexity\n",
    "    \n",
    "shuffle(bow_corpus)\n",
    "\n",
    "train_corpus, test_corpus = bow_corpus[:800], bow_corpus[800:]\n",
    "\n",
    "# Number of words in the training set and in the test set\n",
    "print(sum(cnt for document in train_corpus for _, cnt in document))\n",
    "print(sum(cnt for document in test_corpus for _, cnt in document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(19, 1), (45, 1)], [(15, 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of topics :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-word likelihood bound      -6.057575934881151\n",
      "perplexity : exp(-bound)                              427.3382844753499\n",
      "elapsed time: 3.489\n",
      " \n",
      "number of topics :  3\n",
      "per-word likelihood bound      -6.240780424114853\n",
      "perplexity : exp(-bound)                              513.2589143141769\n",
      "elapsed time: 3.228\n",
      " \n",
      "number of topics :  4\n",
      "per-word likelihood bound      -6.35142970354262\n",
      "perplexity : exp(-bound)                              573.3117892493092\n",
      "elapsed time: 3.372\n",
      " \n",
      "number of topics :  5\n",
      "per-word likelihood bound      -6.458772560126805\n",
      "perplexity : exp(-bound)                              638.2771287578629\n",
      "elapsed time: 3.418\n",
      " \n",
      "number of topics :  7\n",
      "per-word likelihood bound      -6.477651982502794\n",
      "perplexity : exp(-bound)                              650.4419028944502\n",
      "elapsed time: 3.483\n",
      " \n",
      "number of topics :  8\n",
      "per-word likelihood bound      -6.490411871153375\n",
      "perplexity : exp(-bound)                              658.7946458552644\n",
      "elapsed time: 3.643\n",
      " \n",
      "number of topics :  9\n",
      "per-word likelihood bound      -6.542932365550644\n",
      "perplexity : exp(-bound)                              694.3195946662776\n",
      "elapsed time: 3.845\n",
      " \n",
      "number of topics :  10\n",
      "per-word likelihood bound      -6.556032855112723\n",
      "perplexity : exp(-bound)                              703.4753628471663\n",
      "elapsed time: 3.757\n",
      " \n",
      "number of topics :  15\n",
      "per-word likelihood bound      -6.316640971795373\n",
      "perplexity : exp(-bound)                              553.7099378782061\n",
      "elapsed time: 3.616\n",
      " \n",
      "number of topics :  20\n",
      "per-word likelihood bound      -6.390093181244905\n",
      "perplexity : exp(-bound)                              595.9121049328121\n",
      "elapsed time: 3.483\n",
      " \n",
      "number of topics :  25\n",
      "per-word likelihood bound      -6.472888055453731\n",
      "perplexity : exp(-bound)                              647.3506143024748\n",
      "elapsed time: 3.784\n",
      " \n",
      "number of topics :  30\n",
      "per-word likelihood bound      -6.510781318846355\n",
      "perplexity : exp(-bound)                              672.3515333473423\n",
      "elapsed time: 3.844\n",
      " \n",
      "number of topics :  35\n",
      "per-word likelihood bound      -6.101530494897262\n",
      "perplexity : exp(-bound)                              446.54067558292076\n",
      "elapsed time: 3.715\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# (ii) loop on training set for several numbers of topics: \n",
    "topics_seq = list((2,3,4,5,7,8,9,10, 15, 20, 25, 30, 35))\n",
    "\n",
    "results_perplexity = {}\n",
    "for topic_n in topics_seq:\n",
    "    start_time = time.time()\n",
    "    # run model\n",
    "    print('number of topics :  %d' % topic_n)\n",
    "    \n",
    "    model = models.LdaModel(corpus=train_corpus\n",
    "                             , num_topics=topic_n\n",
    "                             , id2word=dictionary\n",
    "                             , passes = 20  # as we have a small corpus\n",
    "                             , eta = 0.01 # topics are known to be word-sparse, the Dirichlet parameter of the word distributions is set small (e.g., 0.01), in which case learning is efficient.\n",
    "                             , alpha = 0.1    #believed that each document is associated with few topics\n",
    "                             , random_state = 1\n",
    "                             )\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # perplexity on hold-out test data\n",
    "    log_perplexity = model.log_perplexity(test_corpus)              # this is actually per-word likelihood bound\n",
    "    perplexity_test = np.exp(-log_perplexity.astype(np.float64))    # https://stats.stackexchange.com/a/324243\n",
    "    \n",
    "    print('per-word likelihood bound     ', log_perplexity)\n",
    "    print('perplexity : exp(-bound)                             ', perplexity_test)\n",
    "    print('elapsed time: %.3f' % elapsed)  \n",
    "    print( ' ')\n",
    "    results_perplexity[topic_n] = perplexity_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 427.3382844753499,\n",
       " 3: 513.2589143141769,\n",
       " 4: 573.3117892493092,\n",
       " 5: 638.2771287578629,\n",
       " 7: 650.4419028944502,\n",
       " 8: 658.7946458552644,\n",
       " 9: 694.3195946662776,\n",
       " 10: 703.4753628471663,\n",
       " 15: 553.7099378782061,\n",
       " 20: 595.9121049328121,\n",
       " 25: 647.3506143024748,\n",
       " 30: 672.3515333473423,\n",
       " 35: 446.54067558292076}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f64bbe37198>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of perplexity versus number of topics\n",
    "plt.plot(results_perplexity.keys(), results_perplexity.values(), 'r--',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Perplexity')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.grid(True) \n",
    "plt.show()\n",
    "\n",
    "# Perplexiy seems to suggest 8 topics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Build an lda model with the suggested number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "# Build the lda model with the suggested number of topics\n",
    "\n",
    "NUM_TOPICS = 8\n",
    "\n",
    "lda_model_1 = models.LdaModel(corpus=bow_corpus\n",
    "                             , num_topics=NUM_TOPICS\n",
    "                             , id2word=dictionary\n",
    "                             , passes = 20  # as we have a small corpus\n",
    "                             , eta = 0.01 # topics are known to be word-sparse, the Dirichlet parameter of the word distributions is set small (e.g., 0.01), in which case learning is efficient.\n",
    "                             , alpha = 0.1    #believed that each document is associated with few topics\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Explore topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the topics, we will look at each topic in terms of the words it has the highest probability to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.194*\"time\" + 0.133*\"order\" + 0.108*\"experience\" + 0.087*\"chicken\" + 0.078*\"place\"\n",
      "Topic #1: 0.438*\"place\" + 0.135*\"eat\" + 0.107*\"delicious\" + 0.105*\"food\" + 0.051*\"awesome\"\n",
      "Topic #2: 0.349*\"food\" + 0.294*\"service\" + 0.067*\"minute\" + 0.046*\"thing\" + 0.042*\"buffet\"\n",
      "Topic #3: 0.155*\"wait\" + 0.151*\"restaurant\" + 0.113*\"im\" + 0.086*\"salad\" + 0.086*\"menu\"\n",
      "Topic #4: 0.120*\"dont\" + 0.102*\"taste\" + 0.092*\"pretty\" + 0.088*\"pizza\" + 0.082*\"dish\"\n",
      "Topic #5: 0.107*\"steak\" + 0.101*\"disappointed\" + 0.097*\"burger\" + 0.088*\"flavor\" + 0.088*\"fresh\"\n",
      "Topic #6: 0.310*\"back\" + 0.129*\"never\" + 0.113*\"think\" + 0.093*\"definitely\" + 0.093*\"wont\"\n",
      "Topic #7: 0.150*\"nice\" + 0.145*\"friendly\" + 0.106*\"staff\" + 0.100*\"star\" + 0.089*\"give\"\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# (iv) Explore Topics\n",
    "\n",
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(NUM_TOPICS):\n",
    "    # Print the first 5 most representative words for each topic\n",
    "    print(\"Topic #%s:\" % idx, lda_model_1.print_topic(idx, 5))\n",
    " \n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Really hard to understand the topics...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python package ```pyLDAvis``` is designed to help the interpretion of the topics in a topic model. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization (https://datascienceplus.com/topic-modeling-in-python-with-nltk-and-gensim/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaela/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el118821400705981984008247933659\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el118821400705981984008247933659_data = {\"mdsDat\": {\"x\": [-0.15638072197264868, -0.2396122742456624, -0.23869125293260618, -0.05816540127108414, 0.1617769402108131, 0.2538925074775487, 0.1497555779881664, 0.12742462474547306], \"y\": [-0.1647612119052861, 0.13417393367875743, 0.15239696265152902, -0.205614752661291, 0.06991820213069916, 0.19067134463667518, -0.2863326615524874, 0.10954818302140348], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [11.83181381225586, 13.376872062683105, 16.178890228271484, 12.052549362182617, 12.523614883422852, 10.690020561218262, 12.016288757324219, 11.329939842224121]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Freq\": [110.0, 114.0, 76.0, 60.0, 54.0, 30.0, 29.0, 27.0, 26.0, 31.0, 25.0, 25.0, 27.0, 22.0, 23.0, 22.0, 20.0, 20.0, 19.0, 18.0, 19.0, 17.0, 18.0, 18.0, 18.0, 17.0, 17.0, 16.0, 16.0, 16.0, 20.50140380859375, 16.581750869750977, 12.697341918945312, 25.278621673583984, 9.766222953796387, 11.681326866149902, 12.636419296264648, 8.78903865814209, 8.796307563781738, 37.008445739746094, 6.601563453674316, 1.9957592487335205, 14.843452453613281, 1.4800970554351807, 0.9860948920249939, 0.09032408893108368, 0.04196183755993843, 0.049011893570423126, 0.01984412781894207, 0.01348685659468174, 0.017328636720776558, 0.00976424477994442, 0.00976425688713789, 0.009764233604073524, 0.011781645938754082, 0.009764239192008972, 0.00976424477994442, 0.0097642308101058, 0.01046767458319664, 0.009764251299202442, 0.02322714403271675, 0.013813517056405544, 0.017819063737988472, 0.010255306027829647, 0.013626309111714363, 0.012354311533272266, 0.013799471780657768, 0.0112081840634346, 0.013642975129187107, 0.011251397430896759, 23.135967254638672, 9.975129127502441, 29.032745361328125, 11.065448760986328, 94.23704528808594, 9.053986549377441, 7.844272136688232, 2.022761106491089, 2.284282922744751, 22.5137939453125, 2.0251331329345703, 1.056514024734497, 0.12432508915662766, 0.159878671169281, 0.0541265495121479, 0.037853363901376724, 0.029679138213396072, 0.013442093506455421, 0.011084071360528469, 0.010578181594610214, 0.01830345019698143, 0.010283306241035461, 0.01007232815027237, 0.010072323493659496, 0.010072334669530392, 0.010072359815239906, 0.010578086599707603, 0.01007236260920763, 0.01007235050201416, 0.010072332806885242, 0.016626480966806412, 0.01778857782483101, 0.013336032629013062, 0.013449877500534058, 0.013959339819848537, 0.012448573485016823, 0.011450236663222313, 0.016520850360393524, 0.01678670197725296, 0.012786973267793655, 0.01217658817768097, 0.01344317477196455, 0.017837218940258026, 76.61416625976562, 17.36445426940918, 11.885284423828125, 10.972594261169434, 10.033708572387695, 9.14600658416748, 90.91332244873047, 9.032017707824707, 5.712532997131348, 8.22946548461914, 3.8498706817626953, 2.6692733764648438, 2.2751505374908447, 0.3606524169445038, 0.20931772887706757, 0.22206060588359833, 0.08008743077516556, 0.0702674388885498, 0.0731433779001236, 0.02239183895289898, 0.10524604469537735, 0.0298411026597023, 0.016804704442620277, 0.018434518948197365, 0.014909853227436543, 0.01396750845015049, 0.011169926263391972, 0.009704005904495716, 0.009137943387031555, 0.009137950837612152, 0.018163809552788734, 0.02186710759997368, 0.021327167749404907, 0.011556064710021019, 29.324583053588867, 16.727170944213867, 16.724090576171875, 30.1489315032959, 13.568471908569336, 14.594298362731934, 21.848857879638672, 13.846288681030273, 10.239703178405762, 2.1983542442321777, 3.387615203857422, 11.760429382324219, 5.828700542449951, 1.0582327842712402, 0.7299578189849854, 0.1918131560087204, 0.7432754635810852, 0.08853109180927277, 0.05178695544600487, 0.03449607640504837, 0.03171634301543236, 0.019608573988080025, 0.036221813410520554, 0.04170077666640282, 0.15821485221385956, 0.017107021063566208, 0.013706039637327194, 0.011530537158250809, 0.011241268366575241, 0.01107269711792469, 0.06058482080698013, 0.012645009905099869, 0.01975954696536064, 0.01467577088624239, 20.61682891845703, 17.674983978271484, 15.711435317993164, 18.591354370117188, 10.79422378540039, 9.815707206726074, 16.542137145996094, 9.60775375366211, 24.133182525634766, 11.74757194519043, 7.758728504180908, 5.899846076965332, 16.310504913330078, 4.917716026306152, 4.88567590713501, 4.917695045471191, 0.6528312563896179, 0.17877444624900818, 0.07653122395277023, 0.06770393997430801, 0.037892334163188934, 0.02988843061029911, 0.016692008823156357, 0.08296358585357666, 0.010312302969396114, 0.011427928693592548, 0.009819263592362404, 0.00981925055384636, 0.009819253347814083, 0.010312448255717754, 0.014247703365981579, 0.010387670248746872, 0.011806397698819637, 0.01182514987885952, 0.012682219967246056, 0.011270193383097649, 0.012745850719511509, 17.345623016357422, 15.184192657470703, 15.182104110717773, 10.850467681884766, 10.847213745117188, 11.885215759277344, 12.868340492248535, 12.745203971862793, 16.630321502685547, 18.350406646728516, 10.12474250793457, 5.14481782913208, 3.2808218002319336, 2.179642677307129, 2.178948163986206, 2.1781113147735596, 2.2210800647735596, 1.756812572479248, 0.23793797194957733, 0.10273535549640656, 0.08980207145214081, 0.0148868253454566, 0.020937874913215637, 0.01141063030809164, 0.011385459452867508, 0.013204308226704597, 0.01084108091890812, 0.011930120177567005, 0.01084107719361782, 0.01084106508642435, 0.0533951073884964, 0.013603327795863152, 0.011941350065171719, 0.01426434051245451, 0.013165059499442577, 0.014333232305943966, 0.01623961329460144, 59.93357849121094, 24.966171264648438, 17.983503341674805, 17.983184814453125, 21.954444885253906, 13.992928504943848, 9.299120903015137, 11.920598983764648, 4.005354404449463, 3.3984999656677246, 5.173187732696533, 1.40449857711792, 0.14772920310497284, 0.07346221804618835, 0.07629650086164474, 0.08001620322465897, 0.03287564590573311, 0.07711134850978851, 0.01790618896484375, 0.16753213107585907, 0.014121973887085915, 0.015350865200161934, 0.012021583504974842, 0.016379613429307938, 0.013440639711916447, 0.018054703250527382, 0.010584646835923195, 0.009989545680582523, 0.009989532642066479, 0.00998953077942133, 0.07574527710676193, 0.014158318750560284, 0.05390013009309769, 0.013825605623424053, 0.01312247198075056, 26.44052505493164, 19.32545280456543, 18.310277938842773, 16.25345802307129, 27.294950485229492, 9.11939811706543, 8.144514083862305, 10.151265144348145, 10.1749906539917, 8.157970428466797, 10.178064346313477, 4.079451084136963, 4.59375524520874, 3.060701370239258, 2.0443179607391357, 2.222050666809082, 0.5619317889213562, 1.0981390476226807, 0.0906694307923317, 0.05248989537358284, 0.33354824781417847, 0.024329695850610733, 0.049070727080106735, 0.020542696118354797, 0.012578834779560566, 0.012913843616843224, 0.011911369860172272, 0.010779352858662605, 0.014973950572311878, 0.010679281316697598, 0.026088114827871323, 0.014780109748244286, 0.013928365893661976, 0.015173294581472874, 0.013695268891751766], \"Term\": [\"place\", \"food\", \"service\", \"back\", \"time\", \"wait\", \"restaurant\", \"nice\", \"friendly\", \"eat\", \"order\", \"never\", \"dont\", \"think\", \"delicious\", \"im\", \"experience\", \"taste\", \"staff\", \"star\", \"steak\", \"disappointed\", \"pretty\", \"definitely\", \"wont\", \"pizza\", \"burger\", \"give\", \"chicken\", \"salad\", \"experience\", \"chicken\", \"recommend\", \"order\", \"amazing\", \"night\", \"sushi\", \"still\", \"atmosphere\", \"time\", \"quality\", \"fry\", \"place\", \"vega\", \"awesome\", \"find\", \"feel\", \"steak\", \"dish\", \"bland\", \"salad\", \"serve\", \"excellent\", \"side\", \"cant\", \"worth\", \"slow\", \"meat\", \"everything\", \"perfect\", \"dont\", \"wont\", \"restaurant\", \"buffet\", \"think\", \"pretty\", \"nice\", \"menu\", \"back\", \"friendly\", \"delicious\", \"find\", \"eat\", \"awesome\", \"place\", \"wasnt\", \"love\", \"meat\", \"next\", \"food\", \"selection\", \"steak\", \"cook\", \"dish\", \"night\", \"salad\", \"chicken\", \"enjoy\", \"excellent\", \"amazing\", \"burger\", \"serve\", \"side\", \"worth\", \"slow\", \"perfect\", \"atmosphere\", \"still\", \"leave\", \"everything\", \"definitely\", \"taste\", \"fresh\", \"take\", \"pizza\", \"table\", \"sushi\", \"nice\", \"restaurant\", \"menu\", \"flavor\", \"im\", \"service\", \"service\", \"minute\", \"thing\", \"buffet\", \"slow\", \"selection\", \"food\", \"vega\", \"quality\", \"price\", \"feel\", \"serve\", \"bland\", \"cook\", \"server\", \"wait\", \"table\", \"pretty\", \"nice\", \"side\", \"time\", \"give\", \"excellent\", \"didnt\", \"next\", \"cant\", \"enjoy\", \"amazing\", \"worth\", \"find\", \"experience\", \"order\", \"never\", \"chicken\", \"restaurant\", \"salad\", \"menu\", \"wait\", \"amaze\", \"table\", \"im\", \"server\", \"feel\", \"serve\", \"vega\", \"time\", \"love\", \"wasnt\", \"worth\", \"enough\", \"food\", \"try\", \"cant\", \"awesome\", \"know\", \"bland\", \"think\", \"order\", \"place\", \"quality\", \"leave\", \"amazing\", \"side\", \"slow\", \"service\", \"thing\", \"dont\", \"friendly\", \"taste\", \"pizza\", \"take\", \"pretty\", \"enjoy\", \"excellent\", \"dish\", \"side\", \"dont\", \"fry\", \"bland\", \"meat\", \"love\", \"serve\", \"know\", \"way\", \"burger\", \"cook\", \"enough\", \"amaze\", \"slow\", \"wasnt\", \"still\", \"time\", \"worth\", \"tasty\", \"amazing\", \"find\", \"perfect\", \"buffet\", \"im\", \"awesome\", \"server\", \"think\", \"eat\", \"steak\", \"service\", \"disappointed\", \"flavor\", \"fresh\", \"everything\", \"leave\", \"cant\", \"fantastic\", \"enough\", \"burger\", \"steak\", \"cook\", \"next\", \"didnt\", \"meat\", \"perfect\", \"atmosphere\", \"tasty\", \"bland\", \"side\", \"nice\", \"order\", \"amazing\", \"salad\", \"find\", \"slow\", \"night\", \"serve\", \"enjoy\", \"excellent\", \"worth\", \"service\", \"dish\", \"recommend\", \"never\", \"pretty\", \"eat\", \"back\", \"back\", \"never\", \"definitely\", \"wont\", \"think\", \"meal\", \"worth\", \"try\", \"next\", \"dont\", \"time\", \"vega\", \"fantastic\", \"sushi\", \"server\", \"im\", \"find\", \"love\", \"enjoy\", \"food\", \"excellent\", \"bland\", \"amazing\", \"fry\", \"recommend\", \"disappointed\", \"perfect\", \"serve\", \"side\", \"slow\", \"service\", \"way\", \"place\", \"minute\", \"take\", \"friendly\", \"staff\", \"star\", \"give\", \"nice\", \"tasty\", \"perfect\", \"didnt\", \"way\", \"know\", \"price\", \"try\", \"server\", \"wasnt\", \"still\", \"eat\", \"time\", \"place\", \"im\", \"menu\", \"food\", \"worth\", \"delicious\", \"enough\", \"serve\", \"meat\", \"enjoy\", \"side\", \"fry\", \"find\", \"dont\", \"burger\", \"chicken\", \"restaurant\", \"service\"], \"Total\": [110.0, 114.0, 76.0, 60.0, 54.0, 30.0, 29.0, 27.0, 26.0, 31.0, 25.0, 25.0, 27.0, 22.0, 23.0, 22.0, 20.0, 20.0, 19.0, 18.0, 19.0, 17.0, 18.0, 18.0, 18.0, 17.0, 17.0, 16.0, 16.0, 16.0, 20.58453369140625, 16.680110931396484, 12.773942947387695, 25.4763126373291, 9.844932556152344, 11.798864364624023, 12.775225639343262, 10.901759147644043, 11.036210060119629, 54.716285705566406, 12.383338928222656, 13.8162260055542, 110.4227294921875, 15.346185684204102, 12.13709831237793, 10.14985466003418, 14.183932304382324, 19.50936508178711, 16.776851654052734, 11.859548568725586, 16.843936920166016, 9.838801383972168, 9.898970603942871, 9.919930458068848, 12.002801895141602, 10.103536605834961, 10.134055137634277, 10.154533386230469, 10.92113208770752, 10.383318901062012, 27.632661819458008, 18.061199188232422, 29.41794204711914, 11.045944213867188, 22.05824851989746, 18.73244857788086, 27.5336971282959, 16.84370994567871, 60.01734924316406, 26.51853370666504, 23.246917724609375, 10.14985466003418, 31.325210571289062, 12.13709831237793, 110.4227294921875, 13.24323558807373, 30.101755142211914, 10.154533386230469, 11.490106582641602, 114.70419311523438, 11.232736587524414, 19.50936508178711, 10.829421997070312, 16.776851654052734, 11.798864364624023, 16.843936920166016, 16.680110931396484, 10.881644248962402, 9.898970603942871, 9.844932556152344, 17.357746124267578, 9.838801383972168, 9.919930458068848, 10.103536605834961, 10.134055137634277, 10.383318901062012, 11.036210060119629, 10.901759147644043, 10.92098617553711, 10.92113208770752, 18.061416625976562, 20.700775146484375, 15.257206916809082, 15.791077613830566, 17.754920959472656, 14.739169120788574, 12.775225639343262, 27.5336971282959, 29.41794204711914, 16.84370994567871, 15.257333755493164, 22.078033447265625, 76.85855102539062, 76.85855102539062, 17.442964553833008, 11.959976196289062, 11.045944213867188, 10.134055137634277, 11.232736587524414, 114.70419311523438, 15.346185684204102, 12.383338928222656, 18.47332763671875, 14.183932304382324, 9.838801383972168, 11.859548568725586, 10.829421997070312, 18.768688201904297, 30.435544967651367, 14.739169120788574, 18.73244857788086, 27.5336971282959, 9.919930458068848, 54.716285705566406, 16.34765625, 9.898970603942871, 13.501193046569824, 11.490106582641602, 12.002801895141602, 10.881644248962402, 9.844932556152344, 10.103536605834961, 10.14985466003418, 20.58453369140625, 25.4763126373291, 25.053098678588867, 16.680110931396484, 29.41794204711914, 16.843936920166016, 16.84370994567871, 30.435544967651367, 13.697973251342773, 14.739169120788574, 22.078033447265625, 18.768688201904297, 14.183932304382324, 9.838801383972168, 15.346185684204102, 54.716285705566406, 30.101755142211914, 13.24323558807373, 10.103536605834961, 13.075302124023438, 114.70419311523438, 16.138784408569336, 12.002801895141602, 12.13709831237793, 13.126535415649414, 11.859548568725586, 22.05824851989746, 25.4763126373291, 110.4227294921875, 12.383338928222656, 10.92098617553711, 9.844932556152344, 9.919930458068848, 10.134055137634277, 76.85855102539062, 11.959976196289062, 27.632661819458008, 26.51853370666504, 20.700775146484375, 17.754920959472656, 15.791077613830566, 18.73244857788086, 10.881644248962402, 9.898970603942871, 16.776851654052734, 9.919930458068848, 27.632661819458008, 13.8162260055542, 11.859548568725586, 10.154533386230469, 30.101755142211914, 9.838801383972168, 13.126535415649414, 15.158416748046875, 17.357746124267578, 10.829421997070312, 13.075302124023438, 13.697973251342773, 10.134055137634277, 13.24323558807373, 10.901759147644043, 54.716285705566406, 10.103536605834961, 11.402645111083984, 9.844932556152344, 10.14985466003418, 10.383318901062012, 11.045944213867188, 22.078033447265625, 12.13709831237793, 18.768688201904297, 22.05824851989746, 31.325210571289062, 19.50936508178711, 76.85855102539062, 17.424972534179688, 15.257333755493164, 15.257206916809082, 10.92113208770752, 10.92098617553711, 12.002801895141602, 13.077532768249512, 13.075302124023438, 17.357746124267578, 19.50936508178711, 10.829421997070312, 11.490106582641602, 13.501193046569824, 10.154533386230469, 10.383318901062012, 11.036210060119629, 11.402645111083984, 11.859548568725586, 9.919930458068848, 27.5336971282959, 25.4763126373291, 9.844932556152344, 16.843936920166016, 10.14985466003418, 10.134055137634277, 11.798864364624023, 9.838801383972168, 10.881644248962402, 9.898970603942871, 10.103536605834961, 76.85855102539062, 16.776851654052734, 12.773942947387695, 25.053098678588867, 18.73244857788086, 31.325210571289062, 60.01734924316406, 60.01734924316406, 25.053098678588867, 18.061416625976562, 18.061199188232422, 22.05824851989746, 14.065574645996094, 10.103536605834961, 16.138784408569336, 11.490106582641602, 27.632661819458008, 54.716285705566406, 15.346185684204102, 13.077532768249512, 12.775225639343262, 18.768688201904297, 22.078033447265625, 10.14985466003418, 30.101755142211914, 10.881644248962402, 114.70419311523438, 9.898970603942871, 11.859548568725586, 9.844932556152344, 13.8162260055542, 12.773942947387695, 17.424972534179688, 10.383318901062012, 9.838801383972168, 9.919930458068848, 10.134055137634277, 76.85855102539062, 15.158416748046875, 110.4227294921875, 17.442964553833008, 15.791077613830566, 26.51853370666504, 19.40045928955078, 18.38360023498535, 16.34765625, 27.5336971282959, 11.402645111083984, 10.383318901062012, 13.501193046569824, 15.158416748046875, 13.126535415649414, 18.47332763671875, 16.138784408569336, 18.768688201904297, 13.24323558807373, 10.901759147644043, 31.325210571289062, 54.716285705566406, 110.4227294921875, 22.078033447265625, 16.84370994567871, 114.70419311523438, 10.103536605834961, 23.246917724609375, 13.075302124023438, 9.838801383972168, 10.154533386230469, 10.881644248962402, 9.919930458068848, 13.8162260055542, 10.14985466003418, 27.632661819458008, 17.357746124267578, 16.680110931396484, 29.41794204711914, 76.85855102539062], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1303000450134277, 2.128499984741211, 2.1284000873565674, 2.1266000270843506, 2.1263999938964844, 2.1243999004364014, 2.123500108718872, 1.9190000295639038, 1.9075000286102295, 1.743399977684021, 1.5053000450134277, 0.1995999962091446, 0.12759999930858612, -0.20440000295639038, -0.375900000333786, -2.587399959564209, -3.688699960708618, -3.8522000312805176, -4.605500221252441, -4.644800186157227, -4.744999885559082, -4.781000137329102, -4.787099838256836, -4.7891998291015625, -4.791999816894531, -4.807499885559082, -4.8105998039245605, -4.812600135803223, -4.815800189971924, -4.834799766540527, -4.9471001625061035, -5.041500091552734, -5.274700164794922, -4.847599983215332, -5.255099773406982, -5.189599990844727, -5.464200019836426, -5.180699825286865, -6.254799842834473, -5.63070011138916, 2.0069000720977783, 1.9943000078201294, 1.9356000423431396, 1.9191999435424805, 1.8530999422073364, 1.6313999891281128, 0.6668000221252441, 0.39820000529289246, 0.3962000012397766, 0.38339999318122864, 0.29840001463890076, -0.9042999744415283, -2.4554998874664307, -2.641700029373169, -3.37280011177063, -4.086400032043457, -4.319900035858154, -4.684800148010254, -4.7829999923706055, -4.8242998123168945, -4.843100070953369, -4.851900100708008, -4.880899906158447, -4.899199962615967, -4.902200222015381, -4.926499843597412, -4.938499927520752, -4.975200176239014, -4.9770002365112305, -4.9770002365112305, -4.978899955749512, -5.047699928283691, -5.030700206756592, -5.056600093841553, -5.136600017547607, -5.065000057220459, -5.0055999755859375, -5.406899929046631, -5.457099914550781, -5.1717000007629395, -5.121699810028076, -5.392199993133545, -6.356800079345703, 1.8183000087738037, 1.8170000314712524, 1.8151999711990356, 1.8148000240325928, 1.8114999532699585, 1.6159000396728516, 1.5889999866485596, 1.2913999557495117, 1.0477999448776245, 1.0128999948501587, 0.5174000263214111, 0.5169000029563904, 0.1703999936580658, -1.5806000232696533, -2.6745998859405518, -3.0989999771118164, -3.393699884414673, -3.76419997215271, -4.109300136566162, -4.27209997177124, -4.432199954986572, -4.484499931335449, -4.55709981918335, -4.774799823760986, -4.825799942016602, -4.934700012207031, -5.060100078582764, -5.1006999015808105, -5.186699867248535, -5.191299915313721, -5.211400032043457, -5.239099979400635, -5.247300148010254, -5.4532999992370605, 2.1126999855041504, 2.1089000701904297, 2.108799934387207, 2.1064000129699707, 2.1064000129699707, 2.1059999465942383, 2.1054999828338623, 1.8116999864578247, 1.7900999784469604, 0.6172999739646912, 0.6051999926567078, 0.578499972820282, 0.4740999937057495, -0.41100001335144043, -0.5117999911308289, -2.106100082397461, -2.9231998920440674, -3.0896999835968018, -3.329900026321411, -3.747299909591675, -3.9096999168395996, -4.289000034332275, -4.295899868011475, -4.299099922180176, -4.432199954986572, -4.468699932098389, -4.564700126647949, -4.633800029754639, -4.666800022125244, -4.7032999992370605, -5.029799938201904, -4.736199855804443, -5.127200126647949, -5.383500099182129, 2.073499917984009, 2.072999954223633, 2.072499990463257, 2.069999933242798, 2.069499969482422, 2.0690999031066895, 2.063499927520752, 2.045599937438965, 1.9421000480651855, 1.9154000282287598, 1.6532000303268433, 1.534600019454956, 1.4648000001907349, 1.3840999603271484, 1.0892000198364258, 0.9517999887466431, -1.2029000520706177, -2.0262999534606934, -3.063199996948242, -3.232300043106079, -3.511399984359741, -4.016200065612793, -4.404200077056885, -4.414000034332275, -4.809700012207031, -4.828000068664551, -4.832799911499023, -4.86329984664917, -4.886099815368652, -4.898900032043457, -5.268199920654297, -4.985799789428711, -5.293799877166748, -5.453700065612793, -5.734399795532227, -5.378900051116943, -6.626999855041504, 2.231300115585327, 2.231100082397461, 2.2309000492095947, 2.2293999195098877, 2.229099988937378, 2.2260000705718994, 2.2197000980377197, 2.2102999687194824, 2.193000078201294, 2.1745998859405518, 2.168600082397461, 1.4323999881744385, 0.8212000131607056, 0.6970999836921692, 0.6744999885559082, 0.613099992275238, 0.6000000238418579, 0.326200008392334, -1.4944000244140625, -3.3552000522613525, -3.4119999408721924, -4.258399963378906, -4.4542999267578125, -4.554800033569336, -4.555500030517578, -4.5594000816345215, -4.574900150299072, -4.579899787902832, -4.580999851226807, -4.601399898529053, -5.036099910736084, -4.8815999031066895, -4.739299774169922, -5.235099792480469, -5.024600028991699, -5.453700065612793, -5.979100227355957, 2.117500066757202, 2.1154000759124756, 2.1145999431610107, 2.1145999431610107, 2.1142001152038574, 2.1136999130249023, 2.035900115966797, 1.8158999681472778, 1.0650999546051025, 0.02319999970495701, -0.23980000615119934, -0.27230000495910645, -2.3643999099731445, -3.039599895477295, -3.386399984359741, -3.501199960708618, -3.613600015640259, -3.8482000827789307, -4.290800094604492, -4.409999847412109, -4.433499813079834, -4.530799865722656, -4.589099884033203, -4.61870002746582, -4.73799991607666, -4.753300189971924, -4.769599914550781, -4.773600101470947, -4.781899929046631, -4.803199768066406, -4.803400039672852, -4.857100009918213, -5.50600004196167, -5.021299839019775, -4.973999977111816, 2.174799919128418, 2.173799991607666, 2.1737000942230225, 2.1719000339508057, 2.1689999103546143, 1.954300045967102, 1.9349000453948975, 1.8925000429153442, 1.779099941253662, 1.7021000385284424, 1.5815999507904053, 0.8025000095367432, 0.7702000141143799, 0.7128999829292297, 0.5038999915122986, -0.4683000147342682, -2.4007999897003174, -2.433000087738037, -3.3173999786376953, -3.593400001525879, -3.662600040435791, -3.8512001037597656, -3.9828999042510986, -4.278299808502197, -4.484399795532227, -4.489699840545654, -4.639599800109863, -4.646900177001953, -4.649600028991699, -4.679200172424316, -4.787600040435791, -4.8907999992370605, -4.910299777984619, -5.392099857330322, -6.454999923706055], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.229099988937378, -2.4412999153137207, -2.708199977874756, -2.019700050354004, -2.9707000255584717, -2.791599988937378, -2.7130000591278076, -3.0761001110076904, -3.0752999782562256, -1.6384999752044678, -3.362299919128418, -4.558599948883057, -2.5520999431610107, -4.857500076293945, -5.263599872589111, -7.6539998054504395, -8.420599937438965, -8.265299797058105, -9.169500350952148, -9.555700302124023, -9.305000305175781, -9.878600120544434, -9.878600120544434, -9.878600120544434, -9.690799713134766, -9.878600120544434, -9.878600120544434, -9.878600120544434, -9.809100151062012, -9.878600120544434, -9.01200008392334, -9.531700134277344, -9.277099609375, -9.82960033416748, -9.54539966583252, -9.643400192260742, -9.532699584960938, -9.740699768066406, -9.544099807739258, -9.736900329589844, -2.2309999465942383, -3.0722999572753906, -2.0039000511169434, -2.9684998989105225, -0.8264999985694885, -3.169100046157837, -3.3125998973846436, -4.667900085449219, -4.546299934387207, -2.25819993019104, -4.6666998863220215, -5.317399978637695, -7.457200050354004, -7.205699920654297, -8.288800239562988, -8.646400451660156, -8.889699935913086, -9.681699752807617, -9.874600410461426, -9.921299934387207, -9.373000144958496, -9.949600219726562, -9.97029972076416, -9.97029972076416, -9.97029972076416, -9.97029972076416, -9.921299934387207, -9.97029972076416, -9.97029972076416, -9.97029972076416, -9.469099998474121, -9.40149974822998, -9.689599990844727, -9.681099891662598, -9.644000053405762, -9.758500099182129, -9.842100143432617, -9.475500106811523, -9.459500312805176, -9.73169994354248, -9.780599594116211, -9.681599617004395, -9.398799896240234, -1.2237000465393066, -2.7081000804901123, -3.0871999263763428, -3.167099952697754, -3.2565999031066895, -3.3492000102996826, -1.0526000261306763, -3.361799955368042, -3.8199000358581543, -3.4547998905181885, -4.2144999504089355, -4.580699920654297, -4.740499973297119, -6.582399845123291, -7.126399993896484, -7.067299842834473, -8.087200164794922, -8.218000411987305, -8.177900314331055, -9.361599922180176, -7.814000129699707, -9.074399948120117, -9.648599624633789, -9.556099891662598, -9.76830005645752, -9.833499908447266, -10.057100296020508, -10.197699546813965, -10.257800102233887, -10.257800102233887, -9.570899963378906, -9.385299682617188, -9.410300254821777, -10.023099899291992, -1.8897000551223755, -2.4511001110076904, -2.451200008392334, -1.861899971961975, -2.6603000164031982, -2.5875000953674316, -2.1839001178741455, -2.6401000022888184, -2.941800117492676, -4.480400085449219, -4.047999858856201, -2.8034000396728516, -3.5053000450134277, -5.21150016784668, -5.582900047302246, -6.919300079345703, -5.564799785614014, -7.692500114440918, -8.228699684143066, -8.635000228881836, -8.718999862670898, -9.199899673461914, -8.586199760437012, -8.445300102233887, -7.1118998527526855, -9.336400032043457, -9.557999610900879, -9.730899810791016, -9.75629997253418, -9.771400451660156, -8.071800231933594, -9.63860034942627, -9.19219970703125, -9.489700317382812, -2.2802999019622803, -2.434299945831299, -2.552000045776367, -2.383699893951416, -2.9274001121520996, -3.0225000381469727, -2.500499963760376, -3.0439000129699707, -2.12280011177063, -2.8427999019622803, -3.2576000690460205, -3.5315001010894775, -2.5146000385284424, -3.713599920272827, -3.720099925994873, -3.713599920272827, -5.732900142669678, -7.02810001373291, -7.876500129699707, -7.999000072479248, -8.579400062561035, -8.816699981689453, -9.399299621582031, -7.79580020904541, -9.880900382995605, -9.77810001373291, -9.929800033569336, -9.929800033569336, -9.929800033569336, -9.880800247192383, -9.557600021362305, -9.873600006103516, -9.745599746704102, -9.744000434875488, -9.673999786376953, -9.791999816894531, -9.668999671936035, -2.294800043106079, -2.4279000759124756, -2.427999973297119, -2.7639000415802, -2.76419997215271, -2.672800064086914, -2.593400001525879, -2.6029999256134033, -2.336899995803833, -2.2385001182556152, -2.8331000804901123, -3.5100998878479004, -3.9600000381469727, -4.36899995803833, -4.36929988861084, -4.369699954986572, -4.350100040435791, -4.58459997177124, -6.583899974822998, -7.423699855804443, -7.558300018310547, -9.355400085449219, -9.014300346374512, -9.621299743652344, -9.623499870300293, -9.475299835205078, -9.672499656677246, -9.576800346374512, -9.672499656677246, -9.672499656677246, -8.078200340270996, -9.445599555969238, -9.575900077819824, -9.398099899291992, -9.478300094604492, -9.39330005645752, -9.268400192260742, -1.1718000173568726, -2.047600030899048, -2.3756000995635986, -2.3756000995635986, -2.176100015640259, -2.626499891281128, -3.0352001190185547, -2.786799907684326, -3.877500057220459, -4.041800022125244, -3.6215999126434326, -4.9253997802734375, -7.177499771118164, -7.876100063323975, -7.838200092315674, -7.790599822998047, -8.680100440979004, -7.827600002288818, -9.287699699401855, -7.051700115203857, -9.525099754333496, -9.441699981689453, -9.686100006103516, -9.376799583435059, -9.574600219726562, -9.279399871826172, -9.813400268554688, -9.871299743652344, -9.871299743652344, -9.871299743652344, -7.8454999923706055, -9.522500038146973, -8.185700416564941, -9.546299934387207, -9.59850025177002, -1.931399941444397, -2.244800090789795, -2.298799991607666, -2.4179999828338623, -1.8996000289916992, -2.9958999156951904, -3.1089000701904297, -2.888700008392334, -2.8863000869750977, -3.107300043106079, -2.885999917984009, -3.800299882888794, -3.6816000938415527, -4.087600231170654, -4.491199970245361, -4.407800197601318, -5.782599925994873, -5.11269998550415, -7.606800079345703, -8.153400421142578, -6.304200172424316, -8.922300338745117, -8.220800399780273, -9.091500282287598, -9.581999778747559, -9.555700302124023, -9.636500358581543, -9.73639965057373, -9.407699584960938, -9.745699882507324, -8.852499961853027, -9.420700073242188, -9.48009967803955, -9.394499778747559, -9.496999740600586]}, \"token.table\": {\"Topic\": [4, 1, 1, 6, 1, 2, 7, 3, 5, 6, 3, 5, 6, 6, 1, 6, 7, 2, 6, 8, 6, 5, 5, 7, 2, 8, 5, 6, 6, 5, 1, 6, 3, 4, 2, 6, 2, 3, 4, 6, 8, 1, 5, 8, 4, 5, 8, 6, 2, 4, 5, 7, 2, 5, 6, 4, 3, 7, 2, 6, 7, 8, 1, 1, 6, 8, 5, 1, 2, 8, 5, 3, 8, 1, 3, 1, 4, 4, 2, 3, 3, 4, 5, 4, 8, 3, 5, 3, 8, 8, 2, 6, 1, 8, 1, 4, 5, 5, 6, 8, 3, 7, 1, 4, 7, 8, 7, 8, 1, 3, 4, 7, 4, 2, 4, 8, 5, 8, 7, 4, 7], \"Freq\": [1.022049069404602, 1.0157510042190552, 0.8154973387718201, 0.1812216341495514, 0.08239201456308365, 0.9063121676445007, 0.9997109174728394, 0.16864047944545746, 0.6745619177818298, 0.16864047944545746, 0.9958406090736389, 0.057611167430877686, 0.9793898463249207, 0.9997665882110596, 1.0191779136657715, 0.9234102964401245, 0.996599555015564, 0.9893784523010254, 0.2222025841474533, 0.7406752705574036, 0.9756112694740295, 1.0133010149002075, 0.8685373663902283, 0.10856717079877853, 0.9257718920707703, 0.06384634226560593, 1.0108766555786133, 0.9942408800125122, 1.0072215795516968, 1.0102061033248901, 1.0201834440231323, 0.9940713047981262, 0.2820092439651489, 0.7050231099128723, 0.9852358102798462, 0.9831337928771973, 0.2005157768726349, 0.793345034122467, 0.008718077093362808, 0.9831419587135315, 0.9804463386535645, 0.14475733041763306, 0.8685439825057983, 0.9787335991859436, 0.9964655637741089, 0.3809078335762024, 0.609452486038208, 1.007235050201416, 0.2657652199268341, 0.19932392239570618, 0.5315304398536682, 0.995337963104248, 0.19695636630058289, 0.590869128704071, 0.19695636630058289, 1.0092788934707642, 0.9746049642562866, 0.9978805780410767, 0.1740627884864807, 0.4351569712162018, 0.3481255769729614, 0.980616569519043, 1.0170470476150513, 0.9813036918640137, 0.19261664152145386, 0.7704665660858154, 1.013803482055664, 0.13584159314632416, 0.8512740135192871, 0.009056106209754944, 1.0142828226089478, 0.4330568015575409, 0.5413209795951843, 0.5652756690979004, 0.4845219850540161, 1.017696738243103, 0.9857929348945618, 1.0092651844024658, 0.17805099487304688, 0.8012295365333557, 0.304915189743042, 0.20327679812908173, 0.5081920027732849, 0.7459232211112976, 0.26640114188194275, 1.001840353012085, 1.0080715417861938, 0.986771821975708, 0.9793582558631897, 0.9791335463523865, 0.051257435232400894, 0.9226338267326355, 0.8255548477172852, 0.1834566295146942, 1.017594575881958, 1.017696499824524, 1.0132304430007935, 1.01445472240448, 0.17539790272712708, 0.7892905473709106, 1.0033464431762695, 0.9973593354225159, 0.6762154698371887, 0.2193131297826767, 0.09138046950101852, 0.018276093527674675, 0.7435504198074341, 0.24785013496875763, 0.0651627704501152, 0.5864649415016174, 0.1954883188009262, 0.0651627704501152, 0.9856895804405212, 0.6795922517776489, 0.07551024854183197, 0.2265307456254959, 0.3298497498035431, 0.6596994996070862, 0.9966115951538086, 0.09897524118423462, 0.8907771706581116], \"Term\": [\"amaze\", \"amazing\", \"atmosphere\", \"atmosphere\", \"awesome\", \"awesome\", \"back\", \"bland\", \"bland\", \"bland\", \"buffet\", \"burger\", \"burger\", \"cant\", \"chicken\", \"cook\", \"definitely\", \"delicious\", \"didnt\", \"didnt\", \"disappointed\", \"dish\", \"dont\", \"dont\", \"eat\", \"eat\", \"enjoy\", \"enough\", \"everything\", \"excellent\", \"experience\", \"fantastic\", \"feel\", \"feel\", \"find\", \"flavor\", \"food\", \"food\", \"food\", \"fresh\", \"friendly\", \"fry\", \"fry\", \"give\", \"im\", \"know\", \"know\", \"leave\", \"love\", \"love\", \"love\", \"meal\", \"meat\", \"meat\", \"meat\", \"menu\", \"minute\", \"never\", \"next\", \"next\", \"next\", \"nice\", \"night\", \"order\", \"perfect\", \"perfect\", \"pizza\", \"place\", \"place\", \"place\", \"pretty\", \"price\", \"price\", \"quality\", \"quality\", \"recommend\", \"restaurant\", \"salad\", \"selection\", \"selection\", \"serve\", \"serve\", \"serve\", \"server\", \"server\", \"service\", \"side\", \"slow\", \"staff\", \"star\", \"steak\", \"steak\", \"still\", \"still\", \"sushi\", \"table\", \"take\", \"taste\", \"tasty\", \"tasty\", \"thing\", \"think\", \"time\", \"time\", \"time\", \"time\", \"try\", \"try\", \"vega\", \"vega\", \"vega\", \"vega\", \"wait\", \"wasnt\", \"wasnt\", \"wasnt\", \"way\", \"way\", \"wont\", \"worth\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el118821400705981984008247933659\", ldavis_el118821400705981984008247933659_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el118821400705981984008247933659\", ldavis_el118821400705981984008247933659_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el118821400705981984008247933659\", ldavis_el118821400705981984008247933659_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(lda_model_1, bow_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saliency**: a measure of how much the term tells you about the topic.\n",
    "\n",
    "**Relevance**: a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n",
    "\n",
    "The **size** of the bubble measures the importance of the topics, relative to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "?remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (7) Test on new text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.017260833),\n",
       " (1, 0.01724369),\n",
       " (2, 0.18951832),\n",
       " (3, 0.017246092),\n",
       " (4, 0.017241381),\n",
       " (5, 0.017241381),\n",
       " (6, 0.53268766),\n",
       " (7, 0.19156067)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try on a new (invented) text\n",
    "text_test = ['time', 'waste', 'food', 'staff', 'back', 'definitely']\n",
    "text_test_bow = dictionary.doc2bow(text_test)\n",
    "\n",
    "lda_model_1.get_document_topics(bow = text_test_bow)\n",
    "list(lda_model_1[text_test_bow])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of topic probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ```topicmod.lda_dtm2df``` to create a dataframe in which:\n",
    "- each row represents a document/text\n",
    "- has one column for each topic containing the probability of that topic for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_df = lda_dtm2df(lda_model_1[bow_corpus], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_lda</th>\n",
       "      <th>t1_lda</th>\n",
       "      <th>t2_lda</th>\n",
       "      <th>t3_lda</th>\n",
       "      <th>t4_lda</th>\n",
       "      <th>t5_lda</th>\n",
       "      <th>t6_lda</th>\n",
       "      <th>t7_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.749976</td>\n",
       "      <td>0.035738</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026319</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.289481</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t0_lda    t1_lda    t2_lda    t3_lda    t4_lda    t5_lda    t6_lda  \\\n",
       "0  0.035714  0.749976  0.035738  0.035714  0.035714  0.035714  0.035714   \n",
       "1  0.055556  0.055556  0.055556  0.055556  0.611111  0.055556  0.055556   \n",
       "2  0.026316  0.026316  0.026316  0.026316  0.026316  0.026316  0.026316   \n",
       "3  0.026316  0.026319  0.289463  0.026316  0.026316  0.289474  0.289481   \n",
       "4  0.055556  0.055556  0.055556  0.611111  0.055556  0.055556  0.055556   \n",
       "\n",
       "     t7_lda  \n",
       "0  0.035714  \n",
       "1  0.055556  \n",
       "2  0.815789  \n",
       "3  0.026316  \n",
       "4  0.055556  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of topics' top n words and their probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ```topicmod.lda_topic_top_words``` to create a dataframe in which:\n",
    "- each row represents a document/text\n",
    "- columns contains a list of that topic's top n words and a list of their the probability for that topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0_top_words_lda</th>\n",
       "      <th>t1_top_words_lda</th>\n",
       "      <th>t2_top_words_lda</th>\n",
       "      <th>t3_top_words_lda</th>\n",
       "      <th>t4_top_words_lda</th>\n",
       "      <th>t5_top_words_lda</th>\n",
       "      <th>t6_top_words_lda</th>\n",
       "      <th>t7_top_words_lda</th>\n",
       "      <th>t0_top_word_pbs_lda</th>\n",
       "      <th>t1_top_word_pbs_lda</th>\n",
       "      <th>t2_top_word_pbs_lda</th>\n",
       "      <th>t3_top_word_pbs_lda</th>\n",
       "      <th>t4_top_word_pbs_lda</th>\n",
       "      <th>t5_top_word_pbs_lda</th>\n",
       "      <th>t6_top_word_pbs_lda</th>\n",
       "      <th>t7_top_word_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[time, order, experience, chicken, place, recommend]</td>\n",
       "      <td>[place, eat, delicious, food, awesome, find]</td>\n",
       "      <td>[food, service, minute, thing, buffet, slow]</td>\n",
       "      <td>[wait, restaurant, im, salad, menu, table]</td>\n",
       "      <td>[dont, taste, pretty, pizza, dish, love]</td>\n",
       "      <td>[steak, disappointed, burger, flavor, fresh, fantastic]</td>\n",
       "      <td>[back, never, think, definitely, wont, meal]</td>\n",
       "      <td>[nice, friendly, staff, star, give, price]</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[time, order, experience, chicken, place, recommend]</td>\n",
       "      <td>[place, eat, delicious, food, awesome, find]</td>\n",
       "      <td>[food, service, minute, thing, buffet, slow]</td>\n",
       "      <td>[wait, restaurant, im, salad, menu, table]</td>\n",
       "      <td>[dont, taste, pretty, pizza, dish, love]</td>\n",
       "      <td>[steak, disappointed, burger, flavor, fresh, fantastic]</td>\n",
       "      <td>[back, never, think, definitely, wont, meal]</td>\n",
       "      <td>[nice, friendly, staff, star, give, price]</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[time, order, experience, chicken, place, recommend]</td>\n",
       "      <td>[place, eat, delicious, food, awesome, find]</td>\n",
       "      <td>[food, service, minute, thing, buffet, slow]</td>\n",
       "      <td>[wait, restaurant, im, salad, menu, table]</td>\n",
       "      <td>[dont, taste, pretty, pizza, dish, love]</td>\n",
       "      <td>[steak, disappointed, burger, flavor, fresh, fantastic]</td>\n",
       "      <td>[back, never, think, definitely, wont, meal]</td>\n",
       "      <td>[nice, friendly, staff, star, give, price]</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[time, order, experience, chicken, place, recommend]</td>\n",
       "      <td>[place, eat, delicious, food, awesome, find]</td>\n",
       "      <td>[food, service, minute, thing, buffet, slow]</td>\n",
       "      <td>[wait, restaurant, im, salad, menu, table]</td>\n",
       "      <td>[dont, taste, pretty, pizza, dish, love]</td>\n",
       "      <td>[steak, disappointed, burger, flavor, fresh, fantastic]</td>\n",
       "      <td>[back, never, think, definitely, wont, meal]</td>\n",
       "      <td>[nice, friendly, staff, star, give, price]</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[time, order, experience, chicken, place, recommend]</td>\n",
       "      <td>[place, eat, delicious, food, awesome, find]</td>\n",
       "      <td>[food, service, minute, thing, buffet, slow]</td>\n",
       "      <td>[wait, restaurant, im, salad, menu, table]</td>\n",
       "      <td>[dont, taste, pretty, pizza, dish, love]</td>\n",
       "      <td>[steak, disappointed, burger, flavor, fresh, fantastic]</td>\n",
       "      <td>[back, never, think, definitely, wont, meal]</td>\n",
       "      <td>[nice, friendly, staff, star, give, price]</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       t0_top_words_lda  \\\n",
       "0  [time, order, experience, chicken, place, recommend]   \n",
       "1  [time, order, experience, chicken, place, recommend]   \n",
       "2  [time, order, experience, chicken, place, recommend]   \n",
       "3  [time, order, experience, chicken, place, recommend]   \n",
       "4  [time, order, experience, chicken, place, recommend]   \n",
       "\n",
       "                               t1_top_words_lda  \\\n",
       "0  [place, eat, delicious, food, awesome, find]   \n",
       "1  [place, eat, delicious, food, awesome, find]   \n",
       "2  [place, eat, delicious, food, awesome, find]   \n",
       "3  [place, eat, delicious, food, awesome, find]   \n",
       "4  [place, eat, delicious, food, awesome, find]   \n",
       "\n",
       "                               t2_top_words_lda  \\\n",
       "0  [food, service, minute, thing, buffet, slow]   \n",
       "1  [food, service, minute, thing, buffet, slow]   \n",
       "2  [food, service, minute, thing, buffet, slow]   \n",
       "3  [food, service, minute, thing, buffet, slow]   \n",
       "4  [food, service, minute, thing, buffet, slow]   \n",
       "\n",
       "                             t3_top_words_lda  \\\n",
       "0  [wait, restaurant, im, salad, menu, table]   \n",
       "1  [wait, restaurant, im, salad, menu, table]   \n",
       "2  [wait, restaurant, im, salad, menu, table]   \n",
       "3  [wait, restaurant, im, salad, menu, table]   \n",
       "4  [wait, restaurant, im, salad, menu, table]   \n",
       "\n",
       "                           t4_top_words_lda  \\\n",
       "0  [dont, taste, pretty, pizza, dish, love]   \n",
       "1  [dont, taste, pretty, pizza, dish, love]   \n",
       "2  [dont, taste, pretty, pizza, dish, love]   \n",
       "3  [dont, taste, pretty, pizza, dish, love]   \n",
       "4  [dont, taste, pretty, pizza, dish, love]   \n",
       "\n",
       "                                          t5_top_words_lda  \\\n",
       "0  [steak, disappointed, burger, flavor, fresh, fantastic]   \n",
       "1  [steak, disappointed, burger, flavor, fresh, fantastic]   \n",
       "2  [steak, disappointed, burger, flavor, fresh, fantastic]   \n",
       "3  [steak, disappointed, burger, flavor, fresh, fantastic]   \n",
       "4  [steak, disappointed, burger, flavor, fresh, fantastic]   \n",
       "\n",
       "                               t6_top_words_lda  \\\n",
       "0  [back, never, think, definitely, wont, meal]   \n",
       "1  [back, never, think, definitely, wont, meal]   \n",
       "2  [back, never, think, definitely, wont, meal]   \n",
       "3  [back, never, think, definitely, wont, meal]   \n",
       "4  [back, never, think, definitely, wont, meal]   \n",
       "\n",
       "                             t7_top_words_lda  \\\n",
       "0  [nice, friendly, staff, star, give, price]   \n",
       "1  [nice, friendly, staff, star, give, price]   \n",
       "2  [nice, friendly, staff, star, give, price]   \n",
       "3  [nice, friendly, staff, star, give, price]   \n",
       "4  [nice, friendly, staff, star, give, price]   \n",
       "\n",
       "                                                           t0_top_word_pbs_lda  \\\n",
       "0  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "1  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "2  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "3  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "4  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "\n",
       "                                                        t1_top_word_pbs_lda  \\\n",
       "0  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "1  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "2  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "3  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "4  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "\n",
       "                                                       t2_top_word_pbs_lda  \\\n",
       "0  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "1  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "2  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "3  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "4  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "\n",
       "                                                          t3_top_word_pbs_lda  \\\n",
       "0  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "1  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "2  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "3  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "4  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "\n",
       "                                                      t4_top_word_pbs_lda  \\\n",
       "0  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "1  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "2  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "3  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "4  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "\n",
       "                                                          t5_top_word_pbs_lda  \\\n",
       "0  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "1  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "2  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "3  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "4  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "\n",
       "                                                         t6_top_word_pbs_lda  \\\n",
       "0  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "1  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "2  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "3  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "4  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "\n",
       "                                                        t7_top_word_pbs_lda  \n",
       "0  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]  \n",
       "1  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]  \n",
       "2  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]  \n",
       "3  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]  \n",
       "4  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (iv) extract top n words and their probabilities for each topic, turn them into a dataframe\n",
    "\n",
    "words_topics_dict = lda_topic_top_words(lda_mod = lda_model_1, n_top_words = 6)\n",
    "words_topics_df = topictopwords_dict2df(words_topics_dict, orig_dataset = df, tech = 'lda')\n",
    "\n",
    "words_topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe with top n topics for each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use ```topicmod.lda_ranked_topics2df``` to create a dataframe in which:\n",
    "- rows are documents\n",
    "- the first column ```ranked_topics_lda``` contains tuples of ranked topics for each document; if all topics have the same probability for a document, then topics are ordered by their index (e.g., (0,1,2,3))\n",
    "- the second column ```ranked_topics_pbs_lda``` contains tuples of the ranked topics' probabilities for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranked_topics_lda</th>\n",
       "      <th>ranked_topics_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2, 3, 7, 0, 4, 5, 6)</td>\n",
       "      <td>(0.7499741, 0.035740074, 0.035714395, 0.035714306, 0.03571429, 0.03571429, 0.03571429, 0.03571429)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(4, 0, 1, 2, 3, 5, 6, 7)</td>\n",
       "      <td>(0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(7, 0, 1, 2, 3, 4, 5, 6)</td>\n",
       "      <td>(0.81578946, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(6, 5, 2, 1, 3, 7, 0, 4)</td>\n",
       "      <td>(0.28948092, 0.28947368, 0.2894628, 0.026319396, 0.026315846, 0.026315797, 0.026315788, 0.026315788)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(3, 0, 1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>(0.61111104, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ranked_topics_lda  \\\n",
       "0  (1, 2, 3, 7, 0, 4, 5, 6)   \n",
       "1  (4, 0, 1, 2, 3, 5, 6, 7)   \n",
       "2  (7, 0, 1, 2, 3, 4, 5, 6)   \n",
       "3  (6, 5, 2, 1, 3, 7, 0, 4)   \n",
       "4  (3, 0, 1, 2, 4, 5, 6, 7)   \n",
       "\n",
       "                                                                                    ranked_topics_pbs_lda  \n",
       "0  (0.7499741, 0.035740074, 0.035714395, 0.035714306, 0.03571429, 0.03571429, 0.03571429, 0.03571429)      \n",
       "1  (0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)  \n",
       "2  (0.81578946, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579)        \n",
       "3  (0.28948092, 0.28947368, 0.2894628, 0.026319396, 0.026315846, 0.026315797, 0.026315788, 0.026315788)    \n",
       "4  (0.61111104, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)        "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (v) Ranked topics for each doc, create a DTM dataframe \n",
    "\n",
    "ranked_DTM_df =  lda_ranked_topics2df(lda_mod = lda_model_1, corpus = bow_corpus)\n",
    "\n",
    "ranked_DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join LDA-results datasets with the original dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll be using our ```nlpfunctions.utils.merge_dfs``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = merge_dfs(df, DTM_df, words_topics_df, ranked_DTM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>text_lemmas</th>\n",
       "      <th>t0_lda</th>\n",
       "      <th>t1_lda</th>\n",
       "      <th>t2_lda</th>\n",
       "      <th>t3_lda</th>\n",
       "      <th>t4_lda</th>\n",
       "      <th>t5_lda</th>\n",
       "      <th>...</th>\n",
       "      <th>t0_top_word_pbs_lda</th>\n",
       "      <th>t1_top_word_pbs_lda</th>\n",
       "      <th>t2_top_word_pbs_lda</th>\n",
       "      <th>t3_top_word_pbs_lda</th>\n",
       "      <th>t4_top_word_pbs_lda</th>\n",
       "      <th>t5_top_word_pbs_lda</th>\n",
       "      <th>t6_top_word_pbs_lda</th>\n",
       "      <th>t7_top_word_pbs_lda</th>\n",
       "      <th>ranked_topics_lda</th>\n",
       "      <th>ranked_topics_pbs_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[wow, love, place]</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.749976</td>\n",
       "      <td>0.035738</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "      <td>(1, 2, 3, 7, 0, 4, 5, 6)</td>\n",
       "      <td>(0.7499741, 0.035740074, 0.035714395, 0.035714306, 0.03571429, 0.03571429, 0.03571429, 0.03571429)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[crust]</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "      <td>(4, 0, 1, 2, 3, 5, 6, 7)</td>\n",
       "      <td>(0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "      <td>(7, 0, 1, 2, 3, 4, 5, 6)</td>\n",
       "      <td>(0.81578946, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[stop, bank, holiday, rick, steve, recommendation, love]</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026319</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "      <td>(6, 5, 2, 1, 3, 7, 0, 4)</td>\n",
       "      <td>(0.28948092, 0.28947368, 0.2894628, 0.026319396, 0.026315846, 0.026315797, 0.026315788, 0.026315788)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "      <td>[selection, menu, price]</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]</td>\n",
       "      <td>[0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]</td>\n",
       "      <td>[0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]</td>\n",
       "      <td>[0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]</td>\n",
       "      <td>[0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]</td>\n",
       "      <td>[0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]</td>\n",
       "      <td>[0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]</td>\n",
       "      <td>[0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]</td>\n",
       "      <td>(3, 0, 1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>(0.61111104, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      text  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "   score source                                               text_lemmas  \\\n",
       "0  1      yelp   [wow, love, place]                                         \n",
       "1  0      yelp   [crust]                                                    \n",
       "2  0      yelp   [tasty, texture, nasty]                                    \n",
       "3  1      yelp   [stop, bank, holiday, rick, steve, recommendation, love]   \n",
       "4  1      yelp   [selection, menu, price]                                   \n",
       "\n",
       "     t0_lda    t1_lda    t2_lda    t3_lda    t4_lda    t5_lda  \\\n",
       "0  0.035714  0.749976  0.035738  0.035714  0.035714  0.035714   \n",
       "1  0.055556  0.055556  0.055556  0.055556  0.611111  0.055556   \n",
       "2  0.026316  0.026316  0.026316  0.026316  0.026316  0.026316   \n",
       "3  0.026316  0.026319  0.289463  0.026316  0.026316  0.289474   \n",
       "4  0.055556  0.055556  0.055556  0.611111  0.055556  0.055556   \n",
       "\n",
       "                                                    ...                                                    \\\n",
       "0                                                   ...                                                     \n",
       "1                                                   ...                                                     \n",
       "2                                                   ...                                                     \n",
       "3                                                   ...                                                     \n",
       "4                                                   ...                                                     \n",
       "\n",
       "                                                           t0_top_word_pbs_lda  \\\n",
       "0  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "1  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "2  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "3  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "4  [0.19427764, 0.13270135, 0.107623115, 0.087046705, 0.07792143, 0.066655315]   \n",
       "\n",
       "                                                        t1_top_word_pbs_lda  \\\n",
       "0  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "1  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "2  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "3  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "4  [0.4375628, 0.13480526, 0.10742526, 0.10453638, 0.051379252, 0.04631667]   \n",
       "\n",
       "                                                       t2_top_word_pbs_lda  \\\n",
       "0  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "1  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "2  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "3  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "4  [0.3490215, 0.2941262, 0.06666314, 0.04562829, 0.04212442, 0.038519986]   \n",
       "\n",
       "                                                          t3_top_word_pbs_lda  \\\n",
       "0  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "1  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "2  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "3  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "4  [0.15536971, 0.15112151, 0.11259605, 0.08620191, 0.086186044, 0.075210355]   \n",
       "\n",
       "                                                      t4_top_word_pbs_lda  \\\n",
       "0  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "1  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "2  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "3  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "4  [0.11969008, 0.10225051, 0.092205025, 0.08766023, 0.0820418, 0.080893]   \n",
       "\n",
       "                                                          t5_top_word_pbs_lda  \\\n",
       "0  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "1  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "2  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "3  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "4  [0.10662046, 0.10078241, 0.096626334, 0.088223964, 0.08821183, 0.07476828]   \n",
       "\n",
       "                                                         t6_top_word_pbs_lda  \\\n",
       "0  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "1  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "2  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "3  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "4  [0.30979413, 0.12904908, 0.11348158, 0.09295596, 0.092954315, 0.07232885]   \n",
       "\n",
       "                                                        t7_top_word_pbs_lda  \\\n",
       "0  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]   \n",
       "1  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]   \n",
       "2  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]   \n",
       "3  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]   \n",
       "4  [0.14963323, 0.1449492, 0.10594377, 0.10037849, 0.089102834, 0.05579701]   \n",
       "\n",
       "          ranked_topics_lda  \\\n",
       "0  (1, 2, 3, 7, 0, 4, 5, 6)   \n",
       "1  (4, 0, 1, 2, 3, 5, 6, 7)   \n",
       "2  (7, 0, 1, 2, 3, 4, 5, 6)   \n",
       "3  (6, 5, 2, 1, 3, 7, 0, 4)   \n",
       "4  (3, 0, 1, 2, 4, 5, 6, 7)   \n",
       "\n",
       "                                                                                    ranked_topics_pbs_lda  \n",
       "0  (0.7499741, 0.035740074, 0.035714395, 0.035714306, 0.03571429, 0.03571429, 0.03571429, 0.03571429)      \n",
       "1  (0.6111111, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556, 0.055555556)  \n",
       "2  (0.81578946, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579, 0.02631579)        \n",
       "3  (0.28948092, 0.28947368, 0.2894628, 0.026319396, 0.026315846, 0.026315797, 0.026315788, 0.026315788)    \n",
       "4  (0.61111104, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556, 0.05555556)        \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the LDA results as input for other analyses. For instance, here we show how we could include documents' ranked topics and probabilities in a classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lda_topic_pbs = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['t0_lda', 't1_lda', 't2_lda', 't3_lda', 't4_lda', 't5_lda', 't6_lda', 't7_lda']))\n",
    "        \n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = CountVectorizer(tokenizer = word_tokenize,\n",
    "                         analyzer=\"word\",\n",
    "                         ngram_range = (1,3),\n",
    "                         stop_words=None,\n",
    "                         min_df=1\n",
    "                         )\n",
    "\n",
    "pipe_bags_words = Pipeline([\n",
    "        \n",
    "        ('selector', ColumnSelector(columns=['text'])),\n",
    "        ('transformer', Series2ListOfStrings()),\n",
    "        ('vec', my_vec),\n",
    "        ('tf_idf', TfidfTransformer())\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier\n",
    "\n",
    "svm = SVC(probability=True, C=1, kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_svm_clf = Pipeline([\n",
    "        \n",
    "        # Combined text (bag-of-word) and ad-hoc features\n",
    "        ('features', FeatureUnion(\n",
    "            \n",
    "                transformer_list = [\n",
    "                        ('lda', pipe_lda_topic_pbs),\n",
    "                        ('bow', pipe_bags_words)\n",
    "                        ],\n",
    "            \n",
    "                # weight components in FeatureUnion\n",
    "                transformer_weights={\n",
    "                        'lda': 0.6,\n",
    "                        'bow': 1.0\n",
    "                        }    \n",
    "                )),\n",
    "        \n",
    "        # Use classifier on combined features\n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = text_df[['text', 't0_lda', 't1_lda', 't2_lda', 't3_lda', 't4_lda', 't5_lda', 't6_lda', 't7_lda']]\n",
    "y = text_df.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_validate(lda_bow_svm_clf, X, y, cv = 5, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.999 (std 0.001)\n",
      "Test Accuracy: 0.813 (std 0.028)\n"
     ]
    }
   ],
   "source": [
    "sorted(scores_svm.keys())\n",
    "\n",
    "print(\"Train Accuracy: %0.3f (std %0.3f)\" % (scores_svm['train_score'].mean(), scores_svm['train_score'].std()))\n",
    "print(\"Test Accuracy: %0.3f (std %0.3f)\" % (scores_svm['test_score'].mean(), scores_svm['test_score'].std()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuplesToColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class for building sklearn Pipeline step. \n",
    "    This class turns columns from a pandas data frame (type Series) that\n",
    "    contain tuples of integer or float values into separate array columns \n",
    "    that can be used as inout in ML pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialise\n",
    "    def __init__(self):\n",
    "        self              #could also use 'pass'\n",
    "        \n",
    "    # \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):        #X: dataset to pass to the transformer.\n",
    "        cols_df = pd.DataFrame()\n",
    "        for name, valuez in X.iteritems():\n",
    "            valuez_df = pd.DataFrame(valuez.values.tolist())\n",
    "            cols_df = pd.concat([cols_df, valuez_df], axis=1)\n",
    "        return cols_df.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lda_topic_pbs_2 = Pipeline([\n",
    "    \n",
    "    ('selector', ColumnSelector(columns=['ranked_topics_lda', 'ranked_topics_pbs_lda'])),\n",
    "    ('toarray', TuplesToColumns())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_svm_clf_2 = Pipeline([\n",
    "        \n",
    "        # Combined text (bag-of-word) and ad-hoc features\n",
    "        ('features', FeatureUnion(\n",
    "            \n",
    "                transformer_list = [\n",
    "                        ('lda', pipe_lda_topic_pbs_2),\n",
    "                        ('bow', pipe_bags_words)\n",
    "                        ],\n",
    "            \n",
    "                # weight components in FeatureUnion\n",
    "                transformer_weights={\n",
    "                        'lda': 0.6,\n",
    "                        'bow': 1.0\n",
    "                        }    \n",
    "                )),\n",
    "        \n",
    "        # Use classifier on combined features\n",
    "        ('classifier', svm)\n",
    "        \n",
    "        ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_df[['text', 'ranked_topics_lda', 'ranked_topics_pbs_lda']]\n",
    "y = text_df.score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_validate(lda_bow_svm_clf_2, X, y, cv = 5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.998 (std 0.001)\n",
      "Test Accuracy: 0.809 (std 0.035)\n"
     ]
    }
   ],
   "source": [
    "sorted(scores_svm.keys())\n",
    "\n",
    "print(\"Train Accuracy: %0.3f (std %0.3f)\" % (scores_svm['train_score'].mean(), scores_svm['train_score'].std()))\n",
    "print(\"Test Accuracy: %0.3f (std %0.3f)\" % (scores_svm['test_score'].mean(), scores_svm['test_score'].std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc = TuplesToColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.        , 3.        , ..., 0.03571429, 0.03571429,\n",
       "        0.03571429],\n",
       "       [4.        , 0.        , 1.        , ..., 0.05555556, 0.05555556,\n",
       "        0.05555556],\n",
       "       [7.        , 0.        , 1.        , ..., 0.02631579, 0.02631579,\n",
       "        0.02631579],\n",
       "       ...,\n",
       "       [5.        , 1.        , 0.        , ..., 0.02631579, 0.02631579,\n",
       "        0.02631579],\n",
       "       [4.        , 0.        , 1.        , ..., 0.05555556, 0.05555556,\n",
       "        0.05555556],\n",
       "       [5.        , 0.        , 1.        , ..., 0.05555556, 0.05555556,\n",
       "        0.05555556]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc.fit_transform(text_df[['ranked_topics_lda', 'ranked_topics_pbs_lda']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
